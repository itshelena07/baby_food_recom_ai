{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1684dd94",
   "metadata": {
    "papermill": {
     "duration": 0.065982,
     "end_time": "2022-04-07T12:57:39.624742",
     "exception": false,
     "start_time": "2022-04-07T12:57:39.558760",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We're going to replicate the benchmark in [A Named Entity Based Approach to Model Recipes](https://arxiv.org/abs/2004.12184), by Diwan, Batra, and Bagler using StanfordNLP, and check it using [seqeval](https://github.com/chakki-works/seqeval).\n",
    "\n",
    "Evaluating NER is surprisingly tricky, as [David Batista explains](https://www.davidsbatista.net/blog/2018/05/09/Named_Entity_Evaluation/), and I want to check that the results in the paper are the same as what seqeval gives, so I can compare it to other models.\n",
    "\n",
    "The authors share their data in an [associated git repository](https://github.com/cosylabiiit/recipe-knowledge-mining) and train a model using [Stanford NER](https://nlp.stanford.edu/software/CRF-NER.html), which is open source, so we have a chance of replicating the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e559cc76",
   "metadata": {
    "papermill": {
     "duration": 0.059759,
     "end_time": "2022-04-07T12:57:39.748864",
     "exception": false,
     "start_time": "2022-04-07T12:57:39.689105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Installing Stanford NLP\n",
    "\n",
    "We're going to install Stanford NLP which is a Java library.\n",
    "To make things easier we will use [stanza](https://stanfordnlp.github.io/stanza/) which includes tools for [installing and invoking Stanford NLP](https://stanfordnlp.github.io/stanza/corenlp_client.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2873cc65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T12:57:39.879337Z",
     "iopub.status.busy": "2022-04-07T12:57:39.878337Z",
     "iopub.status.idle": "2022-04-07T12:57:53.376009Z",
     "shell.execute_reply": "2022-04-07T12:57:53.374964Z",
     "shell.execute_reply.started": "2022-04-07T12:49:07.145062Z"
    },
    "papermill": {
     "duration": 13.566942,
     "end_time": "2022-04-07T12:57:53.376225",
     "exception": false,
     "start_time": "2022-04-07T12:57:39.809283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanza\n",
      "  Downloading stanza-1.10.1-py3-none-any.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 2.4 MB/s eta 0:00:00\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "     -------------------------------------- 590.6/590.6 kB 6.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\helena\\desktop\\apu\\semester 5\\inv\\ir - proposal\\scraping-code\\.venv\\lib\\site-packages (from stanza) (2.2.5)\n",
      "Collecting protobuf>=3.15.0\n",
      "  Downloading protobuf-6.31.0-cp310-abi3-win_amd64.whl (435 kB)\n",
      "     -------------------------------------- 435.1/435.1 kB 6.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\helena\\desktop\\apu\\semester 5\\inv\\ir - proposal\\scraping-code\\.venv\\lib\\site-packages (from stanza) (2.32.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\helena\\desktop\\apu\\semester 5\\inv\\ir - proposal\\scraping-code\\.venv\\lib\\site-packages (from stanza) (3.4.2)\n",
      "Requirement already satisfied: torch>=1.3.0 in c:\\users\\helena\\desktop\\apu\\semester 5\\inv\\ir - proposal\\scraping-code\\.venv\\lib\\site-packages (from stanza) (2.7.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\helena\\desktop\\apu\\semester 5\\inv\\ir - proposal\\scraping-code\\.venv\\lib\\site-packages (from stanza) (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\helena\\desktop\\apu\\semester 5\\inv\\ir - proposal\\scraping-code\\.venv\\lib\\site-packages (from torch>=1.3.0->stanza) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\helena\\desktop\\apu\\semester 5\\inv\\ir - proposal\\scraping-code\\.venv\\lib\\site-packages (from torch>=1.3.0->stanza) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\helena\\desktop\\apu\\semester 5\\inv\\ir - proposal\\scraping-code\\.venv\\lib\\site-packages (from torch>=1.3.0->stanza) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\helena\\desktop\\apu\\semester 5\\inv\\ir - proposal\\scraping-code\\.venv\\lib\\site-packages (from torch>=1.3.0->stanza) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\helena\\desktop\\apu\\semester 5\\inv\\ir - proposal\\scraping-code\\.venv\\lib\\site-packages (from torch>=1.3.0->stanza) (2025.3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\helena\\desktop\\apu\\semester 5\\inv\\ir - proposal\\scraping-code\\.venv\\lib\\site-packages (from requests->stanza) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\helena\\desktop\\apu\\semester 5\\inv\\ir - proposal\\scraping-code\\.venv\\lib\\site-packages (from requests->stanza) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\helena\\desktop\\apu\\semester 5\\inv\\ir - proposal\\scraping-code\\.venv\\lib\\site-packages (from requests->stanza) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\helena\\desktop\\apu\\semester 5\\inv\\ir - proposal\\scraping-code\\.venv\\lib\\site-packages (from requests->stanza) (2025.4.26)\n",
      "Requirement already satisfied: colorama in c:\\users\\helena\\desktop\\apu\\semester 5\\inv\\ir - proposal\\scraping-code\\.venv\\lib\\site-packages (from tqdm->stanza) (0.4.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\helena\\desktop\\apu\\semester 5\\inv\\ir - proposal\\scraping-code\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.3.0->stanza) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\helena\\desktop\\apu\\semester 5\\inv\\ir - proposal\\scraping-code\\.venv\\lib\\site-packages (from jinja2->torch>=1.3.0->stanza) (3.0.2)\n",
      "Installing collected packages: protobuf, emoji, stanza\n",
      "Successfully installed emoji-2.14.1 protobuf-6.31.0 stanza-1.10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "    !pip install stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71bca3f",
   "metadata": {
    "papermill": {
     "duration": 0.072074,
     "end_time": "2022-04-07T12:57:53.522613",
     "exception": false,
     "start_time": "2022-04-07T12:57:53.450539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can specify where to install Core NLP, but we will us the default, which is either \"\\\\$CORE_NLP_HOME\", or \"\\\\$HOME/stanza_corenlp\". (Ideally we'd use stanza to get this, but I couldn't easy work out how.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85b13351",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T12:57:53.670403Z",
     "iopub.status.busy": "2022-04-07T12:57:53.669467Z",
     "iopub.status.idle": "2022-04-07T12:58:29.230320Z",
     "shell.execute_reply": "2022-04-07T12:58:29.229643Z",
     "shell.execute_reply.started": "2022-04-07T12:49:18.684182Z"
    },
    "papermill": {
     "duration": 35.633674,
     "end_time": "2022-04-07T12:58:29.230514",
     "exception": false,
     "start_time": "2022-04-07T12:57:53.596840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-15 21:01:51 INFO: Installing CoreNLP package into C:\\Users\\Helena\\stanza_corenlp\n",
      "Downloading https://huggingface.co/stanfordnlp/CoreNLP/resolve/main/stanford-corenlp-latest.zip: 100%|██████████| 508M/508M [01:23<00:00, 6.07MB/s] \n",
      "2025-05-15 21:03:16 INFO: Downloaded file to C:\\Users\\Helena\\stanza_corenlp\\corenlp.zip\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.install_corenlp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4483cf45",
   "metadata": {
    "papermill": {
     "duration": 0.06657,
     "end_time": "2022-04-07T12:58:29.364624",
     "exception": false,
     "start_time": "2022-04-07T12:58:29.298054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We'll need to invoke the Stanford Core NLP JAR that we just installed, so let's find it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b31ac2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T12:58:29.505152Z",
     "iopub.status.busy": "2022-04-07T12:58:29.504095Z",
     "iopub.status.idle": "2022-04-07T12:58:29.516285Z",
     "shell.execute_reply": "2022-04-07T12:58:29.515710Z",
     "shell.execute_reply.started": "2022-04-07T12:49:53.274276Z"
    },
    "papermill": {
     "duration": 0.084307,
     "end_time": "2022-04-07T12:58:29.516468",
     "exception": false,
     "start_time": "2022-04-07T12:58:29.432161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Helena\\\\stanza_corenlp\\\\stanford-corenlp-4.5.9.jar'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Reimplement the logic to find the path where stanza_corenlp is installed.\n",
    "core_nlp_path = os.getenv('CORENLP_HOME', str(Path.home() / 'stanza_corenlp'))\n",
    "\n",
    "# A heuristic to find the right jar file\n",
    "classpath = [str(p) for p in Path(core_nlp_path).iterdir() if re.match(r\"stanford-corenlp-[0-9.]+\\.jar\", p.name)][0]\n",
    "classpath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98419a70",
   "metadata": {
    "papermill": {
     "duration": 0.074162,
     "end_time": "2022-04-07T12:58:29.661879",
     "exception": false,
     "start_time": "2022-04-07T12:58:29.587717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's test the [basic usage](https://stanfordnlp.github.io/stanza/client_usage.html).\n",
    "\n",
    "There are currently models for 8 languages, and for some fairly complex tasks like coreference resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a8e1173",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T12:58:29.804047Z",
     "iopub.status.busy": "2022-04-07T12:58:29.803014Z",
     "iopub.status.idle": "2022-04-07T12:59:11.230446Z",
     "shell.execute_reply": "2022-04-07T12:59:11.229515Z",
     "shell.execute_reply.started": "2022-04-07T12:49:53.286134Z"
    },
    "papermill": {
     "duration": 41.500822,
     "end_time": "2022-04-07T12:59:11.230672",
     "exception": false,
     "start_time": "2022-04-07T12:58:29.729850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:09:50 INFO: Writing properties to tmp file: corenlp_server-2eae0dd9fb824ba3.props\n"
     ]
    },
    {
     "ename": "PermanentlyFailedException",
     "evalue": "Error: unable to start the CoreNLP server on port 9000 (possibly something is already running there)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\stanza\\server\\client.py:134\u001b[39m, in \u001b[36mRobustService.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.error \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mOSError\u001b[39m: [WinError 10048] Only one usage of each socket address (protocol/network address/port) is normally permitted",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mPermanentlyFailedException\u001b[39m                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstanza\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mserver\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CoreNLPClient\n\u001b[32m      3\u001b[39m text = \u001b[33m\"\u001b[39m\u001b[33mDavid Batista wrote a blog post on NER evaluation. \u001b[39m\u001b[33m\"\u001b[39m \\\n\u001b[32m      4\u001b[39m        \u001b[33m\"\u001b[39m\u001b[33mHiroki Nakayama wrote seqeval to evaluate sequential labelling tasks, such as NER. \u001b[39m\u001b[33m\"\u001b[39m \\\n\u001b[32m      5\u001b[39m        \u001b[33m\"\u001b[39m\u001b[33mWe will test his library against Stanford Core NLP. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mCoreNLPClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m     \u001b[49m\u001b[43mannotators\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtokenize\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mssplit\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpos\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlemma\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mner\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mparse\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdepparse\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcoref\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m     \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m     \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m6G\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m     \u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3001\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use a different port to avoid conflicts\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mann\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mannotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\stanza\\server\\client.py:187\u001b[39m, in \u001b[36mRobustService.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\stanza\\server\\client.py:141\u001b[39m, in \u001b[36mRobustService.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    139\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    140\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m PermanentlyFailedException(\u001b[33m\"\u001b[39m\u001b[33mError: unable to start the CoreNLP server on port \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    142\u001b[39m                                                  \u001b[33m\"\u001b[39m\u001b[33m(possibly something is already running there)\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mself\u001b[39m.port) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.be_quiet:\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# Issue #26: subprocess.DEVNULL isn't supported in python 2.7.\u001b[39;00m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(subprocess, \u001b[33m'\u001b[39m\u001b[33mDEVNULL\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[31mPermanentlyFailedException\u001b[39m: Error: unable to start the CoreNLP server on port 9000 (possibly something is already running there)"
     ]
    }
   ],
   "source": [
    "from stanza.server import CoreNLPClient\n",
    "\n",
    "text = \"David Batista wrote a blog post on NER evaluation. \" \\\n",
    "       \"Hiroki Nakayama wrote seqeval to evaluate sequential labelling tasks, such as NER. \" \\\n",
    "       \"We will test his library against Stanford Core NLP. \"\n",
    "\n",
    "with CoreNLPClient(\n",
    "     annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse','coref'],\n",
    "     timeout=30000,\n",
    "     memory='6G',\n",
    "     port=3001  # Use a different port to avoid conflicts\n",
    ") as client:\n",
    "    \n",
    "    ann = client.annotate(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27657787",
   "metadata": {
    "papermill": {
     "duration": 0.073188,
     "end_time": "2022-04-07T12:59:11.379679",
     "exception": false,
     "start_time": "2022-04-07T12:59:11.306491",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We get 3 sentences out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ca28fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T12:59:11.534658Z",
     "iopub.status.busy": "2022-04-07T12:59:11.533863Z",
     "iopub.status.idle": "2022-04-07T12:59:11.538234Z",
     "shell.execute_reply": "2022-04-07T12:59:11.537672Z",
     "shell.execute_reply.started": "2022-04-07T12:50:29.701187Z"
    },
    "papermill": {
     "duration": 0.083411,
     "end_time": "2022-04-07T12:59:11.538434",
     "exception": false,
     "start_time": "2022-04-07T12:59:11.455023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ann' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m \u001b[43mann\u001b[49m.sentence:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join([token.word \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m sentence.token]))\n",
      "\u001b[31mNameError\u001b[39m: name 'ann' is not defined"
     ]
    }
   ],
   "source": [
    "for sentence in ann.sentence:\n",
    "    print(\" \".join([token.word for token in sentence.token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a71d850",
   "metadata": {
    "papermill": {
     "duration": 0.075015,
     "end_time": "2022-04-07T12:59:11.688350",
     "exception": false,
     "start_time": "2022-04-07T12:59:11.613335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It can even do clever things like coreference resolution; resolving that \"his library\" refers to \"Hiroki Nakayama's library\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15c591e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T12:59:11.844039Z",
     "iopub.status.busy": "2022-04-07T12:59:11.843369Z",
     "iopub.status.idle": "2022-04-07T12:59:11.847528Z",
     "shell.execute_reply": "2022-04-07T12:59:11.848178Z",
     "shell.execute_reply.started": "2022-04-07T12:50:29.708506Z"
    },
    "papermill": {
     "duration": 0.081987,
     "end_time": "2022-04-07T12:59:11.848387",
     "exception": false,
     "start_time": "2022-04-07T12:59:11.766400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nakayama', 'his']\n"
     ]
    }
   ],
   "source": [
    "for chain in ann.corefChain:\n",
    "    print([ann.mentionsForCoref[mention.mentionID].headString for mention in chain.mention])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1942b0",
   "metadata": {
    "papermill": {
     "duration": 0.074006,
     "end_time": "2022-04-07T12:59:11.997611",
     "exception": false,
     "start_time": "2022-04-07T12:59:11.923605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can extract things such as lemmas, parts of speech and standard NER tags.\n",
    "\n",
    "But we want to train our own NER model to detect ingredients. First we will need to collect the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb5b69e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T12:59:12.165040Z",
     "iopub.status.busy": "2022-04-07T12:59:12.156660Z",
     "iopub.status.idle": "2022-04-07T12:59:12.184016Z",
     "shell.execute_reply": "2022-04-07T12:59:12.184541Z",
     "shell.execute_reply.started": "2022-04-07T12:50:29.721655Z"
    },
    "papermill": {
     "duration": 0.11083,
     "end_time": "2022-04-07T12:59:12.184757",
     "exception": false,
     "start_time": "2022-04-07T12:59:12.073927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ann' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m tokens = \u001b[43mann\u001b[49m.sentence[\u001b[32m1\u001b[39m].token\n\u001b[32m      5\u001b[39m pd.DataFrame({\u001b[33m'\u001b[39m\u001b[33mword\u001b[39m\u001b[33m'\u001b[39m: [s.word \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m tokens],\n\u001b[32m      6\u001b[39m               \u001b[33m'\u001b[39m\u001b[33mlemma\u001b[39m\u001b[33m'\u001b[39m: [s.lemma \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m tokens],\n\u001b[32m      7\u001b[39m               \u001b[33m'\u001b[39m\u001b[33mpos\u001b[39m\u001b[33m'\u001b[39m: [s.pos \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m tokens],\n\u001b[32m      8\u001b[39m               \u001b[33m'\u001b[39m\u001b[33mner\u001b[39m\u001b[33m'\u001b[39m: [s.ner \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m tokens]}).T\n",
      "\u001b[31mNameError\u001b[39m: name 'ann' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tokens = ann.sentence[1].token\n",
    "\n",
    "pd.DataFrame({'word': [s.word for s in tokens],\n",
    "              'lemma': [s.lemma for s in tokens],\n",
    "              'pos': [s.pos for s in tokens],\n",
    "              'ner': [s.ner for s in tokens]}).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c281d3",
   "metadata": {
    "papermill": {
     "duration": 0.074855,
     "end_time": "2022-04-07T12:59:12.333648",
     "exception": false,
     "start_time": "2022-04-07T12:59:12.258793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Get Data\n",
    "\n",
    "Helpfully the authors provide the annotated ingredients data in the format for Stanford NER that we can download [from github](https://github.com/cosylabiiit/recipe-knowledge-mining).\n",
    "\n",
    "There are two sources of ingredients, `ar` is AllRecipes and `gk` is  FOOD.com (formerly GeniusKitchen.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04edd65b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-07T12:59:12.498569Z",
     "iopub.status.busy": "2022-04-07T12:59:12.497854Z",
     "iopub.status.idle": "2022-04-07T12:59:14.808353Z",
     "shell.execute_reply": "2022-04-07T12:59:14.807269Z",
     "shell.execute_reply.started": "2022-04-07T12:50:29.755893Z"
    },
    "papermill": {
     "duration": 2.400074,
     "end_time": "2022-04-07T12:59:14.808574",
     "exception": false,
     "start_time": "2022-04-07T12:59:12.408500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "data_sources = ['ar', 'gk']\n",
    "data_splits = ['train', 'test']\n",
    "\n",
    "base_url = 'https://raw.githubusercontent.com/cosylabiiit/recipe-knowledge-mining/master/'\n",
    "\n",
    "def data_filename(source, split):\n",
    "    return f'{source}_{split}.tsv'\n",
    "\n",
    "for source in data_sources:\n",
    "    for split in data_splits:\n",
    "        name = data_filename(source, split)\n",
    "        urlretrieve(base_url + name, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c260e5f",
   "metadata": {
    "papermill": {
     "duration": 0.073279,
     "end_time": "2022-04-07T12:59:14.957042",
     "exception": false,
     "start_time": "2022-04-07T12:59:14.883763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Each line of the file is either a single tab (separating different texts), or a token followed by a tab and then the entity type.\n",
    "\n",
    "So for example the first ingredient is `4 cloves garlic`, which is a quantity (4) followed by a unit (cloves) and a name (garlic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20fd23c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T12:59:15.124352Z",
     "iopub.status.busy": "2022-04-07T12:59:15.122955Z",
     "iopub.status.idle": "2022-04-07T12:59:15.897018Z",
     "shell.execute_reply": "2022-04-07T12:59:15.897645Z",
     "shell.execute_reply.started": "2022-04-07T12:50:32.106713Z"
    },
    "papermill": {
     "duration": 0.866332,
     "end_time": "2022-04-07T12:59:15.897874",
     "exception": false,
     "start_time": "2022-04-07T12:59:15.031542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'head' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!head {data_filename('ar', 'train')} | cat -t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5b9b7d",
   "metadata": {
    "papermill": {
     "duration": 0.077612,
     "end_time": "2022-04-07T12:59:16.051180",
     "exception": false,
     "start_time": "2022-04-07T12:59:15.973568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can read this in to Python, converting it to a list of annotated sentences, which is just a sequence of token, label pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3682be8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T12:59:16.206078Z",
     "iopub.status.busy": "2022-04-07T12:59:16.204972Z",
     "iopub.status.idle": "2022-04-07T12:59:16.214225Z",
     "shell.execute_reply": "2022-04-07T12:59:16.214726Z",
     "shell.execute_reply.started": "2022-04-07T12:50:32.911852Z"
    },
    "papermill": {
     "duration": 0.089243,
     "end_time": "2022-04-07T12:59:16.214969",
     "exception": false,
     "start_time": "2022-04-07T12:59:16.125726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Generator\n",
    "\n",
    "Annotation = Tuple[str, str]\n",
    "AnnotatedSentence = List[Annotation]\n",
    "\n",
    "def segment_texts(data: str) -> Generator[AnnotatedSentence, None, None]:\n",
    "    output = []\n",
    "    for line in data.split('\\n'):\n",
    "        if line.strip():\n",
    "            text, token = line.split('\\t')\n",
    "            output.append((text.strip(), token.strip()))\n",
    "        elif output:\n",
    "            yield output\n",
    "            output = []\n",
    "            \n",
    "def segment_file(filename: str) -> List[AnnotatedSentence]:\n",
    "    with open(filename, 'rt') as f:\n",
    "        return list(segment_texts(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "411d8e65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T12:59:16.373155Z",
     "iopub.status.busy": "2022-04-07T12:59:16.371969Z",
     "iopub.status.idle": "2022-04-07T12:59:16.388214Z",
     "shell.execute_reply": "2022-04-07T12:59:16.388796Z",
     "shell.execute_reply.started": "2022-04-07T12:50:32.921731Z"
    },
    "papermill": {
     "duration": 0.0992,
     "end_time": "2022-04-07T12:59:16.389053",
     "exception": false,
     "start_time": "2022-04-07T12:59:16.289853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ar_train = segment_file(data_filename('ar', 'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f048122",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T12:59:16.545563Z",
     "iopub.status.busy": "2022-04-07T12:59:16.544455Z",
     "iopub.status.idle": "2022-04-07T12:59:16.551302Z",
     "shell.execute_reply": "2022-04-07T12:59:16.551951Z",
     "shell.execute_reply.started": "2022-04-07T12:50:32.947480Z"
    },
    "papermill": {
     "duration": 0.087288,
     "end_time": "2022-04-07T12:59:16.552158",
     "exception": false,
     "start_time": "2022-04-07T12:59:16.464870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('4', 'QUANTITY'), ('cloves', 'UNIT'), ('garlic', 'NAME')],\n",
       " [('2', 'QUANTITY'),\n",
       "  ('tablespoons', 'UNIT'),\n",
       "  ('vegetable', 'NAME'),\n",
       "  ('oil', 'NAME'),\n",
       "  (',', 'O'),\n",
       "  ('divided', 'STATE')]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dcacf1",
   "metadata": {
    "papermill": {
     "duration": 0.07699,
     "end_time": "2022-04-07T12:59:16.705265",
     "exception": false,
     "start_time": "2022-04-07T12:59:16.628275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can then calculate the number of sentences in the training set for a source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "170a4c27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T12:59:16.860723Z",
     "iopub.status.busy": "2022-04-07T12:59:16.859821Z",
     "iopub.status.idle": "2022-04-07T12:59:16.863539Z",
     "shell.execute_reply": "2022-04-07T12:59:16.864041Z",
     "shell.execute_reply.started": "2022-04-07T12:50:32.954556Z"
    },
    "papermill": {
     "duration": 0.084373,
     "end_time": "2022-04-07T12:59:16.864216",
     "exception": false,
     "start_time": "2022-04-07T12:59:16.779843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1470"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ar_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76312b92",
   "metadata": {
    "papermill": {
     "duration": 0.076091,
     "end_time": "2022-04-07T12:59:17.014758",
     "exception": false,
     "start_time": "2022-04-07T12:59:16.938667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can use this to check the types of entities annotated, as in the paper (DF is Dried/Fresh)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1142681f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T12:59:17.175245Z",
     "iopub.status.busy": "2022-04-07T12:59:17.174209Z",
     "iopub.status.idle": "2022-04-07T12:59:17.178876Z",
     "shell.execute_reply": "2022-04-07T12:59:17.178340Z",
     "shell.execute_reply.started": "2022-04-07T12:50:32.968592Z"
    },
    "papermill": {
     "duration": 0.089217,
     "end_time": "2022-04-07T12:59:17.179088",
     "exception": false,
     "start_time": "2022-04-07T12:59:17.089871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'NAME': 2501,\n",
       "         'O': 1662,\n",
       "         'QUANTITY': 1583,\n",
       "         'UNIT': 1338,\n",
       "         'STATE': 879,\n",
       "         'DF': 154,\n",
       "         'SIZE': 64,\n",
       "         'TEMP': 31})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tag_counts = Counter([annotation[1] for sentence in ar_train for annotation in sentence])\n",
    "tag_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677e4069",
   "metadata": {
    "papermill": {
     "duration": 0.073955,
     "end_time": "2022-04-07T12:59:17.327416",
     "exception": false,
     "start_time": "2022-04-07T12:59:17.253461",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train NER Model\n",
    "\n",
    "Now we want to train a Stanford NER model on the new annotations.\n",
    "\n",
    "First we have to configure it; but there's no information on the paper on how it's configured.\n",
    "I've copied this template configuration out of the [FAQ](https://nlp.stanford.edu/software/crf-faq.html)\n",
    "For more information on the parameters you can check the [NERFeatureFactory documentation](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/ie/NERFeatureFactory.html) or the [source](https://github.com/stanfordnlp/CoreNLP/blob/main/src/edu/stanford/nlp/ie/NERFeatureFactory.java)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59a6e2c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T12:59:17.491773Z",
     "iopub.status.busy": "2022-04-07T12:59:17.490773Z",
     "iopub.status.idle": "2022-04-07T12:59:17.497225Z",
     "shell.execute_reply": "2022-04-07T12:59:17.497813Z",
     "shell.execute_reply.started": "2022-04-07T12:50:32.983052Z"
    },
    "papermill": {
     "duration": 0.092886,
     "end_time": "2022-04-07T12:59:17.498022",
     "exception": false,
     "start_time": "2022-04-07T12:59:17.405136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ner_prop_str(train_files: List[str], test_files: List[str], output: str) -> str:\n",
    "    \"\"\"Returns configuration string to train NER model\"\"\"\n",
    "    train_file_str = ','.join(train_files)\n",
    "    test_file_str = ','.join(test_files)\n",
    "    return f\"\"\"\n",
    "trainFileList = {train_file_str}\n",
    "testFiles = {test_file_str}\n",
    "serializeTo = {output}\n",
    "map = word=0,answer=1\n",
    "\n",
    "useClassFeature=true\n",
    "useWord=true\n",
    "useNGrams=true\n",
    "noMidNGrams=true\n",
    "maxNGramLeng=6\n",
    "usePrev=true\n",
    "useNext=true\n",
    "useSequences=true\n",
    "usePrevSequences=true\n",
    "maxLeft=1\n",
    "useTypeSeqs=true\n",
    "useTypeSeqs2=true\n",
    "useTypeySequences=true\n",
    "wordShape=chris2useLC\n",
    "useDisjunctive=true\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207441dc",
   "metadata": {
    "papermill": {
     "duration": 0.075391,
     "end_time": "2022-04-07T12:59:17.650533",
     "exception": false,
     "start_time": "2022-04-07T12:59:17.575142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is expected to be a file, so let's write a helper that writes it to a file. (An alternative would be to pass these as arguments to the trainer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9e7eb79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T12:59:17.812064Z",
     "iopub.status.busy": "2022-04-07T12:59:17.810962Z",
     "iopub.status.idle": "2022-04-07T12:59:17.816510Z",
     "shell.execute_reply": "2022-04-07T12:59:17.817089Z",
     "shell.execute_reply.started": "2022-04-07T12:50:32.994122Z"
    },
    "papermill": {
     "duration": 0.087414,
     "end_time": "2022-04-07T12:59:17.817303",
     "exception": false,
     "start_time": "2022-04-07T12:59:17.729889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_ner_prop_file(ner_prop_file: str, train_files: List[str], test_files: List[str], output_file: str) -> None:\n",
    "    with open(ner_prop_file, 'wt') as f:\n",
    "        props = ner_prop_str(train_files, test_files, output_file)\n",
    "        f.write(props)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec3df3",
   "metadata": {
    "papermill": {
     "duration": 0.075681,
     "end_time": "2022-04-07T12:59:17.970722",
     "exception": false,
     "start_time": "2022-04-07T12:59:17.895041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Stanza doesn't give an interface to train a CRF NER model using Stanford NLP, but we can invoke `edu.stanford.nlp.ie.crf.CRFClassifier` directly.\n",
    "\n",
    "Let's write a properties file and invoke Java to run the classifier.\n",
    "It prints a lot of training information, and importantly a summary report at the end which we want to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d0cb59c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T12:59:18.128663Z",
     "iopub.status.busy": "2022-04-07T12:59:18.127603Z",
     "iopub.status.idle": "2022-04-07T12:59:18.136205Z",
     "shell.execute_reply": "2022-04-07T12:59:18.136742Z",
     "shell.execute_reply.started": "2022-04-07T12:50:33.006937Z"
    },
    "papermill": {
     "duration": 0.089125,
     "end_time": "2022-04-07T12:59:18.136964",
     "exception": false,
     "start_time": "2022-04-07T12:59:18.047839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from typing import List\n",
    "\n",
    "def train_model(model_name, train_files: List[str], test_files: List[str], print_report=True, classpath=classpath) -> str:\n",
    "    \"\"\"Trains CRF NER Model using StanfordNLP\"\"\"\n",
    "    model_file = f'{model_name}.model.ser.gz'\n",
    "    ner_prop_filename = f'{model_name}.model.props'\n",
    "    write_ner_prop_file(ner_prop_filename, train_files, test_files, model_file)\n",
    "        \n",
    "    result = subprocess.run(\n",
    "                ['java',\n",
    "                 '-Xmx2g',\n",
    "                 '-cp', classpath,\n",
    "                 'edu.stanford.nlp.ie.crf.CRFClassifier',\n",
    "                 '-prop', ner_prop_filename],\n",
    "                capture_output=True)\n",
    "    \n",
    "    # If there's an error with invocation better log the stacktrace\n",
    "    if result.returncode != 0:\n",
    "        print(result.stderr.decode('utf-8'))\n",
    "    result.check_returncode()\n",
    "    \n",
    "    if print_report:\n",
    "        print(*result.stderr.decode('utf-8').split('\\n')[-11:], sep='\\n')\n",
    "        \n",
    "    return model_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9936f352",
   "metadata": {
    "papermill": {
     "duration": 0.074215,
     "end_time": "2022-04-07T12:59:18.286972",
     "exception": false,
     "start_time": "2022-04-07T12:59:18.212757",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can train models on each dataset separately, and all together.\n",
    "For evaluation we'll use the corresponding test set.\n",
    "\n",
    "This only takes a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8232dd04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T12:59:18.443591Z",
     "iopub.status.busy": "2022-04-07T12:59:18.442776Z",
     "iopub.status.idle": "2022-04-07T13:01:35.835973Z",
     "shell.execute_reply": "2022-04-07T13:01:35.836649Z",
     "shell.execute_reply.started": "2022-04-07T12:50:33.017883Z"
    },
    "papermill": {
     "duration": 137.47581,
     "end_time": "2022-04-07T13:01:35.836960",
     "exception": false,
     "start_time": "2022-04-07T12:59:18.361150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar\n",
      "CRFClassifier tagged 2788 words in 483 documents at 3295.51 words per second.\n",
      "         Entity\tP\tR\tF1\tTP\tFP\tFN\n",
      "             DF\t1.0000\t0.9608\t0.9800\t49\t0\t2\n",
      "           NAME\t0.9297\t0.9279\t0.9288\t463\t35\t36\n",
      "       QUANTITY\t1.0000\t0.9962\t0.9981\t522\t0\t2\n",
      "           SIZE\t1.0000\t1.0000\t1.0000\t20\t0\t0\n",
      "          STATE\t0.9601\t0.9633\t0.9617\t289\t12\t11\n",
      "           TEMP\t0.8750\t0.7000\t0.7778\t7\t1\t3\n",
      "           UNIT\t0.9819\t0.9841\t0.9830\t434\t8\t7\n",
      "         Totals\t0.9696\t0.9669\t0.9682\t1784\t56\t61\n",
      "\n",
      "\n",
      "gk\n",
      "CRFClassifier tagged 9886 words in 1705 documents at 9701.67 words per second.\n",
      "         Entity\tP\tR\tF1\tTP\tFP\tFN\n",
      "             DF\t0.9718\t0.9517\t0.9617\t138\t4\t7\n",
      "           NAME\t0.9132\t0.9021\t0.9076\t1621\t154\t176\n",
      "       QUANTITY\t0.9882\t0.9870\t0.9876\t1598\t19\t21\n",
      "           SIZE\t0.9750\t0.9398\t0.9571\t78\t2\t5\n",
      "          STATE\t0.9255\t0.9503\t0.9377\t708\t57\t37\n",
      "           TEMP\t0.8125\t0.8125\t0.8125\t26\t6\t6\n",
      "           UNIT\t0.9810\t0.9721\t0.9766\t1291\t25\t37\n",
      "         Totals\t0.9534\t0.9497\t0.9516\t5460\t267\t289\n",
      "\n",
      "\n",
      "ar_gk\n",
      "CRFClassifier tagged 12674 words in 2188 documents at 8645.29 words per second.\n",
      "         Entity\tP\tR\tF1\tTP\tFP\tFN\n",
      "             DF\t0.9738\t0.9490\t0.9612\t186\t5\t10\n",
      "           NAME\t0.9136\t0.9077\t0.9106\t2084\t197\t212\n",
      "       QUANTITY\t0.9911\t0.9897\t0.9904\t2121\t19\t22\n",
      "           SIZE\t0.9798\t0.9417\t0.9604\t97\t2\t6\n",
      "          STATE\t0.9386\t0.9512\t0.9449\t994\t65\t51\n",
      "           TEMP\t0.8140\t0.8333\t0.8235\t35\t8\t7\n",
      "           UNIT\t0.9801\t0.9763\t0.9782\t1727\t35\t42\n",
      "         Totals\t0.9563\t0.9539\t0.9551\t7244\t331\t350\n",
      "\n",
      "\n",
      "CPU times: total: 172 ms\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "models = {}\n",
    "for source in ['ar', 'gk', 'ar_gk']:\n",
    "    print(source)\n",
    "    train_files = [data_filename(s, 'train') for s in source.split('_')]\n",
    "    test_files = [data_filename(s, 'test') for s in source.split('_')]\n",
    "    models[source] = train_model(source, train_files, test_files)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f6f0c9",
   "metadata": {
    "papermill": {
     "duration": 0.077949,
     "end_time": "2022-04-07T13:01:35.992806",
     "exception": false,
     "start_time": "2022-04-07T13:01:35.914857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The summary report shows for each model and entity type:\n",
    "\n",
    "* True Positives (TP): The number of times that entity was predicted correctly\n",
    "* False Positives (FP): The number of times that entity in the text but not predicted correctly\n",
    "* False Negative (FN): The number of times that entity was not in the text and predicted\n",
    "* Precision (P): Probability a predicted entity is correct, TP/(TP+FP)\n",
    "* Recall (R): Probability a correct entity is predicted, TP/(TP+FN)\n",
    "* F1 Score (F1): Harmonic mean of precision and recall, 2/(1/P + 1/R).\n",
    "\n",
    "We can compare the F1 Totals to the diagonal of Table IV in the paper\n",
    "\n",
    "* AllRecipes.com (ar): We get 0.9682, they report 0.9682\n",
    "* FOOD.com (gk): We get 0.9516, they report 0.9519\n",
    "* Both (ar_gk): We get 0.9551, they report 0.9611\n",
    "\n",
    "These are super close.\n",
    "The furthest is `ar_gk` and in the repository they have a separate `ar_gk_train.tsv`; it would be interesting to check whether using it directly gives a closer result and why there is a difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54563997",
   "metadata": {
    "papermill": {
     "duration": 0.0776,
     "end_time": "2022-04-07T13:01:36.149703",
     "exception": false,
     "start_time": "2022-04-07T13:01:36.072103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Running the model in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2def70",
   "metadata": {
    "papermill": {
     "duration": 0.076927,
     "end_time": "2022-04-07T13:01:36.304500",
     "exception": false,
     "start_time": "2022-04-07T13:01:36.227573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can now use these trained models in Python by invoking Stanford NLP with Stanza.\n",
    "\n",
    "First we'll load in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0564ac40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T13:01:36.466360Z",
     "iopub.status.busy": "2022-04-07T13:01:36.465286Z",
     "iopub.status.idle": "2022-04-07T13:01:36.487026Z",
     "shell.execute_reply": "2022-04-07T13:01:36.487684Z",
     "shell.execute_reply.started": "2022-04-07T12:52:33.237540Z"
    },
    "papermill": {
     "duration": 0.105083,
     "end_time": "2022-04-07T13:01:36.487888",
     "exception": false,
     "start_time": "2022-04-07T13:01:36.382805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar 483\n",
      "gk 1705\n"
     ]
    }
   ],
   "source": [
    "test_data = {}\n",
    "\n",
    "for source in data_sources:\n",
    "    test_data[source] = segment_file(data_filename(source, 'test'))\n",
    "    print(source, len(test_data[source]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e03b03d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T23:58:43.359429Z",
     "iopub.status.busy": "2022-04-06T23:58:43.359055Z",
     "iopub.status.idle": "2022-04-06T23:58:43.365707Z",
     "shell.execute_reply": "2022-04-06T23:58:43.36474Z",
     "shell.execute_reply.started": "2022-04-06T23:58:43.35939Z"
    },
    "papermill": {
     "duration": 0.078031,
     "end_time": "2022-04-07T13:01:36.643468",
     "exception": false,
     "start_time": "2022-04-07T13:01:36.565437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can call StanfordNLP with our custom model by passing the property `ner.model`.\n",
    "\n",
    "Our test data is already tokenized in a different way to StanfordNLP, so we'll add an option to the [Tokenizer](https://stanfordnlp.github.io/CoreNLP/tokenize.html) to use whitespace tokenization which is easy to invert.\n",
    "\n",
    "It takes a while to start up the server so we want to annotate a large number of texts at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "175dca12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "from stanza.server import CoreNLPClient  # Add this import\n",
    "from tqdm import tqdm  # Also add this for the tqdm function\n",
    "\n",
    "def annotate_ner_robust(ner_model_file: str, texts: List[str], tokenize_whitespace: bool = True):\n",
    "    \"\"\"A more robust version of annotate_ner that handles port conflicts better\"\"\"\n",
    "    \n",
    "    # 1. First, try to kill any lingering Java processes that might be using ports\n",
    "    try:\n",
    "        subprocess.run(['taskkill', '/F', '/IM', 'java.exe'], capture_output=True)\n",
    "        time.sleep(2)  # Give system time to release resources\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not kill Java processes: {e}\")\n",
    "    \n",
    "    # 2. Generate random, high-numbered ports to avoid conflicts\n",
    "    server_port = random.randint(20000, 50000)\n",
    "    control_port = server_port + 1000  # Keep these well separated\n",
    "    \n",
    "    print(f\"Trying server port: {server_port}, control port: {control_port}\")\n",
    "    \n",
    "    # 3. Set additional parameters to avoid issues\n",
    "    properties = {\n",
    "        \"ner.model\": ner_model_file, \n",
    "        \"tokenize.whitespace\": tokenize_whitespace, \n",
    "        \"ner.applyNumericClassifiers\": False\n",
    "    }\n",
    "    \n",
    "    annotated = []\n",
    "    with CoreNLPClient(\n",
    "         annotators=['tokenize','ssplit','ner'],\n",
    "         properties=properties,\n",
    "         timeout=60000,  # Longer timeout\n",
    "         be_quiet=True,\n",
    "         port=server_port,\n",
    "         start_server=True,\n",
    "         control_port=control_port,\n",
    "         preload=False,  # Don't preload models\n",
    "         memory='4G',    # Use less memory\n",
    "         endpoint=f'http://localhost:{server_port}') as client:  # Include port in endpoint URL\n",
    "        \n",
    "        print(\"Server successfully started!\")\n",
    "        \n",
    "        for text in tqdm(texts):\n",
    "            annotated.append(client.annotate(text))\n",
    "            \n",
    "    return annotated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392be996",
   "metadata": {
    "papermill": {
     "duration": 0.077305,
     "end_time": "2022-04-07T13:01:36.971129",
     "exception": false,
     "start_time": "2022-04-07T13:01:36.893824",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can then get the annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2b52eb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T13:01:37.136508Z",
     "iopub.status.busy": "2022-04-07T13:01:37.135776Z",
     "iopub.status.idle": "2022-04-07T13:01:51.580370Z",
     "shell.execute_reply": "2022-04-07T13:01:51.579773Z",
     "shell.execute_reply.started": "2022-04-07T12:52:33.268568Z"
    },
    "papermill": {
     "duration": 14.527687,
     "end_time": "2022-04-07T13:01:51.580543",
     "exception": false,
     "start_time": "2022-04-07T13:01:37.052856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-17 19:37:19 WARNING: Setting 'start_server' to a boolean value when constructing CoreNLPClient is deprecated and will stop to function in a future version of stanza. Please consider switching to using a value from stanza.server.StartServer.\n",
      "2025-05-17 19:37:19 INFO: Writing properties to tmp file: corenlp_server-fdde4fae98604f80.props\n",
      "2025-05-17 19:37:19 INFO: Starting server with command: java -Xmx4G -cp C:\\Users\\Helena\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 32637 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-fdde4fae98604f80.props -annotators tokenize,ssplit,ner -outputFormat serialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying server port: 32637, control port: 33637\n",
      "Server successfully started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:17<00:00,  4.31s/it]\n"
     ]
    }
   ],
   "source": [
    "from stanza.server import CoreNLPClient\n",
    "\n",
    "annotations = annotate_ner_robust(models['ar'],\n",
    "                           [   \"- 30 g of sweet potato\",\n",
    "\"- 20 g of edamame\",\n",
    "\"- 5 g of cornstarch\" ,\n",
    "\"- A small bit of water\",\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb072c0",
   "metadata": {
    "papermill": {
     "duration": 0.077157,
     "end_time": "2022-04-07T13:01:51.736018",
     "exception": false,
     "start_time": "2022-04-07T13:01:51.658861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note here that the word \"Italian\" has ner \"NATIONALITY\", which comes from another model (it wasn't in the training set!).\n",
    "\n",
    "We want to use the `coarseNER`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f65e5d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T13:01:51.899603Z",
     "iopub.status.busy": "2022-04-07T13:01:51.898653Z",
     "iopub.status.idle": "2022-04-07T13:01:51.902411Z",
     "shell.execute_reply": "2022-04-07T13:01:51.902921Z",
     "shell.execute_reply.started": "2022-04-07T12:52:46.398492Z"
    },
    "papermill": {
     "duration": 0.088481,
     "end_time": "2022-04-07T13:01:51.903104",
     "exception": false,
     "start_time": "2022-04-07T13:01:51.814623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word: \"pancetta\"\n",
       "pos: \"NN\"\n",
       "value: \"pancetta\"\n",
       "originalText: \"pancetta\"\n",
       "ner: \"NAME\"\n",
       "lemma: \"pancetta\"\n",
       "beginChar: 10\n",
       "endChar: 18\n",
       "tokenBeginIndex: 2\n",
       "tokenEndIndex: 3\n",
       "hasXmlContext: false\n",
       "isNewline: false\n",
       "coarseNER: \"NAME\"\n",
       "fineGrainedNER: \"NAME\"\n",
       "entityMentionIndex: 2\n",
       "nerLabelProbs: \"NAME=0.925096306225114\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[2].sentence[0].token[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5113166",
   "metadata": {
    "papermill": {
     "duration": 0.077775,
     "end_time": "2022-04-07T13:01:52.059609",
     "exception": false,
     "start_time": "2022-04-07T13:01:51.981834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When I didn't set `\"ner.applyNumericClassifiers\": False` this would come up as a `NUMBER`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa0cfe7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T13:01:52.223603Z",
     "iopub.status.busy": "2022-04-07T13:01:52.222675Z",
     "iopub.status.idle": "2022-04-07T13:01:52.226917Z",
     "shell.execute_reply": "2022-04-07T13:01:52.226383Z",
     "shell.execute_reply.started": "2022-04-07T12:52:46.408128Z"
    },
    "papermill": {
     "duration": 0.089989,
     "end_time": "2022-04-07T13:01:52.227089",
     "exception": false,
     "start_time": "2022-04-07T13:01:52.137100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word: \"3\"\n",
       "pos: \"CD\"\n",
       "value: \"3\"\n",
       "originalText: \"3\"\n",
       "ner: \"O\"\n",
       "lemma: \"3\"\n",
       "beginChar: 20\n",
       "endChar: 21\n",
       "tokenBeginIndex: 3\n",
       "tokenEndIndex: 4\n",
       "hasXmlContext: false\n",
       "isNewline: false\n",
       "coarseNER: \"O\"\n",
       "fineGrainedNER: \"O\"\n",
       "nerLabelProbs: \"O=0.8599875707736956\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[3].sentence[0].token[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffc242b",
   "metadata": {
    "papermill": {
     "duration": 0.078642,
     "end_time": "2022-04-07T13:01:52.389005",
     "exception": false,
     "start_time": "2022-04-07T13:01:52.310363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can then flatten the sentences and extract the NER tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16628086",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T13:01:52.593218Z",
     "iopub.status.busy": "2022-04-07T13:01:52.587639Z",
     "iopub.status.idle": "2022-04-07T13:01:52.596815Z",
     "shell.execute_reply": "2022-04-07T13:01:52.597409Z",
     "shell.execute_reply.started": "2022-04-07T12:52:46.420198Z"
    },
    "papermill": {
     "duration": 0.109423,
     "end_time": "2022-04-07T13:01:52.597623",
     "exception": false,
     "start_time": "2022-04-07T13:01:52.488200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "@dataclass\n",
    "class NERData:\n",
    "    ner: List[str]\n",
    "    tokens: List[str]\n",
    "        \n",
    "    # Let's use Pandas to make it pretty in a notebook\n",
    "    def _repr_html_(self):\n",
    "        return pd.DataFrame(asdict(self)).T._repr_html_()\n",
    "\n",
    "def extract_ner_data(annotation) -> NERData:\n",
    "    tokens = [token for sentence in annotation.sentence for token in sentence.token]\n",
    "    return NERData(tokens=[t.word for t in tokens], ner=[t.coarseNER for t in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ef7ddd",
   "metadata": {
    "papermill": {
     "duration": 0.079568,
     "end_time": "2022-04-07T13:01:52.761448",
     "exception": false,
     "start_time": "2022-04-07T13:01:52.681880",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A relatively simple ingredient works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d4dd5cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T13:01:52.923565Z",
     "iopub.status.busy": "2022-04-07T13:01:52.922824Z",
     "iopub.status.idle": "2022-04-07T13:01:52.934377Z",
     "shell.execute_reply": "2022-04-07T13:01:52.934830Z",
     "shell.execute_reply.started": "2022-04-07T12:52:46.431673Z"
    },
    "papermill": {
     "duration": 0.094408,
     "end_time": "2022-04-07T13:01:52.935033",
     "exception": false,
     "start_time": "2022-04-07T13:01:52.840625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ner</th>\n",
       "      <td>QUANTITY</td>\n",
       "      <td>UNIT</td>\n",
       "      <td>O</td>\n",
       "      <td>TEMP</td>\n",
       "      <td>NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>1</td>\n",
       "      <td>cup</td>\n",
       "      <td>of</td>\n",
       "      <td>frozen</td>\n",
       "      <td>peas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "NERData(ner=['QUANTITY', 'UNIT', 'O', 'TEMP', 'NAME'], tokens=['1', 'cup', 'of', 'frozen', 'peas'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_ner_data(annotations[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68d4ab6",
   "metadata": {
    "papermill": {
     "duration": 0.080341,
     "end_time": "2022-04-07T13:01:53.095739",
     "exception": false,
     "start_time": "2022-04-07T13:01:53.015398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A more complex sentence does quite badly, perhaps because this kind of thing wasn't seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84662f1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T13:01:53.259562Z",
     "iopub.status.busy": "2022-04-07T13:01:53.258809Z",
     "iopub.status.idle": "2022-04-07T13:01:53.269051Z",
     "shell.execute_reply": "2022-04-07T13:01:53.269619Z",
     "shell.execute_reply.started": "2022-04-07T12:52:46.452987Z"
    },
    "papermill": {
     "duration": 0.094219,
     "end_time": "2022-04-07T13:01:53.269840",
     "exception": false,
     "start_time": "2022-04-07T13:01:53.175621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ner</th>\n",
       "      <td>QUANTITY</td>\n",
       "      <td>UNIT</td>\n",
       "      <td>NAME</td>\n",
       "      <td>NAME</td>\n",
       "      <td>NAME</td>\n",
       "      <td>NAME</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>A</td>\n",
       "      <td>dash</td>\n",
       "      <td>of</td>\n",
       "      <td>salt</td>\n",
       "      <td>.</td>\n",
       "      <td>Or</td>\n",
       "      <td>to</td>\n",
       "      <td>taste</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "NERData(ner=['QUANTITY', 'UNIT', 'NAME', 'NAME', 'NAME', 'NAME', 'O', 'O'], tokens=['A', 'dash', 'of', 'salt', '.', 'Or', 'to', 'taste'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_ner_data(annotations[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e85ccce9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T13:01:53.436990Z",
     "iopub.status.busy": "2022-04-07T13:01:53.436294Z",
     "iopub.status.idle": "2022-04-07T13:01:53.445951Z",
     "shell.execute_reply": "2022-04-07T13:01:53.446566Z",
     "shell.execute_reply.started": "2022-04-07T12:52:46.468618Z"
    },
    "papermill": {
     "duration": 0.094843,
     "end_time": "2022-04-07T13:01:53.446783",
     "exception": false,
     "start_time": "2022-04-07T13:01:53.351940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ner</th>\n",
       "      <td>QUANTITY</td>\n",
       "      <td>UNIT</td>\n",
       "      <td>STATE</td>\n",
       "      <td>NAME</td>\n",
       "      <td>NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>1/2</td>\n",
       "      <td>teaspoon</td>\n",
       "      <td>ground</td>\n",
       "      <td>black</td>\n",
       "      <td>pepper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "NERData(ner=['QUANTITY', 'UNIT', 'STATE', 'NAME', 'NAME'], tokens=['1/2', 'teaspoon', 'ground', 'black', 'pepper'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_ner_data(annotations[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "315981a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingredient names: ['peas']\n"
     ]
    }
   ],
   "source": [
    "def extract_ingredient_names(ner_data):\n",
    "    \"\"\"\n",
    "    Extract only the ingredient names from NER data.\n",
    "    If names appear in consecutive tokens, join them together.\n",
    "    \n",
    "    Args:\n",
    "        ner_data: NERData object returned by extract_ner_data\n",
    "        \n",
    "    Returns:\n",
    "        List of extracted ingredient names (joined if multiple consecutive tokens)\n",
    "    \"\"\"\n",
    "    names = []\n",
    "    current_name = []\n",
    "    \n",
    "    # Zip tokens and NER tags together and iterate\n",
    "    for token, tag in zip(ner_data.tokens, ner_data.ner):\n",
    "        if tag == 'NAME':\n",
    "            current_name.append(token)\n",
    "        elif current_name:  # Not a NAME tag but we have collected name tokens\n",
    "            names.append(' '.join(current_name))\n",
    "            current_name = []\n",
    "    \n",
    "    # Add the last name if there's one at the end of the sequence\n",
    "    if current_name:\n",
    "        names.append(' '.join(current_name))\n",
    "    \n",
    "    return names\n",
    "\n",
    "# Example usage:\n",
    "ingredient_names = extract_ingredient_names(extract_ner_data(annotations[0]))\n",
    "print(f\"Ingredient names: {ingredient_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb8ff877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingredient names: ['peas']\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "ingredient_names = extract_ingredient_names(extract_ner_data(annotations[0]))\n",
    "print(f\"Ingredient names: {ingredient_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e36e55bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: '1 cup of frozen peas'\n",
      "Ingredient names: ['peas']\n",
      "\n",
      "Original: '2 tablespoons olive oil'\n",
      "Ingredient names: ['olive oil']\n",
      "\n",
      "Original: '1/2 teaspoon ground black pepper'\n",
      "Ingredient names: ['black pepper']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Process all annotations and extract ingredient names\n",
    "def process_all_annotations(annotations):\n",
    "    \"\"\"\n",
    "    Process all annotations and extract ingredient names from each one\n",
    "    \n",
    "    Args:\n",
    "        annotations: List of annotation objects returned by annotate_ner_robust\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing original text and extracted ingredient names\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i, annotation in enumerate(annotations):\n",
    "        # Extract NER data\n",
    "        ner_data = extract_ner_data(annotation)\n",
    "        \n",
    "        # Extract ingredient names\n",
    "        names = extract_ingredient_names(ner_data)\n",
    "        \n",
    "        # Add to results\n",
    "        results.append({\n",
    "            \"index\": i,\n",
    "            \"tokens\": ner_data.tokens,\n",
    "            \"ingredient_names\": names\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "all_results = process_all_annotations(annotations)\n",
    "\n",
    "# Print results\n",
    "for result in all_results:\n",
    "    original_text = ' '.join(result['tokens'])\n",
    "    print(f\"Original: '{original_text}'\")\n",
    "    print(f\"Ingredient names: {result['ingredient_names']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6452da29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the end of your model training notebook\n",
    "import pickle\n",
    "\n",
    "# Save models dictionary\n",
    "with open('trained_models.pkl', 'wb') as f:\n",
    "    pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a990176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_names_from_ingredient(ingredient_text, model_file):\n",
    "    \"\"\"\n",
    "    Process an ingredient text and extract only the ingredient names.\n",
    "    \n",
    "    Args:\n",
    "        ingredient_text: String with ingredient text\n",
    "        model_file: Path to the trained NER model\n",
    "        \n",
    "    Returns:\n",
    "        List of ingredient names\n",
    "    \"\"\"\n",
    "    # Make sure to import CoreNLPClient to avoid NameError\n",
    "    from stanza.server import CoreNLPClient\n",
    "    \n",
    "    # Get annotations\n",
    "    annotations = annotate_ner_robust(model_file, [ingredient_text])\n",
    "    \n",
    "    # Process each annotation\n",
    "    if not annotations or annotations[0] is None:\n",
    "        return []\n",
    "    \n",
    "    # Extract NER data\n",
    "    ner_data = extract_ner_data(annotations[0])\n",
    "    \n",
    "    # Extract just the names\n",
    "    return extract_ingredient_names(ner_data)\n",
    "\n",
    "# Example:\n",
    "# names = extract_names_from_ingredient(\"1 cup of frozen peas\", ar_model_file)\n",
    "# print(names)  # Should print [\"peas\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d067bdb5",
   "metadata": {
    "papermill": {
     "duration": 0.080591,
     "end_time": "2022-04-07T13:01:53.610955",
     "exception": false,
     "start_time": "2022-04-07T13:01:53.530364",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can chain these functions together to get from text to NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e1f8e27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T13:01:53.777728Z",
     "iopub.status.busy": "2022-04-07T13:01:53.777006Z",
     "iopub.status.idle": "2022-04-07T13:01:53.782184Z",
     "shell.execute_reply": "2022-04-07T13:01:53.782741Z",
     "shell.execute_reply.started": "2022-04-07T12:52:46.490584Z"
    },
    "papermill": {
     "duration": 0.091584,
     "end_time": "2022-04-07T13:01:53.782964",
     "exception": false,
     "start_time": "2022-04-07T13:01:53.691380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def ner_extract(ner_model_file: str, texts: List[str], tokenize_whitespace: bool = True) -> List[Dict[str, List[str]]]:\n",
    "    annotations = annotate_ner(ner_model_file, texts, tokenize_whitespace)\n",
    "    return [extract_ner_data(ann) for ann in annotations]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d193f3",
   "metadata": {
    "papermill": {
     "duration": 0.081116,
     "end_time": "2022-04-07T13:01:53.944944",
     "exception": false,
     "start_time": "2022-04-07T13:01:53.863828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "And then for each model, and test data we can calculate the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c32ef0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T13:01:54.111985Z",
     "iopub.status.busy": "2022-04-07T13:01:54.111261Z",
     "iopub.status.idle": "2022-04-07T13:06:33.038766Z",
     "shell.execute_reply": "2022-04-07T13:06:33.039358Z",
     "shell.execute_reply.started": "2022-04-07T12:52:46.497380Z"
    },
    "papermill": {
     "duration": 279.012135,
     "end_time": "2022-04-07T13:06:33.039789",
     "exception": false,
     "start_time": "2022-04-07T13:01:54.027654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e07430d6f54a9bbd9acea509197ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae58c17d7a2462dadf527338d943cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c71bb6e43e4330b2b149c25da98d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652276ddba8640708df4285c1ddf5ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87190b2caa46403a82d7cb69319b1262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab8307799ba406e85852cb620015885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = {}\n",
    "for model, modelfile in models.items():\n",
    "    preds[model] = {}\n",
    "    for test_source, token_data in test_data.items():\n",
    "        texts = [' '.join([x[0] for x in text]) for text in token_data]\n",
    "        preds[model][test_source] = ner_extract(modelfile, texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2fdccc",
   "metadata": {
    "papermill": {
     "duration": 0.090737,
     "end_time": "2022-04-07T13:06:33.217549",
     "exception": false,
     "start_time": "2022-04-07T13:06:33.126812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sanity checks\n",
    "\n",
    "Let's check the same tokens come through the model as were input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fc5053e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T13:06:33.412009Z",
     "iopub.status.busy": "2022-04-07T13:06:33.410951Z",
     "iopub.status.idle": "2022-04-07T13:06:33.414218Z",
     "shell.execute_reply": "2022-04-07T13:06:33.413529Z",
     "shell.execute_reply.started": "2022-04-07T12:56:31.467543Z"
    },
    "papermill": {
     "duration": 0.109894,
     "end_time": "2022-04-07T13:06:33.414392",
     "exception": false,
     "start_time": "2022-04-07T13:06:33.304498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for test_source, token_data in test_data.items():\n",
    "    tokens = [[x[0] for x in tokens] for tokens in token_data]\n",
    "    \n",
    "    for model in models:\n",
    "        model_preds = preds[model][test_source]\n",
    "        \n",
    "        model_tokens = [p.tokens for p in model_preds]\n",
    "        \n",
    "        if tokens != model_tokens:\n",
    "            raise ValueError(\"Tokenization issue in %s with model %s\" % (test_source, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384d097b",
   "metadata": {
    "papermill": {
     "duration": 0.086069,
     "end_time": "2022-04-07T13:06:33.585161",
     "exception": false,
     "start_time": "2022-04-07T13:06:33.499092",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluating\n",
    "\n",
    "Now that we have predictions we can evaulate with [seqeval](https://github.com/chakki-works/seqeval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ecad075",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T13:06:33.765716Z",
     "iopub.status.busy": "2022-04-07T13:06:33.764994Z",
     "iopub.status.idle": "2022-04-07T13:06:50.298649Z",
     "shell.execute_reply": "2022-04-07T13:06:50.297970Z",
     "shell.execute_reply.started": "2022-04-07T12:56:31.630845Z"
    },
    "papermill": {
     "duration": 16.624488,
     "end_time": "2022-04-07T13:06:50.298801",
     "exception": false,
     "start_time": "2022-04-07T13:06:33.674313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seqeval\r\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\r\n",
      "     |████████████████████████████████| 43 kB 102 kB/s            \r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from seqeval) (1.20.3)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from seqeval) (1.0.1)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (3.0.0)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\r\n",
      "Building wheels for collected packages: seqeval\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=117220ab957b2dfbf6fad8b7cf7fb429b409f1fb1b62fef7ea14d20e38b36203\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\r\n",
      "Successfully built seqeval\r\n",
      "Installing collected packages: seqeval\r\n",
      "Successfully installed seqeval-1.2.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442daabb",
   "metadata": {
    "papermill": {
     "duration": 0.088059,
     "end_time": "2022-04-07T13:06:50.475096",
     "exception": false,
     "start_time": "2022-04-07T13:06:50.387037",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Seqeval expects the data to be in one of the following formats:\n",
    "\n",
    "* IOB1\n",
    "* IOB2\n",
    "* IOE1\n",
    "* IOE2\n",
    "* IOBES(only in strict mode)\n",
    "* BILOU(only in strict mode)\n",
    "\n",
    "These all become important when trying to distinguish distinct entities that are adjacent; these are quite rare in practice.\n",
    "See Wikipedia for a detailed explanation of [IOB (inside-outside-beginning)](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)).\n",
    "\n",
    "In this case it's assumed there's only one entity of each type (which can be wrong when multiple names are listing in a single ingredient).\n",
    "We can easily convert it to IOB1 using this assumption by prefixing every tag other than 'O' with an 'I-'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "816f82e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T13:06:50.659609Z",
     "iopub.status.busy": "2022-04-07T13:06:50.658619Z",
     "iopub.status.idle": "2022-04-07T13:06:50.661057Z",
     "shell.execute_reply": "2022-04-07T13:06:50.660405Z",
     "shell.execute_reply.started": "2022-04-07T12:56:44.754303Z"
    },
    "papermill": {
     "duration": 0.098039,
     "end_time": "2022-04-07T13:06:50.661208",
     "exception": false,
     "start_time": "2022-04-07T13:06:50.563169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_iob1(tokens):\n",
    "    return ['I-' + label if label != 'O' else 'O' for label in tokens]\n",
    "\n",
    "assert convert_to_iob1(['QUANTITY', 'SIZE', 'NAME', 'NAME', 'O', 'STATE']) == ['I-QUANTITY', 'I-SIZE', 'I-NAME', 'I-NAME', 'O', 'I-STATE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd57cb3",
   "metadata": {
    "papermill": {
     "duration": 0.088945,
     "end_time": "2022-04-07T13:06:50.837958",
     "exception": false,
     "start_time": "2022-04-07T13:06:50.749013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's check the classification report for a single example and compare it to the report from StanfordNER.\n",
    "\n",
    "The classification report doesn't have the TP, TN and FN, but instead has the support - the number of true entities in the data.\n",
    "The set of data is equivalent:\n",
    "\n",
    "* support = TP + FN\n",
    "* TP = R * support\n",
    "* FP = TP (1/P - 1)\n",
    "* FN = support - TP\n",
    "\n",
    "The results are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9bf3fab1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T13:06:51.024498Z",
     "iopub.status.busy": "2022-04-07T13:06:51.023501Z",
     "iopub.status.idle": "2022-04-07T13:06:52.408718Z",
     "shell.execute_reply": "2022-04-07T13:06:52.407592Z",
     "shell.execute_reply.started": "2022-04-07T12:56:44.760756Z"
    },
    "papermill": {
     "duration": 1.482137,
     "end_time": "2022-04-07T13:06:52.408950",
     "exception": false,
     "start_time": "2022-04-07T13:06:50.926813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          DF     1.0000    0.9608    0.9800        51\n",
      "        NAME     0.9297    0.9279    0.9288       499\n",
      "    QUANTITY     1.0000    0.9962    0.9981       524\n",
      "        SIZE     1.0000    1.0000    1.0000        20\n",
      "       STATE     0.9601    0.9633    0.9617       300\n",
      "        TEMP     0.8750    0.7000    0.7778        10\n",
      "        UNIT     0.9819    0.9841    0.9830       441\n",
      "\n",
      "   micro avg     0.9696    0.9669    0.9682      1845\n",
      "   macro avg     0.9638    0.9332    0.9471      1845\n",
      "weighted avg     0.9695    0.9669    0.9682      1845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "test_source = 'ar'\n",
    "model = 'ar'\n",
    "\n",
    "actual_ner = [convert_to_iob1([x[1] for x in ann]) for ann in test_data[test_source]]\n",
    "pred_ner = [convert_to_iob1(p.ner) for p in preds[model][test_source]]\n",
    "\n",
    "print(classification_report(actual_ner, pred_ner, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e08983",
   "metadata": {
    "papermill": {
     "duration": 0.08957,
     "end_time": "2022-04-07T13:06:52.587948",
     "exception": false,
     "start_time": "2022-04-07T13:06:52.498378",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can get the micro f1-score directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7f7bfd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T13:06:52.771575Z",
     "iopub.status.busy": "2022-04-07T13:06:52.770572Z",
     "iopub.status.idle": "2022-04-07T13:06:52.797700Z",
     "shell.execute_reply": "2022-04-07T13:06:52.798273Z",
     "shell.execute_reply.started": "2022-04-07T12:56:45.725087Z"
    },
    "papermill": {
     "duration": 0.120808,
     "end_time": "2022-04-07T13:06:52.798476",
     "exception": false,
     "start_time": "2022-04-07T13:06:52.677668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.9682'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "'%0.4f' % f1_score(actual_ner, pred_ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca961cf",
   "metadata": {
    "papermill": {
     "duration": 0.090745,
     "end_time": "2022-04-07T13:06:52.978636",
     "exception": false,
     "start_time": "2022-04-07T13:06:52.887891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can then try to reproduce Table IV by computing the f1-score for each model and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97fe7bab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T13:06:53.162034Z",
     "iopub.status.busy": "2022-04-07T13:06:53.161354Z",
     "iopub.status.idle": "2022-04-07T13:06:53.462721Z",
     "shell.execute_reply": "2022-04-07T13:06:53.462124Z",
     "shell.execute_reply.started": "2022-04-07T12:56:45.748363Z"
    },
    "papermill": {
     "duration": 0.395147,
     "end_time": "2022-04-07T13:06:53.462918",
     "exception": false,
     "start_time": "2022-04-07T13:06:53.067771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = {model: {} for model in models}\n",
    "for test_source, data in test_data.items():\n",
    "    actual_ner = [convert_to_iob1([x[1] for x in ann]) for ann in data]\n",
    "    for model in models:\n",
    "        pred_ner = [convert_to_iob1(p.ner) for p in preds[model][test_source]]\n",
    "        scores[model][test_source] = f1_score(actual_ner, pred_ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ace148",
   "metadata": {
    "papermill": {
     "duration": 0.093906,
     "end_time": "2022-04-07T13:06:53.649107",
     "exception": false,
     "start_time": "2022-04-07T13:06:53.555201",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We also need to calculate the scores on the combined test set, by contatenating them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d19d3eb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T13:06:53.834560Z",
     "iopub.status.busy": "2022-04-07T13:06:53.833800Z",
     "iopub.status.idle": "2022-04-07T13:06:54.131037Z",
     "shell.execute_reply": "2022-04-07T13:06:54.131536Z",
     "shell.execute_reply.started": "2022-04-07T12:56:45.944156Z"
    },
    "papermill": {
     "duration": 0.392623,
     "end_time": "2022-04-07T13:06:54.131761",
     "exception": false,
     "start_time": "2022-04-07T13:06:53.739138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "actual_ner = [convert_to_iob1([x[1] for x in ann]) for data in test_data.values() for ann in data]\n",
    "for model in models:\n",
    "    pred_ner = [convert_to_iob1(p.ner) for test_source in test_data for p in preds[model][test_source]]\n",
    "    scores[model]['combined'] = f1_score(actual_ner, pred_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be344047",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T13:06:54.322051Z",
     "iopub.status.busy": "2022-04-07T13:06:54.321346Z",
     "iopub.status.idle": "2022-04-07T13:06:54.399490Z",
     "shell.execute_reply": "2022-04-07T13:06:54.398955Z",
     "shell.execute_reply.started": "2022-04-07T12:56:46.135926Z"
    },
    "papermill": {
     "duration": 0.177398,
     "end_time": "2022-04-07T13:06:54.399653",
     "exception": false,
     "start_time": "2022-04-07T13:06:54.222255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_1db5d_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >ar</th>\n",
       "      <th class=\"col_heading level0 col1\" >gk</th>\n",
       "      <th class=\"col_heading level0 col2\" >ar_gk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1db5d_level0_row0\" class=\"row_heading level0 row0\" >ar</th>\n",
       "      <td id=\"T_1db5d_row0_col0\" class=\"data row0 col0\" >0.9682</td>\n",
       "      <td id=\"T_1db5d_row0_col1\" class=\"data row0 col1\" >0.9331</td>\n",
       "      <td id=\"T_1db5d_row0_col2\" class=\"data row0 col2\" >0.9704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1db5d_level0_row1\" class=\"row_heading level0 row1\" >gk</th>\n",
       "      <td id=\"T_1db5d_row1_col0\" class=\"data row1 col0\" >0.8666</td>\n",
       "      <td id=\"T_1db5d_row1_col1\" class=\"data row1 col1\" >0.9511</td>\n",
       "      <td id=\"T_1db5d_row1_col2\" class=\"data row1 col2\" >0.9499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1db5d_level0_row2\" class=\"row_heading level0 row2\" >combined</th>\n",
       "      <td id=\"T_1db5d_row2_col0\" class=\"data row2 col0\" >0.8911</td>\n",
       "      <td id=\"T_1db5d_row2_col1\" class=\"data row2 col1\" >0.9469</td>\n",
       "      <td id=\"T_1db5d_row2_col2\" class=\"data row2 col2\" >0.9549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fdef2b77ed0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores).style.format('{:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e61f00f",
   "metadata": {
    "papermill": {
     "duration": 0.090834,
     "end_time": "2022-04-07T13:06:54.582503",
     "exception": false,
     "start_time": "2022-04-07T13:06:54.491669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The results are *slightly* different to those in the paper, but all agree within 0.01 for each row.\n",
    "\n",
    "So we've successfully reproduced the results in the paper, and shown the evaulation from Stanford NER toolkit is very close to that of seqeval (if you work around hallucinated entities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94e67a94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T13:06:54.781566Z",
     "iopub.status.busy": "2022-04-07T13:06:54.780354Z",
     "iopub.status.idle": "2022-04-07T13:06:54.784566Z",
     "shell.execute_reply": "2022-04-07T13:06:54.785228Z",
     "shell.execute_reply.started": "2022-04-07T12:56:46.204022Z"
    },
    "papermill": {
     "duration": 0.11174,
     "end_time": "2022-04-07T13:06:54.785439",
     "exception": false,
     "start_time": "2022-04-07T13:06:54.673699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AllRecipes</th>\n",
       "      <th>FOOD.com</th>\n",
       "      <th>BOTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AllRecipes</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.9317</td>\n",
       "      <td>0.9709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOOD.com</th>\n",
       "      <td>0.8672</td>\n",
       "      <td>0.9519</td>\n",
       "      <td>0.9498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOTH</th>\n",
       "      <td>0.8972</td>\n",
       "      <td>0.9472</td>\n",
       "      <td>0.9611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AllRecipes  FOOD.com    BOTH\n",
       "AllRecipes      0.9682    0.9317  0.9709\n",
       "FOOD.com        0.8672    0.9519  0.9498\n",
       "BOTH            0.8972    0.9472  0.9611"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reported_scores = pd.DataFrame([[0.9682, 0.9317, 0.9709],\n",
    "              [0.8672, 0.9519, 0.9498],\n",
    "              [0.8972, 0.9472, 0.9611]],\n",
    "             columns = ['AllRecipes', 'FOOD.com', 'BOTH'],\n",
    "             index = ['AllRecipes', 'FOOD.com', 'BOTH'])\n",
    "reported_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0eda97e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'annotate_ner_robust' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m ar_model_file = \u001b[33m'\u001b[39m\u001b[33mar.model.ser.gz\u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# This is the default filename format based on your code\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# You can use it with annotate_ner_robust\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m annotations = \u001b[43mannotate_ner_robust\u001b[49m(\n\u001b[32m      5\u001b[39m     ar_model_file,\n\u001b[32m      6\u001b[39m     [\u001b[33m'\u001b[39m\u001b[33m1 cup of frozen peas\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      7\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'annotate_ner_robust' is not defined"
     ]
    }
   ],
   "source": [
    "ar_model_file = 'ar.model.ser.gz'  # This is the default filename format based on your code\n",
    "\n",
    "# You can use it with annotate_ner_robust\n",
    "annotations = annotate_ner_robust(\n",
    "    ar_model_file,\n",
    "    ['1 cup of frozen peas']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9176dcd",
   "metadata": {},
   "source": [
    "<h3><strong>Using The NER Trained Model</strong></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "068c8c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open Excel File\n",
    "import openpyxl\n",
    "import os\n",
    "\n",
    "# Load the workbook\n",
    "workbook = openpyxl.load_workbook('1_food-dataset-final.xlsx')\n",
    "\n",
    "# Select the active worksheet\n",
    "worksheet = workbook[\"Sheet1\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58e303e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (465, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food Name</th>\n",
       "      <th>None</th>\n",
       "      <th>Ingredients</th>\n",
       "      <th>NER Ingredient</th>\n",
       "      <th>Instructions</th>\n",
       "      <th>Min Age Group</th>\n",
       "      <th>Max Age Group</th>\n",
       "      <th>texture</th>\n",
       "      <th>Prep Time</th>\n",
       "      <th>Cook Time</th>\n",
       "      <th>...</th>\n",
       "      <th>Description</th>\n",
       "      <th>Flavor_type</th>\n",
       "      <th>Dietary Tags</th>\n",
       "      <th>choking_hazard</th>\n",
       "      <th>tips</th>\n",
       "      <th>allergen</th>\n",
       "      <th>hypoallergenic</th>\n",
       "      <th>Nutrion Value</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chicken, Squash &amp; Spinach</td>\n",
       "      <td>None</td>\n",
       "      <td>2  tsp sunflower oil_x000D_\\n50g onion, diced_...</td>\n",
       "      <td>None</td>\n",
       "      <td>1. Heat the oil in a saucepan.\\n2. Add the oni...</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Porridge with Apple, Pear &amp; Apricot</td>\n",
       "      <td>None</td>\n",
       "      <td>4 tbsp water_x000D_\\n1 apple, peeled, cored an...</td>\n",
       "      <td>None</td>\n",
       "      <td>1. Put the fruit into a saucepan together with...</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Easy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spinach, Potato, Carrot &amp; Cheddar Mash</td>\n",
       "      <td>None</td>\n",
       "      <td>350g potatoes, diced_x000D_\\n200g carrot, dice...</td>\n",
       "      <td>None</td>\n",
       "      <td>1. Put the potato and carrot into a steamer an...</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Easy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fruity Chicken with Apricots &amp; Sweet Potato Puree</td>\n",
       "      <td>None</td>\n",
       "      <td>2 tsp light olive oil_x000D_\\n1 small onion, c...</td>\n",
       "      <td>None</td>\n",
       "      <td>1. Heat the oil in a pan and sauté the onion f...</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Easy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chicken Curry Puree</td>\n",
       "      <td>None</td>\n",
       "      <td>2 tsp sunflower oil_x000D_\\n1 onion, roughly c...</td>\n",
       "      <td>None</td>\n",
       "      <td>1. Heat the oil in a saucepan.\\n2. Add the oni...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Thin Puree</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Easy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Food Name  None  \\\n",
       "0                          Chicken, Squash & Spinach  None   \n",
       "1                Porridge with Apple, Pear & Apricot  None   \n",
       "2             Spinach, Potato, Carrot & Cheddar Mash  None   \n",
       "3  Fruity Chicken with Apricots & Sweet Potato Puree  None   \n",
       "4                                Chicken Curry Puree  None   \n",
       "\n",
       "                                         Ingredients NER Ingredient  \\\n",
       "0  2  tsp sunflower oil_x000D_\\n50g onion, diced_...           None   \n",
       "1  4 tbsp water_x000D_\\n1 apple, peeled, cored an...           None   \n",
       "2  350g potatoes, diced_x000D_\\n200g carrot, dice...           None   \n",
       "3  2 tsp light olive oil_x000D_\\n1 small onion, c...           None   \n",
       "4  2 tsp sunflower oil_x000D_\\n1 onion, roughly c...           None   \n",
       "\n",
       "                                        Instructions  Min Age Group   \\\n",
       "0  1. Heat the oil in a saucepan.\\n2. Add the oni...               6   \n",
       "1  1. Put the fruit into a saucepan together with...               6   \n",
       "2  1. Put the potato and carrot into a steamer an...               6   \n",
       "3  1. Heat the oil in a pan and sauté the onion f...               6   \n",
       "4  1. Heat the oil in a saucepan.\\n2. Add the oni...               6   \n",
       "\n",
       "   Max Age Group      texture  Prep Time  Cook Time  ... Description  \\\n",
       "0              36     Unknown       12.0       22.0  ...      Medium   \n",
       "1              12     Unknown        5.0       10.0  ...        Easy   \n",
       "2              10     Unknown       10.0       15.0  ...        Easy   \n",
       "3               8     Unknown       10.0       20.0  ...        Easy   \n",
       "4               6  Thin Puree       12.0       25.0  ...        Easy   \n",
       "\n",
       "  Flavor_type Dietary Tags choking_hazard  tips allergen hypoallergenic  \\\n",
       "0        None         None           None  None     None           None   \n",
       "1        None         None           None  None     None           None   \n",
       "2        None         None           None  None     None           None   \n",
       "3        None         None           None  None     None           None   \n",
       "4        None         None           None  None     None           None   \n",
       "\n",
       "  Nutrion Value  None  None  \n",
       "0           Yes  None  None  \n",
       "1           Yes  None  None  \n",
       "2           Yes  None  None  \n",
       "3           Yes  None  None  \n",
       "4           Yes  None  None  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = []\n",
    "headers = []\n",
    "\n",
    "# Get headers from the first row\n",
    "for col in range(1, worksheet.max_column + 1):\n",
    "    headers.append(worksheet.cell(row=1, column=col).value)\n",
    "\n",
    "# Get data from remaining rows\n",
    "for row in range(2, worksheet.max_row + 1):\n",
    "    row_data = []\n",
    "    for col in range(1, worksheet.max_column + 1):\n",
    "        row_data.append(worksheet.cell(row=row, column=col).value)\n",
    "    data.append(row_data)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "# Display first few rows to verify\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4ff572e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers: ['Food Name', None, 'Ingredients', 'NER Ingredient', 'Instructions', 'Min Age Group ', 'Max Age Group ', 'texture', 'Prep Time', 'Cook Time', 'Serving', 'Origin', 'Link ', 'Credibility ', 'Image Link ', 'Region', 'Difficulty', 'Meal Type', 'Description', 'Flavor_type', 'Dietary Tags', 'choking_hazard', 'tips', 'allergen', 'hypoallergenic', 'Nutrion Value', None, None]\n"
     ]
    }
   ],
   "source": [
    "# Get headers from the first row\n",
    "headers = []\n",
    "for col in range(1, worksheet.max_column + 1):\n",
    "    headers.append(worksheet.cell(row=1, column=col).value)\n",
    "\n",
    "print(\"Headers:\", headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6afcbcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['Food Name', None, 'Ingredients', 'NER Ingredient', 'Instructions', 'Min Age Group ', 'Max Age Group ', 'texture', 'Prep Time', 'Cook Time', 'Serving', 'Origin', 'Link ', 'Credibility ', 'Image Link ', 'Region', 'Difficulty', 'Meal Type', 'Description', 'Flavor_type', 'Dietary Tags', 'choking_hazard', 'tips', 'allergen', 'hypoallergenic', 'Nutrion Value', None, None]\n",
      "Dropped 3 None column(s)\n",
      "Column post-clean: ['Food Name', 'Ingredients', 'NER Ingredient', 'Instructions', 'Min Age Group ', 'Max Age Group ', 'texture', 'Prep Time', 'Cook Time', 'Serving', 'Origin', 'Link ', 'Credibility ', 'Image Link ', 'Region', 'Difficulty', 'Meal Type', 'Description', 'Flavor_type', 'Dietary Tags', 'choking_hazard', 'tips', 'allergen', 'hypoallergenic', 'Nutrion Value']\n",
      "Dataset shape: (465, 25)\n"
     ]
    }
   ],
   "source": [
    "# Display all column names to verify\n",
    "print(\"Column names:\", df.columns.tolist())\n",
    "\n",
    "# Drop None value column if it exists\n",
    "none_columns = [col for col in df.columns if col is None]\n",
    "if none_columns:\n",
    "    df = df.drop(columns=none_columns)\n",
    "    print(f\"Dropped {len(none_columns)} None column(s)\")\n",
    "\n",
    "# Display all column names to verify\n",
    "print(\"Column post-clean:\", df.columns.tolist())\n",
    "print(f\"Dataset shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f68d3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name post-clean: ['food_name', 'ingredient', 'ner_ingredient', 'instructions', 'min_age_group', 'max_age_group', 'texture', 'prep_time', 'cook_time', 'serving', 'origin', 'recipe_link', 'credibility', 'image_link', 'region', 'difficulty', 'meal_type', 'description', 'flavor_type', 'dietary_tags', 'choking_hazard', 'tips', 'allergen', 'hypoallergenic', 'nutrition_value']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_name</th>\n",
       "      <th>ingredient</th>\n",
       "      <th>ner_ingredient</th>\n",
       "      <th>instructions</th>\n",
       "      <th>min_age_group</th>\n",
       "      <th>max_age_group</th>\n",
       "      <th>texture</th>\n",
       "      <th>prep_time</th>\n",
       "      <th>cook_time</th>\n",
       "      <th>serving</th>\n",
       "      <th>...</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>meal_type</th>\n",
       "      <th>description</th>\n",
       "      <th>flavor_type</th>\n",
       "      <th>dietary_tags</th>\n",
       "      <th>choking_hazard</th>\n",
       "      <th>tips</th>\n",
       "      <th>allergen</th>\n",
       "      <th>hypoallergenic</th>\n",
       "      <th>nutrition_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chicken, Squash &amp; Spinach</td>\n",
       "      <td>2  tsp sunflower oil_x000D_\\n50g onion, diced_...</td>\n",
       "      <td>None</td>\n",
       "      <td>1. Heat the oil in a saucepan.\\n2. Add the oni...</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Medium</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Porridge with Apple, Pear &amp; Apricot</td>\n",
       "      <td>4 tbsp water_x000D_\\n1 apple, peeled, cored an...</td>\n",
       "      <td>None</td>\n",
       "      <td>1. Put the fruit into a saucepan together with...</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4 portions</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Easy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spinach, Potato, Carrot &amp; Cheddar Mash</td>\n",
       "      <td>350g potatoes, diced_x000D_\\n200g carrot, dice...</td>\n",
       "      <td>None</td>\n",
       "      <td>1. Put the potato and carrot into a steamer an...</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Easy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fruity Chicken with Apricots &amp; Sweet Potato Puree</td>\n",
       "      <td>2 tsp light olive oil_x000D_\\n1 small onion, c...</td>\n",
       "      <td>None</td>\n",
       "      <td>1. Heat the oil in a pan and sauté the onion f...</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4 Portions</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Easy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chicken Curry Puree</td>\n",
       "      <td>2 tsp sunflower oil_x000D_\\n1 onion, roughly c...</td>\n",
       "      <td>None</td>\n",
       "      <td>1. Heat the oil in a saucepan.\\n2. Add the oni...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Thin Puree</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4 portions</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Easy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           food_name  \\\n",
       "0                          Chicken, Squash & Spinach   \n",
       "1                Porridge with Apple, Pear & Apricot   \n",
       "2             Spinach, Potato, Carrot & Cheddar Mash   \n",
       "3  Fruity Chicken with Apricots & Sweet Potato Puree   \n",
       "4                                Chicken Curry Puree   \n",
       "\n",
       "                                          ingredient ner_ingredient  \\\n",
       "0  2  tsp sunflower oil_x000D_\\n50g onion, diced_...           None   \n",
       "1  4 tbsp water_x000D_\\n1 apple, peeled, cored an...           None   \n",
       "2  350g potatoes, diced_x000D_\\n200g carrot, dice...           None   \n",
       "3  2 tsp light olive oil_x000D_\\n1 small onion, c...           None   \n",
       "4  2 tsp sunflower oil_x000D_\\n1 onion, roughly c...           None   \n",
       "\n",
       "                                        instructions  min_age_group  \\\n",
       "0  1. Heat the oil in a saucepan.\\n2. Add the oni...              6   \n",
       "1  1. Put the fruit into a saucepan together with...              6   \n",
       "2  1. Put the potato and carrot into a steamer an...              6   \n",
       "3  1. Heat the oil in a pan and sauté the onion f...              6   \n",
       "4  1. Heat the oil in a saucepan.\\n2. Add the oni...              6   \n",
       "\n",
       "   max_age_group     texture  prep_time  cook_time     serving  ...  \\\n",
       "0             36     Unknown       12.0       22.0           4  ...   \n",
       "1             12     Unknown        5.0       10.0  4 portions  ...   \n",
       "2             10     Unknown       10.0       15.0           4  ...   \n",
       "3              8     Unknown       10.0       20.0  4 Portions  ...   \n",
       "4              6  Thin Puree       12.0       25.0  4 portions  ...   \n",
       "\n",
       "  difficulty meal_type description flavor_type dietary_tags choking_hazard  \\\n",
       "0       None      None      Medium        None         None           None   \n",
       "1       None      None        Easy        None         None           None   \n",
       "2       None      None        Easy        None         None           None   \n",
       "3       None      None        Easy        None         None           None   \n",
       "4       None      None        Easy        None         None           None   \n",
       "\n",
       "   tips allergen hypoallergenic nutrition_value  \n",
       "0  None     None           None             Yes  \n",
       "1  None     None           None             Yes  \n",
       "2  None     None           None             Yes  \n",
       "3  None     None           None             Yes  \n",
       "4  None     None           None             Yes  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#renamed columns\n",
    "df = df.rename(columns={\n",
    "    'Food Name' : 'food_name',\n",
    "    'Ingredients' : 'ingredient',\n",
    "    'Instructions' : 'instructions',\n",
    "    'Min Age Group ': 'min_age_group',\n",
    "    'Max Age Group ': 'max_age_group',\n",
    "    'NER Ingredient': 'ner_ingredient',\n",
    "    'Texture': 'texture',\n",
    "    'Prep Time': 'prep_time',\n",
    "    'Cook Time': 'cook_time',\n",
    "    'Serving': 'serving',\n",
    "    'Difficulty': 'difficulty',\n",
    "    'Origin': 'origin',\n",
    "    'Region': 'region',\n",
    "    'Description': 'description',\n",
    "    'Image Link ': 'image_link',\n",
    "    'Link ': 'recipe_link',\n",
    "    'Credibility ': 'credibility',\n",
    "    'Meal Type': 'meal_type',\n",
    "    'Flavor_type': 'flavor_type',\n",
    "    'Dietary Tags': 'dietary_tags',\n",
    "    'Choking Hazards': 'choking_hazards',\n",
    "    'Nutrion Value': 'nutrition_value',\n",
    "    'tips': 'tips',\n",
    "    'Allergen': 'allergen',\n",
    "    'Hypoallergenic': 'hypoallergenic',\n",
    "})\n",
    "\n",
    "print(\"Column name post-clean:\", df.columns.tolist())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b07f0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame:\n",
      "(241, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_name</th>\n",
       "      <th>ingredient</th>\n",
       "      <th>ner_ingredient</th>\n",
       "      <th>instructions</th>\n",
       "      <th>min_age_group</th>\n",
       "      <th>max_age_group</th>\n",
       "      <th>texture</th>\n",
       "      <th>prep_time</th>\n",
       "      <th>cook_time</th>\n",
       "      <th>serving</th>\n",
       "      <th>...</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>meal_type</th>\n",
       "      <th>description</th>\n",
       "      <th>flavor_type</th>\n",
       "      <th>dietary_tags</th>\n",
       "      <th>choking_hazard</th>\n",
       "      <th>tips</th>\n",
       "      <th>allergen</th>\n",
       "      <th>hypoallergenic</th>\n",
       "      <th>nutrition_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Poached Chicken Breast with Carrots and Beans</td>\n",
       "      <td>- 100g finely chopped or minced chicken breast...</td>\n",
       "      <td>None</td>\n",
       "      <td>1. Place chicken, chopped carrots, and green b...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Thin Puree</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Oceanic</td>\n",
       "      <td>nz</td>\n",
       "      <td>Medium</td>\n",
       "      <td>None</td>\n",
       "      <td>A standout among chicken and carrot dishes, th...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beef and Vegetable Casserole Recipe</td>\n",
       "      <td>- 1 tsp olive oil\\n-100g finely minced beef\\n-...</td>\n",
       "      <td>None</td>\n",
       "      <td>1. Heat 1 tsp oil in a medium saucepan over me...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Oceanic</td>\n",
       "      <td>nz</td>\n",
       "      <td>Medium</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicken and Tomato Risoni Recipe</td>\n",
       "      <td>- Spray oil for cooking\\n- 100g chicken mince\\...</td>\n",
       "      <td>None</td>\n",
       "      <td>1. In a small saucepan, cook mince over medium...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>Oceanic</td>\n",
       "      <td>nz</td>\n",
       "      <td>Medium</td>\n",
       "      <td>None</td>\n",
       "      <td>This chicken and tomato risoni recipe is a del...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cream of Pumpkin and Potato Soup</td>\n",
       "      <td>- Spray oil for cooking\\n- ½ small (40g) onion...</td>\n",
       "      <td>None</td>\n",
       "      <td>1. Lightly spray a medium saucepan with oil an...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Oceanic</td>\n",
       "      <td>nz</td>\n",
       "      <td>Medium</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baby-Friendly Lentil Dhal Recipe</td>\n",
       "      <td>– 1 cup (250 mL) water\\n– 1 small (120 g) pota...</td>\n",
       "      <td>None</td>\n",
       "      <td>1. Place water, chopped potato, onion, carrot,...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Oceanic</td>\n",
       "      <td>nz</td>\n",
       "      <td>Easy</td>\n",
       "      <td>None</td>\n",
       "      <td>With its soft texture and carefully chosen ing...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       food_name  \\\n",
       "0  Poached Chicken Breast with Carrots and Beans   \n",
       "1            Beef and Vegetable Casserole Recipe   \n",
       "2               Chicken and Tomato Risoni Recipe   \n",
       "3               Cream of Pumpkin and Potato Soup   \n",
       "4               Baby-Friendly Lentil Dhal Recipe   \n",
       "\n",
       "                                          ingredient ner_ingredient  \\\n",
       "0  - 100g finely chopped or minced chicken breast...           None   \n",
       "1  - 1 tsp olive oil\\n-100g finely minced beef\\n-...           None   \n",
       "2  - Spray oil for cooking\\n- 100g chicken mince\\...           None   \n",
       "3  - Spray oil for cooking\\n- ½ small (40g) onion...           None   \n",
       "4  – 1 cup (250 mL) water\\n– 1 small (120 g) pota...           None   \n",
       "\n",
       "                                        instructions  min_age_group  \\\n",
       "0  1. Place chicken, chopped carrots, and green b...              6   \n",
       "1  1. Heat 1 tsp oil in a medium saucepan over me...              6   \n",
       "2  1. In a small saucepan, cook mince over medium...              6   \n",
       "3  1. Lightly spray a medium saucepan with oil an...              6   \n",
       "4  1. Place water, chopped potato, onion, carrot,...              6   \n",
       "\n",
       "   max_age_group     texture  prep_time  cook_time serving  ... difficulty  \\\n",
       "0              7  Thin Puree       10.0       15.0       2  ...    Oceanic   \n",
       "1              7     Unknown       15.0       20.0       2  ...    Oceanic   \n",
       "2              7     Unknown       10.0       18.0       6  ...    Oceanic   \n",
       "3              7     Unknown       10.0       12.0       2  ...    Oceanic   \n",
       "4              7     Unknown       10.0       15.0       2  ...    Oceanic   \n",
       "\n",
       "  meal_type description flavor_type  \\\n",
       "0        nz      Medium        None   \n",
       "1        nz      Medium        None   \n",
       "2        nz      Medium        None   \n",
       "3        nz      Medium        None   \n",
       "4        nz        Easy        None   \n",
       "\n",
       "                                        dietary_tags choking_hazard  tips  \\\n",
       "0  A standout among chicken and carrot dishes, th...           None  None   \n",
       "1                                               None           None  None   \n",
       "2  This chicken and tomato risoni recipe is a del...           None  None   \n",
       "3                                               None           None  None   \n",
       "4  With its soft texture and carefully chosen ing...           None  None   \n",
       "\n",
       "  allergen hypoallergenic nutrition_value  \n",
       "0     None           None             Yes  \n",
       "1     None           None             Yes  \n",
       "2     None           None             Yes  \n",
       "3     None           None              No  \n",
       "4     None           None             Yes  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop columns if some columns are empty\n",
    "important_columns = ['food_name', 'ingredient', 'instructions',  'recipe_link']\n",
    "for col in df.columns:\n",
    "    if col in important_columns:\n",
    "        null_count = df[col].isnull().sum()        \n",
    "        if null_count >0:\n",
    "            df = df.dropna(subset=[col])\n",
    "\n",
    "# After dropping rows, you may want to reset the index if needed\n",
    "df = df.reset_index(drop=True)\n",
    "# Display the cleaned DataFrame\n",
    "print(\"Cleaned DataFrame:\")\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea23202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataclass from dataclasses module\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Helper functions from your existing code\n",
    "@dataclass\n",
    "class NERData:\n",
    "    ner: List[str]\n",
    "    tokens: List[str]\n",
    "\n",
    "def extract_ner_data(annotation) -> NERData:\n",
    "    tokens = [token for sentence in annotation.sentence for token in sentence.token]\n",
    "    return NERData(tokens=[t.word for t in tokens], ner=[t.coarseNER for t in tokens])\n",
    "\n",
    "def extract_ingredient_names(ner_data):\n",
    "    \"\"\"\n",
    "    Extract only the ingredient names from NER data.\n",
    "    If names appear in consecutive tokens, join them together.\n",
    "    \"\"\"\n",
    "    names = []\n",
    "    current_name = []\n",
    "    \n",
    "    # Zip tokens and NER tags together and iterate\n",
    "    for token, tag in zip(ner_data.tokens, ner_data.ner):\n",
    "        if tag == 'NAME':\n",
    "            current_name.append(token)\n",
    "        elif current_name:  # Not a NAME tag but we have collected name tokens\n",
    "            names.append(' '.join(current_name))\n",
    "            current_name = []\n",
    "    \n",
    "    # Add the last name if there's one at the end of the sequence\n",
    "    if current_name:\n",
    "        names.append(' '.join(current_name))\n",
    "    \n",
    "    return names\n",
    "\n",
    "# Import pickle and load the models\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Check if the model file exists directly\n",
    "ar_model_file = 'ar.model.ser.gz'\n",
    "if not os.path.exists(ar_model_file):\n",
    "    # Try loading from the pickle file if direct model file doesn't exist\n",
    "    try:\n",
    "        with open('trained_models.pkl', 'rb') as f:\n",
    "            models = pickle.load(f)\n",
    "        ar_model_name = models['ar']\n",
    "        \n",
    "        # If models['ar'] is not a full path, prepend the current directory\n",
    "        if not os.path.isabs(ar_model_name):\n",
    "            ar_model_file = os.path.join(os.getcwd(), ar_model_name)\n",
    "        else:\n",
    "            ar_model_file = ar_model_name\n",
    "    except:\n",
    "        print(\"Could not find model file. Using the simple parser instead.\")\n",
    "        use_simple_parser = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29d0c78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for NER model...\n",
      "Found model at ar.model.ser.gz\n"
     ]
    }
   ],
   "source": [
    "# ----- STEP 3: Find and load the NER model -----\n",
    "print(\"Looking for NER model...\")\n",
    "model_file_path = 'ar.model.ser.gz'\n",
    "\n",
    "# If the model file doesn't exist directly, try to find it\n",
    "if not os.path.exists(model_file_path):\n",
    "    try:\n",
    "        # Try to load from trained_models.pkl\n",
    "        with open('trained_models.pkl', 'rb') as f:\n",
    "            models = pickle.load(f)\n",
    "            if 'ar' in models:\n",
    "                model_path = models['ar']\n",
    "                if os.path.exists(model_path):\n",
    "                    model_file_path = model_path\n",
    "                    print(f\"Found model at {model_file_path}\")\n",
    "                else:\n",
    "                    print(f\"Model path {model_path} from pickle doesn't exist\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "else:\n",
    "    print(f\"Found model at {model_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04c433e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ----- STEP 4: Process each ingredient using the NER model -----\n",
    "from stanza.server import CoreNLPClient\n",
    "import random\n",
    "import time\n",
    "import subprocess\n",
    "\n",
    "def annotate_ner_robust(ner_model_file, texts, tokenize_whitespace=True):\n",
    "    \"\"\"A more robust version of annotate_ner that handles port conflicts better\"\"\"\n",
    "    try:\n",
    "        subprocess.run(['taskkill', '/F', '/IM', 'java.exe'], capture_output=True)\n",
    "        time.sleep(2)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not kill Java processes: {e}\")\n",
    "    \n",
    "    server_port = random.randint(20000, 50000)\n",
    "    control_port = server_port + 1000\n",
    "    \n",
    "    print(f\"Starting NER server on port: {server_port}\")\n",
    "    \n",
    "    properties = {\n",
    "        \"ner.model\": ner_model_file, \n",
    "        \"tokenize.whitespace\": tokenize_whitespace, \n",
    "        \"ner.applyNumericClassifiers\": False\n",
    "    }\n",
    "    \n",
    "    annotated = []\n",
    "    with CoreNLPClient(\n",
    "         annotators=['tokenize','ssplit','ner'],\n",
    "         properties=properties,\n",
    "         timeout=60000,\n",
    "         be_quiet=True,\n",
    "         port=server_port,\n",
    "         start_server=True,\n",
    "         control_port=control_port,\n",
    "         preload=False,\n",
    "         memory='4G',\n",
    "         endpoint=f'http://localhost:{server_port}') as client:\n",
    "        \n",
    "        print(\"Server successfully started!\")\n",
    "        \n",
    "        for text in tqdm(texts):\n",
    "            annotated.append(client.annotate(text))\n",
    "            \n",
    "    return annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c46b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ingredients_with_ner(df, model_file):\n",
    "    \"\"\"Process all ingredients and extract names using NER model\"\"\"\n",
    "    processed_df = df.copy()\n",
    "    all_extracted_names = []\n",
    "    \n",
    "    print(\"Processing ingredients with NER model...\")\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        ingredient_text = row['ingredient']\n",
    "        \n",
    "        # Skip if ingredient is missing\n",
    "        if pd.isna(ingredient_text):\n",
    "            all_extracted_names.append(\"\")\n",
    "            continue\n",
    "            \n",
    "        # Split by either \\n or \\\\n\n",
    "        ingredient_lines = re.split(r'\\\\n|\\n', str(ingredient_text))\n",
    "        \n",
    "        # Clean each line (remove leading \"- \" if present)\n",
    "        ingredient_lines = [line.strip('- ').strip() for line in ingredient_lines if line.strip()]\n",
    "        \n",
    "        try:\n",
    "            # Process all ingredient lines for this recipe at once\n",
    "            annotations = annotate_ner_robust(model_file, ingredient_lines)\n",
    "            \n",
    "            # Extract ingredient names from all annotations\n",
    "            extracted_names = []\n",
    "            for annotation in annotations:\n",
    "                ner_data = extract_ner_data(annotation)\n",
    "                names = extract_ingredient_names(ner_data)\n",
    "                if names:\n",
    "                    extracted_names.extend(names)\n",
    "            \n",
    "            # Join all extracted names with commas\n",
    "            all_extracted_names.append(', '.join(extracted_names))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {idx}: {e}\")\n",
    "            all_extracted_names.append(\"\")\n",
    "    \n",
    "    # Add the extracted names as a new column\n",
    "    processed_df['ner_ingredient'] = all_extracted_names\n",
    "    \n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09d742ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ingredient extraction (first 5 rows only)...\n",
      "Processing sample of 5 rows\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'process_ingredients_with_ner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing sample of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_sample)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Process only these 5 rows\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m df_sample_with_ner = \u001b[43mprocess_ingredients_with_ner\u001b[49m(df_sample, model_file_path)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mExtraction complete! Results:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_sample_with_ner[[\u001b[33m'\u001b[39m\u001b[33mfood_name\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mingredient\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mner_ingredient\u001b[39m\u001b[33m'\u001b[39m]])\n",
      "\u001b[31mNameError\u001b[39m: name 'process_ingredients_with_ner' is not defined"
     ]
    }
   ],
   "source": [
    "# ----- STEP 5: Run the processing on first 5 rows only -----\n",
    "print(\"Starting ingredient extraction (first 5 rows only)...\")\n",
    "if os.path.exists(model_file_path):\n",
    "    # Take only the first 5 rows\n",
    "    df_sample = df.head(5).copy()\n",
    "    print(f\"Processing sample of {len(df_sample)} rows\")\n",
    "    \n",
    "    # Process only these 5 rows\n",
    "    df_sample_with_ner = process_ingredients_with_ner(df_sample, model_file_path)\n",
    "    \n",
    "    print(\"\\nExtraction complete! Results:\")\n",
    "    print(df_sample_with_ner[['food_name', 'ingredient', 'ner_ingredient']])\n",
    "    \n",
    "    # Save the sample processed dataframe to a different file name\n",
    "    df_sample_with_ner.to_excel('food_dataset_with_ner_sample.xlsx', index=False)\n",
    "    print(\"Saved sample dataset to 'food_dataset_with_ner_sample.xlsx'\")\n",
    "else:\n",
    "    print(\"NER model file not found. Cannot process ingredients.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0459a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK resources if not already available\n",
    "import nltk\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def clean_ingredient_names(ingredient_names_list):\n",
    "    \"\"\"\n",
    "    Process a list of ingredient names to:\n",
    "    1. Remove measurements and units\n",
    "    2. Remove stopwords\n",
    "    3. Lemmatize words\n",
    "    4. Keep only the core ingredient name\n",
    "    \n",
    "    Args:\n",
    "        ingredient_names_list: List of strings containing extracted ingredient names\n",
    "        \n",
    "    Returns:\n",
    "        List of cleaned, lemmatized ingredient names\n",
    "    \"\"\"\n",
    "    # Custom measurement and cooking stopwords\n",
    "    compound_ingredients = {\n",
    "        \"sweet potato\", \"bell pepper\", \"olive oil\", \"coconut milk\", \n",
    "        \"soy sauce\", \"maple syrup\", \"peanut butter\", \"baking powder\",\n",
    "        \"baking soda\", \"salad greens\", \"sesame oil\", \"rice vinegar\",\n",
    "        \"whole wheat\", \"green onion\", \"red onion\", \"red cabbage\"\n",
    "    }\n",
    "    measurement_units = {\n",
    "        \"cup\", \"cups\", \"tablespoon\", \"tablespoons\", \"tbsp\", \"teaspoon\", \"teaspoons\", \"tsp\",\n",
    "        \"oz\", \"ounce\", \"ounces\", \"pound\", \"pounds\", \"lb\", \"lbs\", \"gram\", \"grams\", \"g\",\n",
    "        \"kilogram\", \"kilograms\", \"kg\", \"ml\", \"milliliter\", \"milliliters\", \"liter\", \"liters\",\n",
    "        \"l\", \"pinch\", \"pinches\", \"dash\", \"dashes\", \"slice\", \"slices\", \"piece\", \"pieces\"\n",
    "    }\n",
    "    \n",
    "    cooking_words = {\n",
    "        \"chopped\", \"diced\", \"minced\", \"sliced\", \"grated\", \"shredded\", \"crushed\",\n",
    "        \"ground\", \"mashed\", \"pureed\", \"julienned\", \"cubed\", \"quartered\", \"halved\",\n",
    "        \"frozen\", \"fresh\", \"dried\", \"canned\", \"boiled\", \"steamed\", \"roasted\", \"baked\",\n",
    "        \"fried\", \"ripe\", \"raw\", \"cooked\", \"processed\", \"peeled\", \"pitted\"\n",
    "    }\n",
    "    \n",
    "    # Combine with NLTK stopwords\n",
    "    all_stopwords = set(stopwords.words('english')).union(measurement_units).union(cooking_words)\n",
    "    \n",
    "    # Initialize lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    cleaned_ingredients = []\n",
    "    \n",
    "    for ingredient in ingredient_names_list:\n",
    "        if not ingredient:\n",
    "            continue\n",
    "            \n",
    "        lower_ingredient = ingredient.lower()\n",
    "        if any(compound in lower_ingredient for compound in compound_ingredients):\n",
    "            # Just clean up numbers and extra punctuation but preserve the compound term\n",
    "            ingredient = re.sub(r'\\d+\\/?\\d*', '', lower_ingredient)\n",
    "            ingredient = re.sub(r'[^\\w\\s-]', '', ingredient).strip()\n",
    "            if ingredient in compound_ingredients:\n",
    "                cleaned_ingredients.append(ingredient)\n",
    "                continue\n",
    "        \n",
    "        # Process with spaCy for better part-of-speech tagging\n",
    "        doc = nlp(ingredient.lower())\n",
    "        \n",
    "        # Extract only nouns, skipping stopwords and lemmatizing\n",
    "        tokens = []\n",
    "        for token in doc:\n",
    "            # Keep only nouns and proper nouns\n",
    "            if token.pos_ in (\"NOUN\", \"PROPN\"):\n",
    "                lemma = lemmatizer.lemmatize(token.text)\n",
    "                if lemma.lower() not in all_stopwords and len(lemma) > 1:\n",
    "                    tokens.append(lemma.lower())\n",
    "        \n",
    "        if tokens:\n",
    "            cleaned_ingredients.append(\" \".join(tokens))\n",
    "    \n",
    "    return cleaned_ingredients\n",
    "\n",
    "# Modify the process_ingredients_with_ner function to include lemmatization\n",
    "def process_ingredients_with_ner_and_lemmatize(df, model_file):\n",
    "    \"\"\"Process all ingredients and extract names using NER model with lemmatization\"\"\"\n",
    "    processed_df = df.copy()\n",
    "    all_extracted_names = []\n",
    "    all_lemmatized_names = []\n",
    "    \n",
    "    print(\"Processing ingredients with NER model and lemmatization...\")\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        ingredient_text = row['ingredient']\n",
    "        \n",
    "        # Skip if ingredient is missing\n",
    "        if pd.isna(ingredient_text):\n",
    "            all_extracted_names.append(\"\")\n",
    "            all_lemmatized_names.append(\"\")\n",
    "            continue\n",
    "            \n",
    "        # Split by either \\n or \\\\n\n",
    "        ingredient_lines = re.split(r'\\\\n|\\n', str(ingredient_text))\n",
    "        \n",
    "        # Clean each line (remove leading \"- \" if present)\n",
    "        ingredient_lines = [line.strip('- ').strip() for line in ingredient_lines if line.strip()]\n",
    "        \n",
    "        try:\n",
    "            # Process all ingredient lines for this recipe at once\n",
    "            annotations = annotate_ner_robust(model_file, ingredient_lines)\n",
    "            \n",
    "            # Extract ingredient names from all annotations\n",
    "            extracted_names = []\n",
    "            for annotation in annotations:\n",
    "                ner_data = extract_ner_data(annotation)\n",
    "                names = extract_ingredient_names(ner_data)\n",
    "                if names:\n",
    "                    extracted_names.extend(names)\n",
    "            \n",
    "            # Store original extracted names\n",
    "            all_extracted_names.append(', '.join(extracted_names))\n",
    "            \n",
    "            # Apply lemmatization and cleaning\n",
    "            lemmatized_names = clean_ingredient_names(extracted_names)\n",
    "            all_lemmatized_names.append(', '.join(lemmatized_names))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {idx}: {e}\")\n",
    "            all_extracted_names.append(\"\")\n",
    "            all_lemmatized_names.append(\"\")\n",
    "    \n",
    "    # Add both the raw and lemmatized extracted names as new columns\n",
    "    processed_df['ner_ingredient'] = all_extracted_names\n",
    "    processed_df['lemmatized_ingredient'] = all_lemmatized_names\n",
    "    \n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50ea0f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ingredient extraction with lemmatization (first 100 rows only)...\n",
      "Processing sample of 100 rows\n",
      "Processing ingredients with NER model and lemmatization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]2025-05-23 09:17:33 WARNING: Setting 'start_server' to a boolean value when constructing CoreNLPClient is deprecated and will stop to function in a future version of stanza. Please consider switching to using a value from stanza.server.StartServer.\n",
      "2025-05-23 09:17:33 INFO: Writing properties to tmp file: corenlp_server-c96f08511bde4e52.props\n",
      "2025-05-23 09:17:33 INFO: Starting server with command: java -Xmx4G -cp C:\\Users\\Helena\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 48444 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-c96f08511bde4e52.props -annotators tokenize,ssplit,ner -outputFormat serialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting NER server on port: 48444\n",
      "Server successfully started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:10<?, ?it/s]\n",
      "  0%|          | 0/100 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing sample of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_sample)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Process only these 5 rows with lemmatization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m df_sample_with_ner = \u001b[43mprocess_ingredients_with_ner_and_lemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mExtraction complete! Results:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# print(df_sample_with_ner[['food_name', 'ingredient', 'ner_ingredient', 'lemmatized_ingredient']])\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 112\u001b[39m, in \u001b[36mprocess_ingredients_with_ner_and_lemmatize\u001b[39m\u001b[34m(df, model_file)\u001b[39m\n\u001b[32m    108\u001b[39m ingredient_lines = [line.strip(\u001b[33m'\u001b[39m\u001b[33m- \u001b[39m\u001b[33m'\u001b[39m).strip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m ingredient_lines \u001b[38;5;28;01mif\u001b[39;00m line.strip()]\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    111\u001b[39m     \u001b[38;5;66;03m# Process all ingredient lines for this recipe at once\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     annotations = \u001b[43mannotate_ner_robust\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mingredient_lines\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m     \u001b[38;5;66;03m# Extract ingredient names from all annotations\u001b[39;00m\n\u001b[32m    115\u001b[39m     extracted_names = []\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mannotate_ner_robust\u001b[39m\u001b[34m(ner_model_file, texts, tokenize_whitespace)\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mServer successfully started!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m tqdm(texts):\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m         annotated.append(\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mannotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m annotated\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\stanza\\server\\client.py:536\u001b[39m, in \u001b[36mCoreNLPClient.annotate\u001b[39m\u001b[34m(self, text, annotators, output_format, properties, reset_default, **kwargs)\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reset_default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    535\u001b[39m     reset_default = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m r = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_properties\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_default\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m request_properties[\u001b[33m\"\u001b[39m\u001b[33moutputFormat\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\stanza\\server\\client.py:461\u001b[39m, in \u001b[36mCoreNLPClient._request\u001b[39m\u001b[34m(self, buf, properties, reset_default, **kwargs)\u001b[39m\n\u001b[32m    459\u001b[39m     kwargs.pop(\u001b[33m'\u001b[39m\u001b[33musername\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    460\u001b[39m     kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mpassword\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m r = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mproperties\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mproperties\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mresetDefault\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreset_default\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontent-type\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mctype\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m*\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m/\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m r.raise_for_status()\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\requests\\api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python311\\Lib\\http\\client.py:1374\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1373\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1374\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1375\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1376\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python311\\Lib\\http\\client.py:318\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    320\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python311\\Lib\\http\\client.py:279\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    281\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python311\\Lib\\socket.py:705\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    704\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    707\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "# Run the processing on first 5 rows with lemmatization\n",
    "print(\"Starting ingredient extraction with lemmatization (first 100 rows only)...\")\n",
    "model_file_path = 'ar.model.ser.gz'  # This is the default filename format based on your code\n",
    "if os.path.exists(model_file_path):\n",
    "    # Take only the first 5 rows\n",
    "    df_sample = df.head(100).copy()\n",
    "    print(f\"Processing sample of {len(df_sample)} rows\")\n",
    "    \n",
    "    # Process only these 5 rows with lemmatization\n",
    "    df_sample_with_ner = process_ingredients_with_ner_and_lemmatize(df_sample, model_file_path)\n",
    "    \n",
    "    print(\"\\nExtraction complete! Results:\")\n",
    "    # print(df_sample_with_ner[['food_name', 'ingredient', 'ner_ingredient', 'lemmatized_ingredient']])\n",
    "    df_sample_with_ner[['food_name', 'ingredient', 'ner_ingredient', 'lemmatized_ingredient']]\n",
    "    # Save the sample processed dataframe to a different file name\n",
    "    df_sample_with_ner.to_excel('100_food_dataset_with_ner_lemmatized_sample.xlsx', index=False)\n",
    "    print(\"Saved sample dataset to 'food_dataset_with_ner_lemmatized_sample.xlsx'\")\n",
    "else:\n",
    "    print(\"NER model file not found. Cannot process ingredients.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe3d6906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_name</th>\n",
       "      <th>ingredient</th>\n",
       "      <th>ner_ingredient</th>\n",
       "      <th>lemmatized_ingredient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Edamame and Sweet Potato Dumplings (Oyaki)</td>\n",
       "      <td>- 30 g of sweet potato\\n- 20 g of edamame\\n- 5...</td>\n",
       "      <td>g, sweet potato, g of edamame, g of cornstarch...</td>\n",
       "      <td>sweet potato, edamame, cornstarch, bit water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chicken, Carrot, and Onion Udon For Babies</td>\n",
       "      <td>- 10 g of onion\\n- 10 g of chicken breast (pre...</td>\n",
       "      <td>g of onion, chicken breast, g of udon, ml, broth)</td>\n",
       "      <td>onion, chicken breast, udon, broth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kinaki Yogurt</td>\n",
       "      <td>- 2-3 tablespoons of plain yogurt \\n- A pinch ...</td>\n",
       "      <td>plain yogurt, soybean flour (kinako)</td>\n",
       "      <td>yogurt, soybean flour kinako</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natto Oyaki and Grilled Salmon</td>\n",
       "      <td>Natto Oyaki :\\n- 200g Japanese rice *steamed\\n...</td>\n",
       "      <td>Natto Oyaki :, Japanese rice *steamed, pack Na...</td>\n",
       "      <td>natto oyaki, rice, pack natto, onion, egg, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Miso Soup</td>\n",
       "      <td>- 120 ml of dashi \\n- 20 grams of tofu \\n- 1/4...</td>\n",
       "      <td>ml of dashi, grams of tofu, of miso paste</td>\n",
       "      <td>dashi, tofu, miso paste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Peach puree with pain d’épice</td>\n",
       "      <td>- 1/2 peach\\n- 1/2 slice of pain d’épice\\n- 1 ...</td>\n",
       "      <td>peach, of pain d’épice, petit-suisse</td>\n",
       "      <td>peach, pain d’épice, petit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Cream of pumpkin soup with thyme</td>\n",
       "      <td>- 150g pumpkin\\n- 1/3 onion\\n- 1 potato\\n- ½ t...</td>\n",
       "      <td>pumpkin, onion, potato, of crème fraîche</td>\n",
       "      <td>onion, potato, fraîche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Ham with pumpkin mash</td>\n",
       "      <td>- 10g cooked ham\\n- 200g pumpkin\\n- 2 measurin...</td>\n",
       "      <td>ham, pumpkin, measuring scoops of follow-on fo...</td>\n",
       "      <td>ham, scoop formula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Courgette and sweet potato puree with sage</td>\n",
       "      <td>- 1 sweet potato\\n- 1 small courgette\\n- 1 tab...</td>\n",
       "      <td>sweet potato, courgette, of crème fraîche, of ...</td>\n",
       "      <td>sweet potato, courgette, fraîche, sage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Soya porridge with mango puree</td>\n",
       "      <td>- 3 tablespoons of yellow cornflour\\n- 1 table...</td>\n",
       "      <td>yellow cornflour, soya powder, 150g mango pure...</td>\n",
       "      <td>yellow cornflour, soya powder, mango puree, su...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     food_name  \\\n",
       "0   Edamame and Sweet Potato Dumplings (Oyaki)   \n",
       "1   Chicken, Carrot, and Onion Udon For Babies   \n",
       "2                                Kinaki Yogurt   \n",
       "3               Natto Oyaki and Grilled Salmon   \n",
       "4                                    Miso Soup   \n",
       "..                                         ...   \n",
       "95               Peach puree with pain d’épice   \n",
       "96            Cream of pumpkin soup with thyme   \n",
       "97                       Ham with pumpkin mash   \n",
       "98  Courgette and sweet potato puree with sage   \n",
       "99              Soya porridge with mango puree   \n",
       "\n",
       "                                           ingredient  \\\n",
       "0   - 30 g of sweet potato\\n- 20 g of edamame\\n- 5...   \n",
       "1   - 10 g of onion\\n- 10 g of chicken breast (pre...   \n",
       "2   - 2-3 tablespoons of plain yogurt \\n- A pinch ...   \n",
       "3   Natto Oyaki :\\n- 200g Japanese rice *steamed\\n...   \n",
       "4   - 120 ml of dashi \\n- 20 grams of tofu \\n- 1/4...   \n",
       "..                                                ...   \n",
       "95  - 1/2 peach\\n- 1/2 slice of pain d’épice\\n- 1 ...   \n",
       "96  - 150g pumpkin\\n- 1/3 onion\\n- 1 potato\\n- ½ t...   \n",
       "97  - 10g cooked ham\\n- 200g pumpkin\\n- 2 measurin...   \n",
       "98  - 1 sweet potato\\n- 1 small courgette\\n- 1 tab...   \n",
       "99  - 3 tablespoons of yellow cornflour\\n- 1 table...   \n",
       "\n",
       "                                       ner_ingredient  \\\n",
       "0   g, sweet potato, g of edamame, g of cornstarch...   \n",
       "1   g of onion, chicken breast, g of udon, ml, broth)   \n",
       "2                plain yogurt, soybean flour (kinako)   \n",
       "3   Natto Oyaki :, Japanese rice *steamed, pack Na...   \n",
       "4           ml of dashi, grams of tofu, of miso paste   \n",
       "..                                                ...   \n",
       "95               peach, of pain d’épice, petit-suisse   \n",
       "96           pumpkin, onion, potato, of crème fraîche   \n",
       "97  ham, pumpkin, measuring scoops of follow-on fo...   \n",
       "98  sweet potato, courgette, of crème fraîche, of ...   \n",
       "99  yellow cornflour, soya powder, 150g mango pure...   \n",
       "\n",
       "                                lemmatized_ingredient  \n",
       "0        sweet potato, edamame, cornstarch, bit water  \n",
       "1                  onion, chicken breast, udon, broth  \n",
       "2                        yogurt, soybean flour kinako  \n",
       "3   natto oyaki, rice, pack natto, onion, egg, but...  \n",
       "4                             dashi, tofu, miso paste  \n",
       "..                                                ...  \n",
       "95                         peach, pain d’épice, petit  \n",
       "96                             onion, potato, fraîche  \n",
       "97                                 ham, scoop formula  \n",
       "98             sweet potato, courgette, fraîche, sage  \n",
       "99  yellow cornflour, soya powder, mango puree, su...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_with_ner[['food_name', 'ingredient', 'ner_ingredient', 'lemmatized_ingredient']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b028c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the dataset in batches\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_dataset_in_batches(df, model_file_path, batch_size=10, output_file='full_dataset_processed.xlsx'):\n",
    "    \"\"\"\n",
    "    Process the full dataset in smaller batches to avoid memory issues with CoreNLP\n",
    "    \"\"\"\n",
    "    print(f\"Processing full dataset of {len(df)} rows in batches of {batch_size}...\")\n",
    "    \n",
    "    # Initialize an empty DataFrame to store all results\n",
    "    all_results = pd.DataFrame()\n",
    "    \n",
    "    # Calculate the number of batches\n",
    "    num_batches = (len(df) // batch_size) + (1 if len(df) % batch_size > 0 else 0)\n",
    "    \n",
    "    for batch_num in range(num_batches):\n",
    "        # Calculate start and end indices for this batch\n",
    "        start_idx = batch_num * batch_size\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing Batch {batch_num+1}/{num_batches}, rows {start_idx}-{end_idx}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Extract the batch\n",
    "        batch_df = df.iloc[start_idx:end_idx].copy()\n",
    "        \n",
    "        # First, ensure any existing Java processes are killed before starting\n",
    "        kill_java_processes()\n",
    "        \n",
    "        try:\n",
    "            # Process this batch\n",
    "            batch_results = process_ingredients_with_ner_and_lemmatize(batch_df, model_file_path)\n",
    "            \n",
    "            # Save intermediate results\n",
    "            batch_file = f'batch_{batch_num+1}_of_{num_batches}.xlsx'\n",
    "            batch_results.to_excel(batch_file, index=False)\n",
    "            print(f\"Saved intermediate batch results to '{batch_file}'\")\n",
    "            \n",
    "            # Append to the full results\n",
    "            all_results = pd.concat([all_results, batch_results], ignore_index=True)\n",
    "            \n",
    "            # Save all results so far (in case of crash)\n",
    "            all_results.to_excel(output_file, index=False)\n",
    "            print(f\"Updated combined results in '{output_file}'\")\n",
    "            \n",
    "            # Remove previous batch file if it exists (keeping only the most recent)\n",
    "            if batch_num > 0:\n",
    "                prev_batch_file = f'batch_{batch_num}_of_{num_batches}.xlsx'\n",
    "                if os.path.exists(prev_batch_file):\n",
    "                    try:\n",
    "                        os.remove(prev_batch_file)\n",
    "                        print(f\"Removed previous batch file: {prev_batch_file}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Could not remove previous batch file: {e}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {batch_num+1}: {e}\")\n",
    "        \n",
    "        # After each batch, kill Java processes to free memory\n",
    "        kill_java_processes()\n",
    "    \n",
    "    print(f\"\\nProcessing complete! Processed {len(all_results)} rows in total.\")\n",
    "    print(f\"Final results saved to '{output_file}'\")\n",
    "    \n",
    "    # Clean up any remaining batch files\n",
    "    clean_up_batch_files(num_batches)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "def kill_java_processes():\n",
    "    \"\"\"Kill all Java processes more thoroughly\"\"\"\n",
    "    print(\"Cleaning up Java processes...\")\n",
    "    try:\n",
    "        # For Windows\n",
    "        subprocess.run(['taskkill', '/F', '/IM', 'java.exe'], capture_output=True)\n",
    "        \n",
    "        # Additional cleanup for potential Java server processes\n",
    "        subprocess.run(['netstat', '-ano'], capture_output=True, text=True)\n",
    "        \n",
    "        # Give system time to release resources\n",
    "        time.sleep(8)\n",
    "        print(\"Java processes terminated\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not kill Java processes: {e}\")\n",
    "\n",
    "def clean_up_batch_files(num_batches):\n",
    "    \"\"\"Clean up all batch files after completion\"\"\"\n",
    "    print(\"Cleaning up batch files...\")\n",
    "    for batch_num in range(1, num_batches + 1):\n",
    "        batch_file = f'batch_{batch_num}_of_{num_batches}.xlsx'\n",
    "        if os.path.exists(batch_file):\n",
    "            try:\n",
    "                os.remove(batch_file)\n",
    "                print(f\"Removed batch file: {batch_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not remove batch file {batch_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58987bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ingredient extraction with batch processing...\n",
      "Processing sample of 241 rows in batches\n",
      "Processing full dataset of 241 rows in batches of 20...\n",
      "\n",
      "============================================================\n",
      "Processing Batch 1/13, rows 0-20\n",
      "============================================================\n",
      "Cleaning up Java processes...\n",
      "Java processes terminated\n",
      "Processing ingredients with NER model and lemmatization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]2025-05-23 13:35:58 WARNING: Setting 'start_server' to a boolean value when constructing CoreNLPClient is deprecated and will stop to function in a future version of stanza. Please consider switching to using a value from stanza.server.StartServer.\n",
      "2025-05-23 13:35:58 INFO: Writing properties to tmp file: corenlp_server-8084e2f6367148fd.props\n",
      "2025-05-23 13:35:58 INFO: Starting server with command: java -Xmx6G -cp C:\\Users\\Helena\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 30749 -timeout 120000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-8084e2f6367148fd.props -annotators tokenize,ssplit,ner -outputFormat serialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting NER server on port: 30749, control port: 31749\n",
      "Using memory: 6G, timeout: 120000ms\n",
      "Server successfully started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:15<?, ?it/s]\n",
      "  0%|          | 0/20 [00:21<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 135\u001b[39m\n\u001b[32m    132\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing sample of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_to_process)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows in batches\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    134\u001b[39m     \u001b[38;5;66;03m# Process in batches of 20 rows\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     processed_df = \u001b[43mprocess_dataset_in_batches\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdf_to_process\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2nd_food_dataset_with_ner_lemmatized.xlsx\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBatch processing complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mprocess_dataset_in_batches\u001b[39m\u001b[34m(df, model_file_path, batch_size, output_file)\u001b[39m\n\u001b[32m     37\u001b[39m kill_java_processes()\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# Process this batch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     batch_results = \u001b[43mprocess_ingredients_with_ner_and_lemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m# Save intermediate results\u001b[39;00m\n\u001b[32m     43\u001b[39m     batch_file = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbatch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_num+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_of_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_batches\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.xlsx\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 112\u001b[39m, in \u001b[36mprocess_ingredients_with_ner_and_lemmatize\u001b[39m\u001b[34m(df, model_file)\u001b[39m\n\u001b[32m    108\u001b[39m ingredient_lines = [line.strip(\u001b[33m'\u001b[39m\u001b[33m- \u001b[39m\u001b[33m'\u001b[39m).strip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m ingredient_lines \u001b[38;5;28;01mif\u001b[39;00m line.strip()]\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    111\u001b[39m     \u001b[38;5;66;03m# Process all ingredient lines for this recipe at once\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     annotations = \u001b[43mannotate_ner_robust\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mingredient_lines\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m     \u001b[38;5;66;03m# Extract ingredient names from all annotations\u001b[39;00m\n\u001b[32m    115\u001b[39m     extracted_names = []\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 114\u001b[39m, in \u001b[36mannotate_ner_robust\u001b[39m\u001b[34m(ner_model_file, texts, tokenize_whitespace, memory, timeout)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m tqdm(texts):\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    113\u001b[39m         \u001b[38;5;66;03m# Handle potential CoreNLP timeouts for individual texts\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         result = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mannotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m         annotated.append(result)\n\u001b[32m    116\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\stanza\\server\\client.py:536\u001b[39m, in \u001b[36mCoreNLPClient.annotate\u001b[39m\u001b[34m(self, text, annotators, output_format, properties, reset_default, **kwargs)\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reset_default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    535\u001b[39m     reset_default = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m r = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_properties\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_default\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m request_properties[\u001b[33m\"\u001b[39m\u001b[33moutputFormat\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\stanza\\server\\client.py:461\u001b[39m, in \u001b[36mCoreNLPClient._request\u001b[39m\u001b[34m(self, buf, properties, reset_default, **kwargs)\u001b[39m\n\u001b[32m    459\u001b[39m     kwargs.pop(\u001b[33m'\u001b[39m\u001b[33musername\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    460\u001b[39m     kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mpassword\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m r = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mproperties\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mproperties\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mresetDefault\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreset_default\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontent-type\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mctype\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m*\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m/\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m r.raise_for_status()\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\requests\\api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Helena\\Desktop\\APU\\Semester 5\\INV\\IR - PROPOSAL\\scraping-code\\.venv\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python311\\Lib\\http\\client.py:1374\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1373\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1374\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1375\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1376\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python311\\Lib\\http\\client.py:318\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    320\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python311\\Lib\\http\\client.py:279\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    281\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python311\\Lib\\socket.py:705\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    704\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    707\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Process the dataset in batches\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_dataset_in_batches(df, model_file_path, batch_size=10, output_file='full_dataset_processed.xlsx'):\n",
    "    \"\"\"\n",
    "    Process the full dataset in smaller batches to avoid memory issues with CoreNLP\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with recipe data\n",
    "        model_file_path: Path to the NER model\n",
    "        batch_size: Number of recipes to process in each batch\n",
    "        output_file: Output file name for the complete processed data\n",
    "    \"\"\"\n",
    "    print(f\"Processing full dataset of {len(df)} rows in batches of {batch_size}...\")\n",
    "    \n",
    "    # Initialize an empty DataFrame to store all results\n",
    "    all_results = pd.DataFrame()\n",
    "    \n",
    "    # Calculate the number of batches\n",
    "    num_batches = (len(df) // batch_size) + (1 if len(df) % batch_size > 0 else 0)\n",
    "    \n",
    "    for batch_num in range(num_batches):\n",
    "        # Calculate start and end indices for this batch\n",
    "        start_idx = batch_num * batch_size\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing Batch {batch_num+1}/{num_batches}, rows {start_idx}-{end_idx}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Extract the batch\n",
    "        batch_df = df.iloc[start_idx:end_idx].copy()\n",
    "        kill_java_processes()\n",
    "        try:\n",
    "            # Process this batch\n",
    "            batch_results = process_ingredients_with_ner_and_lemmatize(batch_df, model_file_path)\n",
    "            \n",
    "            # Save intermediate results\n",
    "            batch_file = f'batch_{batch_num+1}_of_{num_batches}.xlsx'\n",
    "            batch_results.to_excel(batch_file, index=False)\n",
    "            print(f\"Saved intermediate batch results to '{batch_file}'\")\n",
    "            \n",
    "            # Append to the full results\n",
    "            all_results = pd.concat([all_results, batch_results], ignore_index=True)\n",
    "            \n",
    "            # Save all results so far (in case of crash)\n",
    "            all_results.to_excel(output_file, index=False)\n",
    "            print(f\"Updated combined results in '{output_file}'\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {batch_num+1}: {e}\")\n",
    "            \n",
    "        # Make sure to kill all Java processes to free memory\n",
    "        try:\n",
    "            subprocess.run(['taskkill', '/F', '/IM', 'java.exe'], capture_output=True)\n",
    "            print(\"Killed Java processes to free memory\")\n",
    "            time.sleep(10)  # Give more time to fully release resources between batches\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not kill Java processes: {e}\")\n",
    "    \n",
    "    print(f\"\\nProcessing complete! Processed {len(all_results)} rows in total.\")\n",
    "    print(f\"Final results saved to '{output_file}'\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# Enhanced annotate_ner_robust function with better timeout and memory management\n",
    "def annotate_ner_robust(ner_model_file, texts, tokenize_whitespace=True, memory='6G', timeout=120000):\n",
    "    \"\"\"An enhanced version of annotate_ner that handles memory and timeouts better\"\"\"\n",
    "    # Kill any lingering Java processes\n",
    "    try:\n",
    "        subprocess.run(['taskkill', '/F', '/IM', 'java.exe'], capture_output=True)\n",
    "        time.sleep(5)  # Give system time to release resources\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not kill Java processes: {e}\")\n",
    "    \n",
    "    # Use higher port numbers to avoid conflicts\n",
    "    server_port = random.randint(20000, 50000)\n",
    "    control_port = server_port + 1000\n",
    "    \n",
    "    print(f\"Starting NER server on port: {server_port}, control port: {control_port}\")\n",
    "    print(f\"Using memory: {memory}, timeout: {timeout}ms\")\n",
    "    \n",
    "    properties = {\n",
    "        \"ner.model\": ner_model_file, \n",
    "        \"tokenize.whitespace\": tokenize_whitespace, \n",
    "        \"ner.applyNumericClassifiers\": False\n",
    "    }\n",
    "    \n",
    "    annotated = []\n",
    "    with CoreNLPClient(\n",
    "         annotators=['tokenize','ssplit','ner'],\n",
    "         properties=properties,\n",
    "         timeout=timeout,  # Increased timeout\n",
    "         be_quiet=True,\n",
    "         port=server_port,\n",
    "         start_server=True,\n",
    "         control_port=control_port,\n",
    "         preload=False,\n",
    "         memory=memory,    # More memory for larger batches\n",
    "         endpoint=f'http://localhost:{server_port}',\n",
    "         max_char_length=100000  # Support longer texts\n",
    "    ) as client:\n",
    "        \n",
    "        print(\"Server successfully started!\")\n",
    "        \n",
    "        # Process items with progress bar\n",
    "        for text in tqdm(texts):\n",
    "            try:\n",
    "                # Handle potential CoreNLP timeouts for individual texts\n",
    "                result = client.annotate(text)\n",
    "                annotated.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Error annotating text: {e}\")\n",
    "                print(f\"Problematic text: {text[:100]}...\")\n",
    "                # Add None to maintain index alignment\n",
    "                annotated.append(None)\n",
    "            \n",
    "    return annotated\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting ingredient extraction with batch processing...\")\n",
    "    model_file_path = 'ar.model.ser.gz'\n",
    "    \n",
    "    if os.path.exists(model_file_path):\n",
    "        # For testing, process first 100 rows\n",
    "        df_to_process = df.head(400).copy()  # Adjust number as needed\n",
    "        print(f\"Processing sample of {len(df_to_process)} rows in batches\")\n",
    "        \n",
    "        # Process in batches of 20 rows\n",
    "        processed_df = process_dataset_in_batches(\n",
    "            df_to_process, \n",
    "            model_file_path, \n",
    "            batch_size=20,\n",
    "            output_file='2nd_food_dataset_with_ner_lemmatized.xlsx'\n",
    "        )\n",
    "        \n",
    "        \n",
    "        print(\"\\nBatch processing complete!\")\n",
    "    else:\n",
    "        print(\"NER model file not found. Cannot process ingredients.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab83b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting ingredient extraction with batch processing...\")\n",
    "    model_file_path = 'ar.model.ser.gz'\n",
    "    \n",
    "    if os.path.exists(model_file_path):\n",
    "        # For testing, process first 100 rows\n",
    "        df_to_process = df.head(400).copy()  # Adjust number as needed\n",
    "        print(f\"Processing sample of {len(df_to_process)} rows in batches\")\n",
    "        \n",
    "        # Process in batches of 20 rows\n",
    "        processed_df = process_dataset_in_batches(\n",
    "            df_to_process, \n",
    "            model_file_path, \n",
    "            batch_size=20,\n",
    "            output_file='4nd_food_dataset_with_ner_lemmatized.xlsx'\n",
    "        )\n",
    "        \n",
    "        \n",
    "        print(\"\\nBatch processing complete!\")\n",
    "    else:\n",
    "        print(\"NER model file not found. Cannot process ingredients.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 567.381694,
   "end_time": "2022-04-07T13:06:56.199628",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-07T12:57:28.817934",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04e4948e123444569b4b09d696e122ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "05cf3b36eb1e4ddb9c4f9b675fdd6b1d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "081d02fab37a4e29bd2531213f508808": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f688a6aae02749a6874511e7c4d0da95",
       "max": 1705,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a6e2ba7f52a042fb8f3595b50c406bc6",
       "value": 1705
      }
     },
     "0b95b19116f44d5dae17156430a708ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1455809b8e1945e0bebdc8ea8adcc87d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "15dca12ce1ee4b8ca4ec62aa8864f8c7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "171199414c5a4954b0ac767628554d8b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "183452cec8804fd5903953436a43bf20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e4473ff688a9440690198f9e4cf6858e",
       "placeholder": "​",
       "style": "IPY_MODEL_2474d59c1f9d47d4b59ffef46d4f8443",
       "value": " 483/483 [00:29&lt;00:00, 41.45it/s]"
      }
     },
     "19c7b297a53444608e29aa3fcce236b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1a8c3ed5abda483baee14f7c855449cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_337d520658594202b091a3a25a60ab2c",
       "placeholder": "​",
       "style": "IPY_MODEL_46133dd43dca46eba08636f28973f190",
       "value": " 483/483 [00:28&lt;00:00, 37.52it/s]"
      }
     },
     "1fe61ae43c2f4a9b93b25d6c60204c8a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "20145d12fdbb45a8a3c7ed1126260403": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "214063d8f2bf4d2f854bdfaa75dd3469": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_661e0655ba4b41139b1be60f73f4ea87",
       "placeholder": "​",
       "style": "IPY_MODEL_385d18bccb9245548deed2a3b554525c",
       "value": " 1705/1705 [01:00&lt;00:00, 36.52it/s]"
      }
     },
     "21a60b9d20784d38afdbdbdf9fa74f78": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2474d59c1f9d47d4b59ffef46d4f8443": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "263283c3d0764d38b9c3d1ddb6c8b427": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_20145d12fdbb45a8a3c7ed1126260403",
       "placeholder": "​",
       "style": "IPY_MODEL_a7eb0e99aee4463785eea58d0cc847af",
       "value": " 1705/1705 [01:00&lt;00:00, 34.91it/s]"
      }
     },
     "26e07430d6f54a9bbd9acea509197ce1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4191ab859c984f81a50aeb218fc1ac5a",
        "IPY_MODEL_c03a18909027459681be5a9113e88a0a",
        "IPY_MODEL_1a8c3ed5abda483baee14f7c855449cd"
       ],
       "layout": "IPY_MODEL_f04f3af815f24025b341de0249819145"
      }
     },
     "28efee3ebc4b44e4a2411844af855e92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_53c764a85af5434eabf8513c4a5e8e6f",
       "placeholder": "​",
       "style": "IPY_MODEL_9ad75aea6d7341dba7d6e56cf625c10b",
       "value": "100%"
      }
     },
     "2a539d7b18e4425abbd7ae22e76a26fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2b5a6815608b41d69923bd5e845385a3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "316de487dcb041e9aef79533ede9ab20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "337d520658594202b091a3a25a60ab2c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "345e4d287bd24ae9975f3be4e2027c4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "385d18bccb9245548deed2a3b554525c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "38d19c56c37947469a993acb7f0213a0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "39c71bb6e43e4330b2b149c25da98d1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_28efee3ebc4b44e4a2411844af855e92",
        "IPY_MODEL_8bc62d6d2ec34b848127dfe4d57b8c0e",
        "IPY_MODEL_a9267cfc2fb54d408ab6377e7cf9a2cb"
       ],
       "layout": "IPY_MODEL_ec60bd5d40374f4296bf13b4d1a6e957"
      }
     },
     "3cc71d45aca94e189e597f9532b0ff83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "40754c3ca8c049eeaf44280e861bb455": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2a539d7b18e4425abbd7ae22e76a26fa",
       "placeholder": "​",
       "style": "IPY_MODEL_345e4d287bd24ae9975f3be4e2027c4c",
       "value": "Downloading https://huggingface.co/stanfordnlp/CoreNLP/resolve/main/stanford-corenlp-latest.zip: 100%"
      }
     },
     "4191ab859c984f81a50aeb218fc1ac5a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4827280778c24f8ca7bfc579f2bc0806",
       "placeholder": "​",
       "style": "IPY_MODEL_5fe9b045a4014a4a80ab8190de207966",
       "value": "100%"
      }
     },
     "42e7709bb52842e999ccf9a7a385973a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_aacee86f941e404b8c9f0345c0e85a94",
       "placeholder": "​",
       "style": "IPY_MODEL_04e4948e123444569b4b09d696e122ea",
       "value": "100%"
      }
     },
     "44ca9e6935704d00925e55eaf8f5e5ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_38d19c56c37947469a993acb7f0213a0",
       "placeholder": "​",
       "style": "IPY_MODEL_0b95b19116f44d5dae17156430a708ec",
       "value": "100%"
      }
     },
     "46133dd43dca46eba08636f28973f190": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "47ef62581c17433e93855d6789befc2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_21a60b9d20784d38afdbdbdf9fa74f78",
       "placeholder": "​",
       "style": "IPY_MODEL_ae9e033f42884508ac8a7f49f6e62c2a",
       "value": "100%"
      }
     },
     "4827280778c24f8ca7bfc579f2bc0806": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4b524361ba0947b9af302faa8518050f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_73fc8072162e45de89abf389fa5d4b90",
       "max": 1705,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5012502d87f24cd192200979e56af080",
       "value": 1705
      }
     },
     "5012502d87f24cd192200979e56af080": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "53c764a85af5434eabf8513c4a5e8e6f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "555a9bda2a024e9a8a9abc444e4fe4cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_15dca12ce1ee4b8ca4ec62aa8864f8c7",
       "max": 505207915,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_730961bd290541e9a01938ca4876beb9",
       "value": 505207915
      }
     },
     "5ae58c17d7a2462dadf527338d943cea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_47ef62581c17433e93855d6789befc2b",
        "IPY_MODEL_757532f367d248dcb369c157e5565861",
        "IPY_MODEL_263283c3d0764d38b9c3d1ddb6c8b427"
       ],
       "layout": "IPY_MODEL_76e64492e3d7480aa2d96bfc56f3cfa8"
      }
     },
     "5cb06a46903341a9b50676a31addad14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5fe9b045a4014a4a80ab8190de207966": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "652276ddba8640708df4285c1ddf5ff9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8e12508157c44fbcbb77aac67bc12549",
        "IPY_MODEL_4b524361ba0947b9af302faa8518050f",
        "IPY_MODEL_71093fc9838b4e9ea8a1fbeda6150111"
       ],
       "layout": "IPY_MODEL_2b5a6815608b41d69923bd5e845385a3"
      }
     },
     "661e0655ba4b41139b1be60f73f4ea87": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "67197e8331f74dd1a7ae96d9d4ee7490": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_75992a1df6f6420e8bc06349c0a99076",
       "max": 483,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_93654bad7fcf4739bb54a6b45c60c5ed",
       "value": 483
      }
     },
     "6a9d691c650c4d779882190429cbe86b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_05cf3b36eb1e4ddb9c4f9b675fdd6b1d",
       "placeholder": "​",
       "style": "IPY_MODEL_5cb06a46903341a9b50676a31addad14",
       "value": " 505M/505M [00:30&lt;00:00, 17.9MB/s]"
      }
     },
     "6fc700ddba53400b889b51216731058b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "71093fc9838b4e9ea8a1fbeda6150111": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8594609c694247669c25c78c8ded0342",
       "placeholder": "​",
       "style": "IPY_MODEL_b9e45e43c1ae4ff483e64abefa8ed8de",
       "value": " 1705/1705 [01:02&lt;00:00, 37.06it/s]"
      }
     },
     "730961bd290541e9a01938ca4876beb9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "73fc8072162e45de89abf389fa5d4b90": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "757532f367d248dcb369c157e5565861": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_acb9785ff9dc422bb40cb371d4180419",
       "max": 1705,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c7ab303608734bf18388966fda9a2d77",
       "value": 1705
      }
     },
     "75992a1df6f6420e8bc06349c0a99076": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "75b56360c2064ec2b7b5d7d4bdc22d42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c84f6aba9d924d5ba166018593531c9a",
       "placeholder": "​",
       "style": "IPY_MODEL_cdf8f8e1213e4056aff15837fd6cd1b8",
       "value": " 4/4 [00:13&lt;00:00,  3.62s/it]"
      }
     },
     "76e64492e3d7480aa2d96bfc56f3cfa8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f60ca33e67449c1bab4a7c52e290d35": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8594609c694247669c25c78c8ded0342": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "87190b2caa46403a82d7cb69319b1262": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_44ca9e6935704d00925e55eaf8f5e5ec",
        "IPY_MODEL_67197e8331f74dd1a7ae96d9d4ee7490",
        "IPY_MODEL_183452cec8804fd5903953436a43bf20"
       ],
       "layout": "IPY_MODEL_c12c8164a6f2450b804b2f350ed2d580"
      }
     },
     "8ab8307799ba406e85852cb620015885": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_42e7709bb52842e999ccf9a7a385973a",
        "IPY_MODEL_081d02fab37a4e29bd2531213f508808",
        "IPY_MODEL_214063d8f2bf4d2f854bdfaa75dd3469"
       ],
       "layout": "IPY_MODEL_171199414c5a4954b0ac767628554d8b"
      }
     },
     "8bc62d6d2ec34b848127dfe4d57b8c0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7f60ca33e67449c1bab4a7c52e290d35",
       "max": 483,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_99a70625c1a5402e9214a7dc5ed53cd1",
       "value": 483
      }
     },
     "8e12508157c44fbcbb77aac67bc12549": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e6207369245244299c4e72cab9ee9e6f",
       "placeholder": "​",
       "style": "IPY_MODEL_316de487dcb041e9aef79533ede9ab20",
       "value": "100%"
      }
     },
     "92d594f090a64ae0994bb4e7e59a362b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1455809b8e1945e0bebdc8ea8adcc87d",
       "max": 4,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3cc71d45aca94e189e597f9532b0ff83",
       "value": 4
      }
     },
     "93654bad7fcf4739bb54a6b45c60c5ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "94f4b01c55604c8ead1ebc742ec981dc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "99a70625c1a5402e9214a7dc5ed53cd1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9ad75aea6d7341dba7d6e56cf625c10b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9c0da7f9ecde470a8ad513bd82b4e638": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_eaa545004794465bb69a876a78e8386c",
        "IPY_MODEL_92d594f090a64ae0994bb4e7e59a362b",
        "IPY_MODEL_75b56360c2064ec2b7b5d7d4bdc22d42"
       ],
       "layout": "IPY_MODEL_beca40aef11d4d4fbcc39c9f54709889"
      }
     },
     "a6e2ba7f52a042fb8f3595b50c406bc6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a7eb0e99aee4463785eea58d0cc847af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a9267cfc2fb54d408ab6377e7cf9a2cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6fc700ddba53400b889b51216731058b",
       "placeholder": "​",
       "style": "IPY_MODEL_d9376b3ffa6741409f6218d1041020cf",
       "value": " 483/483 [00:34&lt;00:00, 38.36it/s]"
      }
     },
     "aacee86f941e404b8c9f0345c0e85a94": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "acb9785ff9dc422bb40cb371d4180419": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ae9e033f42884508ac8a7f49f6e62c2a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b90172ce78ce4c519efa02f06f3c6835": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_40754c3ca8c049eeaf44280e861bb455",
        "IPY_MODEL_555a9bda2a024e9a8a9abc444e4fe4cf",
        "IPY_MODEL_6a9d691c650c4d779882190429cbe86b"
       ],
       "layout": "IPY_MODEL_fbe7eab600d2483e98a914ba761c293b"
      }
     },
     "b9e45e43c1ae4ff483e64abefa8ed8de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "beca40aef11d4d4fbcc39c9f54709889": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c03a18909027459681be5a9113e88a0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_19c7b297a53444608e29aa3fcce236b9",
       "max": 483,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1fe61ae43c2f4a9b93b25d6c60204c8a",
       "value": 483
      }
     },
     "c12c8164a6f2450b804b2f350ed2d580": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c7ab303608734bf18388966fda9a2d77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c84f6aba9d924d5ba166018593531c9a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cda950e3c9bc4afdb263d7e294ad4276": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cdf8f8e1213e4056aff15837fd6cd1b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d9376b3ffa6741409f6218d1041020cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e4473ff688a9440690198f9e4cf6858e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e6207369245244299c4e72cab9ee9e6f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eaa545004794465bb69a876a78e8386c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_94f4b01c55604c8ead1ebc742ec981dc",
       "placeholder": "​",
       "style": "IPY_MODEL_cda950e3c9bc4afdb263d7e294ad4276",
       "value": "100%"
      }
     },
     "ec60bd5d40374f4296bf13b4d1a6e957": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f04f3af815f24025b341de0249819145": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f688a6aae02749a6874511e7c4d0da95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fbe7eab600d2483e98a914ba761c293b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe02c62b",
   "metadata": {},
   "source": [
    "# Data Pre processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269ec308",
   "metadata": {},
   "source": [
    "### **Data Preparation**\n",
    "<p>Populating Necessary Data</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c362deaf",
   "metadata": {},
   "source": [
    "##### **Extracting NER Ingredients From Original Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262c913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open Excel File\n",
    "import openpyxl\n",
    "import os\n",
    "\n",
    "# Load the workbook\n",
    "workbook = openpyxl.load_workbook('dataset.xlsx')\n",
    "\n",
    "# Select the active worksheet\n",
    "worksheet = workbook[\"Sheet1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a706a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = []\n",
    "headers = []\n",
    "\n",
    "# Get headers from the first row\n",
    "for col in range(1, worksheet.max_column + 1):\n",
    "    headers.append(worksheet.cell(row=1, column=col).value)\n",
    "\n",
    "# Get data from remaining rows\n",
    "for row in range(2, worksheet.max_row + 1):\n",
    "    row_data = []\n",
    "    for col in range(1, worksheet.max_column + 1):\n",
    "        row_data.append(worksheet.cell(row=row, column=col).value)\n",
    "    data.append(row_data)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "print(headers)\n",
    "\n",
    "# Display first few rows to verify\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb46ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all column names to verify\n",
    "print(\"Column names:\", df.columns.tolist())\n",
    "\n",
    "# Drop None value column if it exists\n",
    "none_columns = [col for col in df.columns if col is None]\n",
    "if none_columns:\n",
    "    df = df.drop(columns=none_columns)\n",
    "    print(f\"Dropped {len(none_columns)} None column(s)\")\n",
    "\n",
    "# Display all column names to verify\n",
    "print(\"Column post-clean:\", df.columns.tolist())\n",
    "print(f\"Dataset shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda2912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renamed columns\n",
    "df = df.rename(columns={\n",
    "    'Food Name' : 'food_name',\n",
    "    'Ingredients' : 'ingredient',\n",
    "    'Instructions' : 'instructions',\n",
    "    'Min Age Group ': 'min_age_group',\n",
    "    'Max Age Group ': 'max_age_group',\n",
    "    'NER Ingredient': 'ner_ingredient',\n",
    "    'Texture': 'texture',\n",
    "    'Prep Time': 'prep_time',\n",
    "    'Cook Time': 'cook_time',\n",
    "    'Serving': 'serving',\n",
    "    'Difficulty': 'difficulty',\n",
    "    'Origin': 'origin',\n",
    "    'Region': 'region',\n",
    "    'Description': 'description',\n",
    "    'Image Link ': 'image_link',\n",
    "    'Link ': 'recipe_link',\n",
    "    'Credibility ': 'credibility',\n",
    "    'Meal Type': 'meal_type',\n",
    "    'Flavor_type': 'flavor_type',\n",
    "    'Dietary Tags': 'dietary_tags',\n",
    "    'Choking Hazards': 'choking_hazards',\n",
    "    'Nutrion Value': 'nutrition_value',\n",
    "    'tips': 'tips',\n",
    "    'Allergen': 'allergen',\n",
    "    'Hypoallergenic': 'hypoallergenic',\n",
    "})\n",
    "\n",
    "print(\"Column name post-clean:\", df.columns.tolist())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1a1a96",
   "metadata": {},
   "source": [
    "<p>Checking Any Null Value</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfcc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check every column for null values\n",
    "for col in df.columns:\n",
    "    null_count = df[col].isnull().sum()\n",
    "    if null_count > 0:\n",
    "        print(f\"Column '{col}' has {null_count} null values.\")\n",
    "    else:\n",
    "        print(f\"Column '{col}' has no null values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a3a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop data if imporant columns are empty\n",
    "important_columns = ['food_name', 'ingredient', 'instructions', 'recipe_link']\n",
    "for col in df.columns:\n",
    "    if col in important_columns:\n",
    "        null_count = df[col].isnull().sum()        \n",
    "        if null_count >0:\n",
    "            df = df.dropna(subset=[col])\n",
    "\n",
    "# After dropping rows, you may want to reset the index if needed\n",
    "df = df.reset_index(drop=True)\n",
    "# Display the cleaned DataFrame\n",
    "print(\"Cleaned DataFrame:\")\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3758ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dietary_tags'] = ''\n",
    "df['choking_hazards'] = ''\n",
    "df['difficulty'] = ''\n",
    "df['allergen'] = ''\n",
    "df['hypoallergenic'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd51bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = df.copy()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4475371b",
   "metadata": {},
   "source": [
    "<p>Formatting Ingredient and Instruction</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e6b0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_already_formatted(text):\n",
    "    return '\\n' in text or '\\\\n' in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af8399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Normalize Ingredients ---\n",
    "def normalize_ingredients(text):\n",
    "    if is_already_formatted(text):\n",
    "        return text.replace('\\n', '\\\\n') if '\\n' in text else text\n",
    "\n",
    "    lines = []\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Try splitting by common delimiters\n",
    "    if ' - ' in text:\n",
    "        parts = text.split(' - ')\n",
    "    elif '•' in text:\n",
    "        parts = [p.strip() for p in text.split('•') if p.strip()]\n",
    "    elif ',' in text:\n",
    "        parts = [p.strip() for p in text.split(',') if p.strip()]\n",
    "    elif re.search(r'\\d+\\. ', text):\n",
    "        parts = re.split(r'\\d+\\. ', text)\n",
    "    else:\n",
    "        parts = [text]\n",
    "\n",
    "    for part in parts:\n",
    "        part = re.sub(r'^\\d+\\. ?', '', part).strip()\n",
    "        if part:\n",
    "            lines.append('- ' + part)\n",
    "\n",
    "    return '\\\\n'.join(lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5609914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Normalize Instructions ---\n",
    "def normalize_instructions(text):\n",
    "    if is_already_formatted(text):\n",
    "        return text.replace('\\n', '\\\\n') if '\\n' in text else text\n",
    "\n",
    "    lines = []\n",
    "    text = re.sub(r'\\r\\n|\\r', '\\n', text).strip()\n",
    "\n",
    "    # Match numbered or step-based patterns\n",
    "    step_pattern = r'(?:Step\\s*\\d+:\\s*|\\d+\\.\\s*)([^:.]+?)(?=\\s*(?:Step\\s*\\d+:\\s*|\\d+\\.\\s*|$))'\n",
    "    matches = re.findall(step_pattern, text, re.IGNORECASE)\n",
    "\n",
    "    if matches:\n",
    "        parts = [m.strip() for m in matches if m.strip()]\n",
    "    else:\n",
    "        # Split by sentences\n",
    "        parts = re.split(r'(?<=[.!?])\\s+', text)\n",
    "\n",
    "    for i, part in enumerate(parts):\n",
    "        part = re.sub(r'\\s+', ' ', part).strip()\n",
    "        if part:\n",
    "            lines.append(f\"{i+1}. {part}\")\n",
    "\n",
    "    return '\\\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b95c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the 'ingredient' and 'instructions' columns\n",
    "df['ingredient'] = df['ingredient'].apply(normalize_ingredients)\n",
    "df['instructions'] = df['instructions'].apply(normalize_instructions)\n",
    "\n",
    "df_real[['ingredient','instructions']].head()\n",
    "print(\"Normalized DataFrame:\")\n",
    "df[['ingredient','instructions']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdfd4f3",
   "metadata": {},
   "source": [
    "<p>Extract Ingredient Name</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c78456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "# Load spaCy model and lemmatizer\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords = {\n",
    "    # Common general stopwords\n",
    "    \"a\", \"an\", \"the\", \"of\", \"to\", \"and\", \"in\", \"on\", \"for\", \"with\", \"by\",\n",
    "    \"as\", \"at\", \"be\", \"is\", \"was\", \"are\", \"were\", \"it\", \"this\", \"that\",\n",
    "\n",
    "    # Recipe-specific words\n",
    "    \"finely\", \"stalk\", \"optional\", \"pinch\", \"dash\", \"sprinkle\", \"to taste\", \"fresh\", \"ripe\",\n",
    "    \"whole\", \"cut\", \"slice\", \"diced\", \"chopped\", \"grated\", \"crushed\",\n",
    "    \"halved\", \"quartered\", \"peeled\", \"mashed\", \"blended\", \"cooked\",\n",
    "    \"steamed\", \"boiled\", \"baked\", \"roasted\", \"toasted\", \"minced\", \"pureed\",\n",
    "    \"thinly\", \"soft\", \"ripe\", \"unsalted\", \"lowfat\", \"low-fat\", \"plain\",\n",
    "    \"unsweetened\", \"organic\", \"natural\", \"canned\", \"frozen\", \"freshly\",\n",
    "    \"ground\", \"powder\", \"sized\", \"pieces\", \"piece\", \"part\", \"parts\",\n",
    "    \"measure\", \"measured\", \"add\", \"mix\", \"combine\", \"stir\", \"fold\",\n",
    "    \"whisk\", \"blend\", \"mash\", \"chop\", \"dice\", \"grate\", \"steam\", \"boil\",\n",
    "    \"bake\", \"roast\", \"toast\", \"mince\", \"puree\", \"soak\", \"rinse\", \"drain\",\n",
    "    \"preheat\", \"oven\", \"medium\", \"high\", \"low\", \"heat\", \"temperature\",\n",
    "    \"minutes\", \"minute\", \"hours\", \"hour\", \"time\", \"until\", \"softened\",\n",
    "    \"cooled\", \"warm\", \"room temperature\", \"raw\", \"uncooked\", \"cooked\",\n",
    "    \"leftover\", \"any kind\", \"preferably\", \"fresh\", \"store-bought\",\n",
    "    \"homemade\", \"prepared\", \"ready-to-use\", \"instant\", \"cubed\", \"thin slices\",\n",
    "    \"small\", \"medium\", \"large\", \"few\", \"bit\", \"bits\", \"drop\", \"drops\"\n",
    "}\n",
    "\n",
    "# Combine with NLTK's English stopwords\n",
    "STOPWORDS = set(nltk_stopwords.words('english')).union(custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d529aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "\n",
    "def extract_clean_ingredient(line):\n",
    "\n",
    "    nltk.download('wordnet')\n",
    "    \n",
    "    \"\"\"\n",
    "    Extracts and cleans a single ingredient line from a baby recipe.\n",
    "\n",
    "    Args:\n",
    "        line (str): Raw ingredient line like \"- 1 ripe banana\"\n",
    "\n",
    "    Returns:\n",
    "        str: Cleaned ingredient name like \"banana\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Remove numbers and fractions\n",
    "    line = re.sub(r'\\d+\\/?\\d*', '', line)\n",
    "\n",
    "    # Step 2: Remove units of measurement (expanded list)\n",
    "    line = re.sub(\n",
    "        r'\\b(g|gm|gms|gram|grams|kg|kgs|kilogram|kilograms|'\n",
    "        r'mg|mgs|milligram|milligrams|'\n",
    "        r'ml|mls|milliliter|milliliters|l|ls|liter|liters|'\n",
    "        r'tsp|tsps|teaspoon|teaspoons|tbsp|tb|tbsps|tablespoon|tablespoons|'\n",
    "        r'cup|cups|c|cs|'\n",
    "        r'oz|ounce|ounces|'\n",
    "        r'lb|lbs|pound|pounds|'\n",
    "        r'metric teaspoon|metric tablespoons|'\n",
    "        r'pinch|drops|handful|sprinkle)\\b',\n",
    "        '',\n",
    "        line,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # Step 3: Strip symbols and normalize spaces\n",
    "    line = re.sub(r'[\\-\\*\\(\\),]', '', line).strip()\n",
    "    line = re.sub(r'\\s+', ' ', line).lower().strip()\n",
    "\n",
    "    # Step 4: Use spaCy to process the text\n",
    "    doc = nlp(line)\n",
    "\n",
    "    # Step 5: Tokenize, remove verbs and stopwords, lemmatize\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        lemma = lemmatizer.lemmatize(token.text, 'n')  # Lemmatize as noun\n",
    "        if (\n",
    "            token.pos_ != \"VERB\" and\n",
    "            lemma.lower() not in STOPWORDS and\n",
    "            token.is_alpha\n",
    "        ):\n",
    "            tokens.append(lemma.lower())\n",
    "\n",
    "    return \" \".join(tokens).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a648d067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ingredients(text):\n",
    "    \"\"\"\n",
    "    Converts escaped newlines (\\\\n) to real ones, then extracts ingredients.\n",
    "    Returns: List of cleaned ingredient names\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = text.encode().decode('unicode_escape')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    ingredients = []\n",
    "    for line in text.split('\\n'):\n",
    "        stripped = line.strip()\n",
    "        if stripped.startswith('-'):\n",
    "            ingredient = stripped[1:].strip()\n",
    "            if ingredient:\n",
    "                ingredients.append(ingredient)\n",
    "\n",
    "    return ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd01ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ingredients(text):\n",
    "    raw = extract_ingredients(text)\n",
    "    cleaned = [extract_clean_ingredient(ing) for ing in raw]\n",
    "    return cleaned\n",
    "\n",
    "# Apply function to create new column\n",
    "df['ner_ingredient'] = df['ingredient'].apply(process_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912c1181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['food_name', 'ingredient', 'cleaned_check', 'ner_ingredient']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6da01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_escaped_newlines(df):\n",
    "    \"\"\"\n",
    "    Convert escaped newlines (\\\\n) to real newlines for Excel display\n",
    "    \"\"\"\n",
    "    text_columns = ['ingredient', 'instructions', 'tips']\n",
    "    \n",
    "    for col in text_columns:\n",
    "        if col in df.columns:\n",
    "            # Replace escaped newlines with actual newlines\n",
    "            df[col] = df[col].apply(\n",
    "                lambda x: x.replace('\\\\n', '\\n') if isinstance(x, str) else x\n",
    "            )\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the conversion right before saving\n",
    "df = convert_escaped_newlines(df)\n",
    "\n",
    "# Then save\n",
    "df.to_excel(\"1st_dataset.xlsx\", index=False)\n",
    "print(\"✅ DataFrame saved to '1st_dataset.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0804de83",
   "metadata": {},
   "source": [
    "##### **New Dataset After Checking NER INgredients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e49fc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'ingredients', 'ner_ingredient', 'instructions', 'min_age', 'max_age', 'texture', 'prep_time', 'cook_time', 'serving', 'origin', 'recipe_link', 'credibility', 'image_link', 'region', 'difficulty', 'meal_type', 'description', 'dietary_tags', 'choking_hazard', 'tips', 'allergen', 'hypoallergenic', 'nutrition_value', 'ID', 'Energy / Calorie', 'Carbohydrate (g)', 'Protein (g)', 'Fat (g)', 'List of Micros', None, None, None, None, None]\n",
      "Dataset shape: (1322, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ner_ingredient</th>\n",
       "      <th>instructions</th>\n",
       "      <th>min_age</th>\n",
       "      <th>max_age</th>\n",
       "      <th>texture</th>\n",
       "      <th>prep_time</th>\n",
       "      <th>cook_time</th>\n",
       "      <th>serving</th>\n",
       "      <th>...</th>\n",
       "      <th>Energy / Calorie</th>\n",
       "      <th>Carbohydrate (g)</th>\n",
       "      <th>Protein (g)</th>\n",
       "      <th>Fat (g)</th>\n",
       "      <th>List of Micros</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>- 60 g cassava, boiled and blended\\n- 20 g fis...</td>\n",
       "      <td>['cassava', 'fish', 'chicken', 'coconut oil', ...</td>\n",
       "      <td>Broth:\\n1. Use chicken bones, chicken feet, fi...</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>15 min</td>\n",
       "      <td>45 min</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitterballs (Bitterballen)</td>\n",
       "      <td>- 100 g beef mince \\n- 30 g potato starch \\n- ...</td>\n",
       "      <td>['beef', 'potato starch', 'milk', 'egg', 'marg...</td>\n",
       "      <td>1. Stir-fry blended spices until fragrant. \\n2...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>30 minutes</td>\n",
       "      <td>30 minutes</td>\n",
       "      <td>10 servings</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Broccoli/Cauliflower Cheese</td>\n",
       "      <td>- 175g cauliflower/broccoli, cut into pieces\\n...</td>\n",
       "      <td>['cauliflower', 'broccoli', 'margarine', 'flou...</td>\n",
       "      <td>1. Steam, boil, or microwave cauliflower/brocc...</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>~10 min</td>\n",
       "      <td>~20 min</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vegetable Fingers</td>\n",
       "      <td>- 1 carrot, potato, or sweet potato, peeled an...</td>\n",
       "      <td>['carrot', 'potato', 'sweet potato']</td>\n",
       "      <td>1. Steam or microwave vegetables until tender....</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>~5 min</td>\n",
       "      <td>~10 min</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beef Casserole</td>\n",
       "      <td>- 1 onion, peeled and finely chopped\\n- 1½ tab...</td>\n",
       "      <td>['onion', 'vegetable oil', 'beef', 'steak', 'c...</td>\n",
       "      <td>1. Preheat oven to 180°C.\\n2. Heat oil in a me...</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>~10 min</td>\n",
       "      <td>~2.5 hours</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Cassava Porridge with Fish Sauce and Lemon (Bu...   \n",
       "1                         Bitterballs (Bitterballen)   \n",
       "2                        Broccoli/Cauliflower Cheese   \n",
       "3                                  Vegetable Fingers   \n",
       "4                                     Beef Casserole   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  - 60 g cassava, boiled and blended\\n- 20 g fis...   \n",
       "1  - 100 g beef mince \\n- 30 g potato starch \\n- ...   \n",
       "2  - 175g cauliflower/broccoli, cut into pieces\\n...   \n",
       "3  - 1 carrot, potato, or sweet potato, peeled an...   \n",
       "4  - 1 onion, peeled and finely chopped\\n- 1½ tab...   \n",
       "\n",
       "                                      ner_ingredient  \\\n",
       "0  ['cassava', 'fish', 'chicken', 'coconut oil', ...   \n",
       "1  ['beef', 'potato starch', 'milk', 'egg', 'marg...   \n",
       "2  ['cauliflower', 'broccoli', 'margarine', 'flou...   \n",
       "3               ['carrot', 'potato', 'sweet potato']   \n",
       "4  ['onion', 'vegetable oil', 'beef', 'steak', 'c...   \n",
       "\n",
       "                                        instructions min_age max_age texture  \\\n",
       "0  Broth:\\n1. Use chicken bones, chicken feet, fi...       6       8    None   \n",
       "1  1. Stir-fry blended spices until fragrant. \\n2...       9      11    None   \n",
       "2  1. Steam, boil, or microwave cauliflower/brocc...       6      12    None   \n",
       "3  1. Steam or microwave vegetables until tender....       6      12    None   \n",
       "4  1. Preheat oven to 180°C.\\n2. Heat oil in a me...       6      12    None   \n",
       "\n",
       "    prep_time   cook_time      serving  ... Energy / Calorie Carbohydrate (g)  \\\n",
       "0      15 min      45 min            1  ...             None             None   \n",
       "1  30 minutes  30 minutes  10 servings  ...             None             None   \n",
       "2     ~10 min     ~20 min         None  ...             None             None   \n",
       "3      ~5 min     ~10 min         None  ...             None             None   \n",
       "4     ~10 min  ~2.5 hours         None  ...             None             None   \n",
       "\n",
       "  Protein (g) Fat (g) List of Micros  None  None  None  None  None  \n",
       "0        None    None           None  None  None  None  None  None  \n",
       "1        None    None           None  None  None  None  None  None  \n",
       "2        None    None           None  None  None  None  None  None  \n",
       "3        None    None           None  None  None  None  None  None  \n",
       "4        None    None           None  None  None  None  None  None  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Open Excel File\n",
    "import openpyxl\n",
    "import os\n",
    "\n",
    "# Load the workbook\n",
    "workbook = openpyxl.load_workbook('1st_dataset.xlsx')\n",
    "\n",
    "# Select the active worksheet\n",
    "worksheet = workbook[\"Sheet1\"]\n",
    "# Import pandas for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = []\n",
    "headers = []\n",
    "\n",
    "# Get headers from the first row\n",
    "for col in range(1, worksheet.max_column + 1):\n",
    "    headers.append(worksheet.cell(row=1, column=col).value)\n",
    "\n",
    "# Get data from remaining rows\n",
    "for row in range(2, worksheet.max_row + 1):\n",
    "    row_data = []\n",
    "    for col in range(1, worksheet.max_column + 1):\n",
    "        row_data.append(worksheet.cell(row=row, column=col).value)\n",
    "    data.append(row_data)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "print(headers)\n",
    "\n",
    "# Display first few rows to verify\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2ab72f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame:\n",
      "(1322, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ner_ingredient</th>\n",
       "      <th>instructions</th>\n",
       "      <th>min_age</th>\n",
       "      <th>max_age</th>\n",
       "      <th>texture</th>\n",
       "      <th>prep_time</th>\n",
       "      <th>cook_time</th>\n",
       "      <th>serving</th>\n",
       "      <th>...</th>\n",
       "      <th>Energy / Calorie</th>\n",
       "      <th>Carbohydrate (g)</th>\n",
       "      <th>Protein (g)</th>\n",
       "      <th>Fat (g)</th>\n",
       "      <th>List of Micros</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>- 60 g cassava, boiled and blended\\n- 20 g fis...</td>\n",
       "      <td>['cassava', 'fish', 'chicken', 'coconut oil', ...</td>\n",
       "      <td>Broth:\\n1. Use chicken bones, chicken feet, fi...</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>15 min</td>\n",
       "      <td>45 min</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitterballs (Bitterballen)</td>\n",
       "      <td>- 100 g beef mince \\n- 30 g potato starch \\n- ...</td>\n",
       "      <td>['beef', 'potato starch', 'milk', 'egg', 'marg...</td>\n",
       "      <td>1. Stir-fry blended spices until fragrant. \\n2...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>30 minutes</td>\n",
       "      <td>30 minutes</td>\n",
       "      <td>10 servings</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Broccoli/Cauliflower Cheese</td>\n",
       "      <td>- 175g cauliflower/broccoli, cut into pieces\\n...</td>\n",
       "      <td>['cauliflower', 'broccoli', 'margarine', 'flou...</td>\n",
       "      <td>1. Steam, boil, or microwave cauliflower/brocc...</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>~10 min</td>\n",
       "      <td>~20 min</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vegetable Fingers</td>\n",
       "      <td>- 1 carrot, potato, or sweet potato, peeled an...</td>\n",
       "      <td>['carrot', 'potato', 'sweet potato']</td>\n",
       "      <td>1. Steam or microwave vegetables until tender....</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>~5 min</td>\n",
       "      <td>~10 min</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beef Casserole</td>\n",
       "      <td>- 1 onion, peeled and finely chopped\\n- 1½ tab...</td>\n",
       "      <td>['onion', 'vegetable oil', 'beef', 'steak', 'c...</td>\n",
       "      <td>1. Preheat oven to 180°C.\\n2. Heat oil in a me...</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>~10 min</td>\n",
       "      <td>~2.5 hours</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Toast Fingers</td>\n",
       "      <td>- 1 slice thick wholemeal bread</td>\n",
       "      <td>['wholemeal bread']</td>\n",
       "      <td>1. Toast bread and allow it to cool.\\n2. Cut i...</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>~5 min</td>\n",
       "      <td>~10 min</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pumpkin Polenta Fingers</td>\n",
       "      <td>- 3 cups water\\n- 1 cup polenta (a coarse, gra...</td>\n",
       "      <td>['water', 'polenta', 'pumpkin', 'parmesan chee...</td>\n",
       "      <td>1. Bring water to the boil in a large saucepan...</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>~10 min</td>\n",
       "      <td>~40 min</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rice Pudding</td>\n",
       "      <td>- 1 cup cooked rice\\n- 1 cup milk\\n- ½ - 1 tab...</td>\n",
       "      <td>['rice', 'milk', 'sugar', 'vanilla essence']</td>\n",
       "      <td>1. In a saucepan mix together rice, milk, and ...</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>~5 min</td>\n",
       "      <td>~15 min</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hummus</td>\n",
       "      <td>- 400g canned chickpeas, drained\\n- 1 clove ga...</td>\n",
       "      <td>['chickpeas', 'garlic', 'lemon juice', 'milk',...</td>\n",
       "      <td>1. Combine all ingredients.\\n2. Mash or puree ...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>~5 min</td>\n",
       "      <td>~10 min</td>\n",
       "      <td>2 cups</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baked Bean Pie</td>\n",
       "      <td>- 820g canned baked beans\\n- 1 medium zucchini...</td>\n",
       "      <td>['baked beans', 'zucchini', 'potatoes', 'milk'...</td>\n",
       "      <td>1. Preheat oven to 180°C.\\n2. Place baked bean...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>~10 min</td>\n",
       "      <td>~30 min</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Cassava Porridge with Fish Sauce and Lemon (Bu...   \n",
       "1                         Bitterballs (Bitterballen)   \n",
       "2                        Broccoli/Cauliflower Cheese   \n",
       "3                                  Vegetable Fingers   \n",
       "4                                     Beef Casserole   \n",
       "5                                      Toast Fingers   \n",
       "6                            Pumpkin Polenta Fingers   \n",
       "7                                       Rice Pudding   \n",
       "8                                             Hummus   \n",
       "9                                     Baked Bean Pie   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  - 60 g cassava, boiled and blended\\n- 20 g fis...   \n",
       "1  - 100 g beef mince \\n- 30 g potato starch \\n- ...   \n",
       "2  - 175g cauliflower/broccoli, cut into pieces\\n...   \n",
       "3  - 1 carrot, potato, or sweet potato, peeled an...   \n",
       "4  - 1 onion, peeled and finely chopped\\n- 1½ tab...   \n",
       "5                    - 1 slice thick wholemeal bread   \n",
       "6  - 3 cups water\\n- 1 cup polenta (a coarse, gra...   \n",
       "7  - 1 cup cooked rice\\n- 1 cup milk\\n- ½ - 1 tab...   \n",
       "8  - 400g canned chickpeas, drained\\n- 1 clove ga...   \n",
       "9  - 820g canned baked beans\\n- 1 medium zucchini...   \n",
       "\n",
       "                                      ner_ingredient  \\\n",
       "0  ['cassava', 'fish', 'chicken', 'coconut oil', ...   \n",
       "1  ['beef', 'potato starch', 'milk', 'egg', 'marg...   \n",
       "2  ['cauliflower', 'broccoli', 'margarine', 'flou...   \n",
       "3               ['carrot', 'potato', 'sweet potato']   \n",
       "4  ['onion', 'vegetable oil', 'beef', 'steak', 'c...   \n",
       "5                                ['wholemeal bread']   \n",
       "6  ['water', 'polenta', 'pumpkin', 'parmesan chee...   \n",
       "7       ['rice', 'milk', 'sugar', 'vanilla essence']   \n",
       "8  ['chickpeas', 'garlic', 'lemon juice', 'milk',...   \n",
       "9  ['baked beans', 'zucchini', 'potatoes', 'milk'...   \n",
       "\n",
       "                                        instructions min_age max_age texture  \\\n",
       "0  Broth:\\n1. Use chicken bones, chicken feet, fi...       6       8    None   \n",
       "1  1. Stir-fry blended spices until fragrant. \\n2...       9      11    None   \n",
       "2  1. Steam, boil, or microwave cauliflower/brocc...       6      12    None   \n",
       "3  1. Steam or microwave vegetables until tender....       6      12    None   \n",
       "4  1. Preheat oven to 180°C.\\n2. Heat oil in a me...       6      12    None   \n",
       "5  1. Toast bread and allow it to cool.\\n2. Cut i...       6      12    None   \n",
       "6  1. Bring water to the boil in a large saucepan...       6      12    None   \n",
       "7  1. In a saucepan mix together rice, milk, and ...       6      12    None   \n",
       "8  1. Combine all ingredients.\\n2. Mash or puree ...      12      12    None   \n",
       "9  1. Preheat oven to 180°C.\\n2. Place baked bean...      12      12    None   \n",
       "\n",
       "    prep_time   cook_time      serving  ... Energy / Calorie Carbohydrate (g)  \\\n",
       "0      15 min      45 min            1  ...             None             None   \n",
       "1  30 minutes  30 minutes  10 servings  ...             None             None   \n",
       "2     ~10 min     ~20 min         None  ...             None             None   \n",
       "3      ~5 min     ~10 min         None  ...             None             None   \n",
       "4     ~10 min  ~2.5 hours         None  ...             None             None   \n",
       "5      ~5 min     ~10 min         None  ...             None             None   \n",
       "6     ~10 min     ~40 min            8  ...             None             None   \n",
       "7      ~5 min     ~15 min         None  ...             None             None   \n",
       "8      ~5 min     ~10 min       2 cups  ...             None             None   \n",
       "9     ~10 min     ~30 min         None  ...             None             None   \n",
       "\n",
       "  Protein (g) Fat (g) List of Micros  None  None  None  None  None  \n",
       "0        None    None           None  None  None  None  None  None  \n",
       "1        None    None           None  None  None  None  None  None  \n",
       "2        None    None           None  None  None  None  None  None  \n",
       "3        None    None           None  None  None  None  None  None  \n",
       "4        None    None           None  None  None  None  None  None  \n",
       "5        None    None           None  None  None  None  None  None  \n",
       "6        None    None           None  None  None  None  None  None  \n",
       "7        None    None           None  None  None  None  None  None  \n",
       "8        None    None           None  None  None  None  None  None  \n",
       "9        None    None           None  None  None  None  None  None  \n",
       "\n",
       "[10 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop data if imporant columns are empty\n",
    "important_columns = ['name', 'ingredients', 'ner_ingredient', 'instructions', 'recipe_link']\n",
    "for col in df.columns:\n",
    "    if col in important_columns:\n",
    "        null_count = df[col].isnull().sum()        \n",
    "        if null_count >0:\n",
    "            df = df.dropna(subset=[col])\n",
    "\n",
    "# After dropping rows, you may want to reset the index if needed\n",
    "df = df.reset_index(drop=True)\n",
    "# Display the cleaned DataFrame\n",
    "print(\"Cleaned DataFrame:\")\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71afda52",
   "metadata": {},
   "source": [
    "##### Reformatting NER Ingredient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "720802d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ner_ingredient</th>\n",
       "      <th>ner_ingredient_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>['cassava', 'fish', 'chicken', 'coconut oil', ...</td>\n",
       "      <td>cassava,fish,chicken,coconut oil,chicken broth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitterballs (Bitterballen)</td>\n",
       "      <td>['beef', 'potato starch', 'milk', 'egg', 'marg...</td>\n",
       "      <td>beef,potato starch,milk,egg,margarine,salt,che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Broccoli/Cauliflower Cheese</td>\n",
       "      <td>['cauliflower', 'broccoli', 'margarine', 'flou...</td>\n",
       "      <td>cauliflower,broccoli,margarine,flour,milk,ched...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vegetable Fingers</td>\n",
       "      <td>['carrot', 'potato', 'sweet potato']</td>\n",
       "      <td>carrot,potato,sweet potato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beef Casserole</td>\n",
       "      <td>['onion', 'vegetable oil', 'beef', 'steak', 'c...</td>\n",
       "      <td>onion,vegetable oil,beef,steak,carrots,potatoe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Cassava Porridge with Fish Sauce and Lemon (Bu...   \n",
       "1                         Bitterballs (Bitterballen)   \n",
       "2                        Broccoli/Cauliflower Cheese   \n",
       "3                                  Vegetable Fingers   \n",
       "4                                     Beef Casserole   \n",
       "\n",
       "                                      ner_ingredient  \\\n",
       "0  ['cassava', 'fish', 'chicken', 'coconut oil', ...   \n",
       "1  ['beef', 'potato starch', 'milk', 'egg', 'marg...   \n",
       "2  ['cauliflower', 'broccoli', 'margarine', 'flou...   \n",
       "3               ['carrot', 'potato', 'sweet potato']   \n",
       "4  ['onion', 'vegetable oil', 'beef', 'steak', 'c...   \n",
       "\n",
       "                               ner_ingredient_string  \n",
       "0  cassava,fish,chicken,coconut oil,chicken broth...  \n",
       "1  beef,potato starch,milk,egg,margarine,salt,che...  \n",
       "2  cauliflower,broccoli,margarine,flour,milk,ched...  \n",
       "3                         carrot,potato,sweet potato  \n",
       "4  onion,vegetable oil,beef,steak,carrots,potatoe...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "import re \n",
    "\n",
    "\n",
    "def format_ner_ingredient(df):\n",
    "    # First ensure ner_ingredient is properly parsed as a list\n",
    "    df['ner_ingredient_list'] = df['ner_ingredient'].apply(\n",
    "        lambda x: ast.literal_eval(x) if isinstance(x, str) and x.strip().startswith('[') else \n",
    "                 x if isinstance(x, list) else \n",
    "                 [str(x)] if x else []\n",
    "    )\n",
    "    \n",
    "    # Convert list to comma-separated string\n",
    "    df['ner_ingredient_string'] = df['ner_ingredient_list'].apply(\n",
    "        lambda x: ','.join(str(item) for item in x) if isinstance(x, list) else ''\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function\n",
    "df = format_ner_ingredient(df)\n",
    "\n",
    "# Display the results\n",
    "df[['name', 'ner_ingredient', 'ner_ingredient_string']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b45298eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Go into 'processing-technique' folder and add it to Python path\n",
    "processing_dir = os.path.join(os.getcwd(), \"preprocessing_techniques\")\n",
    "sys.path.append(processing_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1505fdc5",
   "metadata": {},
   "source": [
    "##### **Formatting Min and Max Age Group**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aebbd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Results after formatting====\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_age</th>\n",
       "      <th>max_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   min_age  max_age\n",
       "0      6.0      8.0\n",
       "1      9.0     11.0\n",
       "2      6.0     12.0\n",
       "3      6.0     12.0\n",
       "4      6.0     12.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ensure the min and max age only contain integers\n",
    "import re \n",
    "from openpyxl.styles import PatternFill\n",
    "\n",
    "\n",
    "def format_age(value):\n",
    "    match = re.search(r'\\d+', str(value))\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    return None\n",
    "\n",
    "df['min_age'] = df['min_age'].apply(format_age)\n",
    "df['max_age'] = df['max_age'].apply(format_age)\n",
    "\n",
    "print(\"====Results after formatting====\")\n",
    "df[['min_age','max_age']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4721e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age_keywords': {'chopped': {'max_age': 36,\n",
      "                              'min_age': 10,\n",
      "                              'reason': 'Small soft pieces for chewing '\n",
      "                                        'practice'},\n",
      "                  'finger food': {'max_age': 36,\n",
      "                                  'min_age': 8,\n",
      "                                  'reason': 'Self-feeding for older babies'},\n",
      "                  'mash': {'max_age': 10,\n",
      "                           'min_age': 6,\n",
      "                           'reason': 'Lumpy texture for advancing skills'},\n",
      "                  'porridge': {'max_age': 12,\n",
      "                               'min_age': 4,\n",
      "                               'reason': 'Easy-to-swallow grains'},\n",
      "                  'puree': {'max_age': 8,\n",
      "                            'min_age': 4,\n",
      "                            'reason': 'Smooth texture for early weaning'},\n",
      "                  'stew': {'max_age': 36,\n",
      "                           'min_age': 6,\n",
      "                           'reason': 'Soft, mixed textures'}},\n",
      " 'ingredient_rules': {'cow milk (as drink)': {'min_age': 12,\n",
      "                                              'reason': 'Not recommended as '\n",
      "                                                        'main drink under 12 '\n",
      "                                                        'months'},\n",
      "                      'grapes (whole)': {'min_age': 24,\n",
      "                                         'reason': 'Choking risk; always '\n",
      "                                                   'quarter'},\n",
      "                      'honey': {'min_age': 12,\n",
      "                                'reason': 'Risk of infant botulism'},\n",
      "                      'peanut butter': {'min_age': 6,\n",
      "                                        'reason': 'Introduce as smooth paste '\n",
      "                                                  '(allergy guidelines)'},\n",
      "                      'salt': {'min_age': 12,\n",
      "                               'reason': 'Avoid added salt for babies'},\n",
      "                      'shellfish': {'min_age': 12,\n",
      "                                    'reason': 'High allergen risk'},\n",
      "                      'sugar': {'min_age': 12,\n",
      "                                'reason': 'Avoid added sugars for babies'},\n",
      "                      'whole nuts': {'min_age': 36,\n",
      "                                     'reason': 'Choking hazard'}},\n",
      " 'instruction_keywords': {'blend until smooth': {'max_age': 6,\n",
      "                                                 'min_age': 4,\n",
      "                                                 'reason': 'Stage 1 puree'},\n",
      "                          'chop into small pieces': {'min_age': 8,\n",
      "                                                     'reason': 'Finger food '\n",
      "                                                               'for '\n",
      "                                                               'self-feeding'},\n",
      "                          'grate': {'min_age': 8,\n",
      "                                    'reason': 'Soft grated textures'},\n",
      "                          'mash with a fork': {'max_age': 8,\n",
      "                                               'min_age': 6,\n",
      "                                               'reason': 'Lumpy texture'},\n",
      "                          'steam until soft': {'min_age': 6,\n",
      "                                               'reason': 'Soft, dissolvable '\n",
      "                                                         'texture'}},\n",
      " 'texture_to_age': {'family_food': {'max_age': 36, 'min_age': 12},\n",
      "                    'finger_food': {'max_age': 36, 'min_age': 8},\n",
      "                    'lumpy': {'max_age': 8, 'min_age': 6},\n",
      "                    'smooth': {'max_age': 6, 'min_age': 4}}}\n"
     ]
    }
   ],
   "source": [
    "# Now you can import age_label from mapper\n",
    "from mappers.age_label import age_rules\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(age_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e8c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_age(recipe_name, ingredients, instructions):\n",
    "    # Initialize min_age and reasons\n",
    "    min_age = 6   # Default baby age start (in months)\n",
    "    max_age = 12  # Default upper limit (3 years)\n",
    "    reasons = []\n",
    "\n",
    "    # 1. Check recipe name keywords\n",
    "    for keyword in age_rules[\"age_keywords\"]:\n",
    "        if keyword.lower() in recipe_name.lower():\n",
    "            rule = age_rules[\"age_keywords\"][keyword]\n",
    "            if rule.get(\"min_age\", 0) > min_age:\n",
    "                min_age = rule[\"min_age\"]\n",
    "                reasons.append(f\"Recipe name suggests '{keyword}' ({rule['reason']})\")\n",
    "            if \"max_age\" in rule:\n",
    "                max_age = min(max_age, rule[\"max_age\"])  # Tighten max if rule restricts it\n",
    "\n",
    "    # 2. Check ingredient restrictions\n",
    "    for ingredient in ingredients.split(','):\n",
    "        ing_key = ingredient.strip().lower()\n",
    "        if ing_key in age_rules[\"ingredient_rules\"]:\n",
    "            rule = age_rules[\"ingredient_rules\"][ing_key]\n",
    "            if rule.get(\"min_age\", 0) > min_age:\n",
    "                min_age = rule[\"min_age\"]\n",
    "                reasons.append(f\"Ingredient '{ing_key}' requires {rule['reason']}\")\n",
    "\n",
    "    # 3. Check instructions for texture keywords\n",
    "    for keyword in age_rules[\"instruction_keywords\"]:\n",
    "        if keyword.lower() in instructions.lower():\n",
    "            rule = age_rules[\"instruction_keywords\"][keyword]\n",
    "            if rule.get(\"min_age\", 0) > min_age:\n",
    "                min_age = rule[\"min_age\"]\n",
    "                reasons.append(f\"Instruction '{keyword}' suggests {rule['reason']}\")\n",
    "            if \"max_age\" in rule:\n",
    "                max_age = min(max_age, rule[\"max_age\"])\n",
    "\n",
    "    return {\n",
    "        \"min_age_group\": min_age,\n",
    "        \"max_age_group\": max_age\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38545572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_infer(row):\n",
    "    if pd.isna(row[\"min_age_group\"]) or pd.isna(row[\"max_age_group\"]):\n",
    "        result = infer_age(row[\"food_name\"], row[\"ner_ingredient_csv\"], row[\"instructions\"])\n",
    "        return pd.Series([result[\"min_age_group\"], result[\"max_age_group\"]])\n",
    "    else:\n",
    "        return pd.Series([row[\"min_age_group\"], row[\"max_age_group\"]])\n",
    "\n",
    "# Apply and create new columns\n",
    "df[[\"min_age_group\", \"max_age_group\"]] = df.apply(apply_infer, axis=1)\n",
    "\n",
    "print(df[[\"food_name\", \"min_age_group\", \"max_age_group\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3369e1aa",
   "metadata": {},
   "source": [
    "##### **Format and Fill the Texture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f5ba1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'family food': {'keywords': ['for adults',\n",
      "                              'seasoned for adults',\n",
      "                              'serve as is',\n",
      "                              'family style',\n",
      "                              'serve with family meal',\n",
      "                              'adult portion',\n",
      "                              'shared with family',\n",
      "                              'serve at table',\n",
      "                              'table food',\n",
      "                              'family dinner',\n",
      "                              'not modified',\n",
      "                              'no blending',\n",
      "                              'whole meal',\n",
      "                              'non-baby portion',\n",
      "                              'spaghetti',\n",
      "                              'pizza',\n",
      "                              'fried chicken',\n",
      "                              'steak',\n",
      "                              'burger',\n",
      "                              'taco',\n",
      "                              'sandwich',\n",
      "                              'soup with chunks',\n",
      "                              'stir-fry',\n",
      "                              'casserole',\n",
      "                              'curry',\n",
      "                              'pasta',\n",
      "                              'rice bowl',\n",
      "                              'ramen',\n",
      "                              'noodles',\n",
      "                              'salad']},\n",
      " 'lumpy texture': {'keywords': ['finely chopped',\n",
      "                                'small cubes',\n",
      "                                'bite-sized pieces',\n",
      "                                'chunks',\n",
      "                                'soft lumps',\n",
      "                                'lumpy texture',\n",
      "                                'pieces about',\n",
      "                                'cut into small pieces',\n",
      "                                'with texture',\n",
      "                                'chunky mix',\n",
      "                                'mixed consistency',\n",
      "                                'partially mashed',\n",
      "                                'chopped carrot',\n",
      "                                'diced sweet potato',\n",
      "                                'chopped onion',\n",
      "                                'chopped chicken',\n",
      "                                'udon noodles',\n",
      "                                'rice pieces',\n",
      "                                'soft tofu chunks',\n",
      "                                'natto',\n",
      "                                'edamame',\n",
      "                                'blueberries',\n",
      "                                'raspberries',\n",
      "                                'melon cubes']},\n",
      " 'puree': {'keywords': ['puree',\n",
      "                        'blender',\n",
      "                        'food processor',\n",
      "                        'smooth',\n",
      "                        'blend until smooth',\n",
      "                        'process until smooth',\n",
      "                        'mashed and blended',\n",
      "                        'baby puree',\n",
      "                        'liquefy',\n",
      "                        'whip',\n",
      "                        'strain',\n",
      "                        'homogenized',\n",
      "                        'creamy blend',\n",
      "                        'apple puree',\n",
      "                        'pear puree',\n",
      "                        'banana puree',\n",
      "                        'carrot puree',\n",
      "                        'sweet potato puree',\n",
      "                        'zucchini puree',\n",
      "                        'avocado puree',\n",
      "                        'yogurt',\n",
      "                        'cheese puree',\n",
      "                        'prune puree',\n",
      "                        'oatmeal puree']},\n",
      " 'soft finger food': {'keywords': ['roll into balls',\n",
      "                                   'flatten',\n",
      "                                   'pan-fry soft',\n",
      "                                   'soft dumplings',\n",
      "                                   'mash lightly',\n",
      "                                   'stick together',\n",
      "                                   'formed into shapes',\n",
      "                                   'soft finger foods',\n",
      "                                   'easy to gum',\n",
      "                                   'holdable',\n",
      "                                   'pick-up pieces',\n",
      "                                   'handheld',\n",
      "                                   'rollable',\n",
      "                                   'rice ball',\n",
      "                                   'potato patty',\n",
      "                                   'egg pancake',\n",
      "                                   'tofu cube',\n",
      "                                   'bread slice',\n",
      "                                   'steamed bun',\n",
      "                                   'soft dumpling',\n",
      "                                   'meatball',\n",
      "                                   'pancake',\n",
      "                                   'finger bread',\n",
      "                                   'mashed banana roll',\n",
      "                                   'sweet potato stick',\n",
      "                                   'steamed veggie stick']}}\n"
     ]
    }
   ],
   "source": [
    "# Load the module\n",
    "import importlib\n",
    "from pprint import pprint\n",
    "texture_label_path = os.path.join(os.getcwd(), \"preprocessing_techniques\", \"mappers\", \"texture_label.py\")\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"texture_label\", texture_label_path)\n",
    "texture_label = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(texture_label)\n",
    "\n",
    "# Access the config\n",
    "texture_config = texture_label.texture_config\n",
    "pprint(texture_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e88d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_instructions(text):\n",
    "    \"\"\"\n",
    "    Extracts numbered steps from a block of text and returns a list of instruction strings.\n",
    "    \"\"\"\n",
    "    instructions = []\n",
    "    num_instruction = 0\n",
    "    for line in text.splitlines():\n",
    "        stripped = line.strip()\n",
    "        if stripped.startswith(f\"{num_instruction + 1}.\"):\n",
    "            # Remove the prefix like \"1.\", \"2.\", etc.\n",
    "            instruction = stripped[len(str(num_instruction + 1)) + 1:].strip()\n",
    "            instructions.append(instruction)\n",
    "    instructions_str = ' '.join(instructions).lower()\n",
    "    return instructions_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20dfe5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_recipe_texture(recipe_name, ner_ingredients, instructions_list, TEXTURE_KEYWORDS):\n",
    "    # Step 1: Ensure ingredients are properly processed\n",
    "    if not isinstance(ner_ingredients, list):\n",
    "        ingredients_clean = []\n",
    "    else:\n",
    "        ingredients_clean = ner_ingredients\n",
    "\n",
    "    # Step 2: Clean instructions\n",
    "    instructions_str = parse_instructions(instructions_list)\n",
    "\n",
    "    # Step 3: Combine all searchable text - ensure EVERYTHING is a string\n",
    "    combined_text_parts = [str(recipe_name).lower()]\n",
    "    \n",
    "    # Safely add each ingredient as a string, skipping None values\n",
    "    for i in ingredients_clean:\n",
    "        if i is not None:\n",
    "            combined_text_parts.append(str(i).lower())\n",
    "    \n",
    "    # Add the instructions\n",
    "    combined_text_parts.append(instructions_str)\n",
    "    \n",
    "    # Join all parts with spaces\n",
    "    combined_text = ' '.join(combined_text_parts)\n",
    "\n",
    "    # Step 4: Match against each texture keyword set\n",
    "    for texture_type, data in TEXTURE_KEYWORDS.items():\n",
    "        for keyword in data[\"keywords\"]:\n",
    "            if keyword.lower() in combined_text:\n",
    "                return texture_type\n",
    "\n",
    "    # Default fallback\n",
    "    return \"NONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e1a21b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ner_ingredient</th>\n",
       "      <th>texture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>['cassava', 'fish', 'chicken', 'coconut oil', ...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitterballs (Bitterballen)</td>\n",
       "      <td>['beef', 'potato starch', 'milk', 'egg', 'marg...</td>\n",
       "      <td>family food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Broccoli/Cauliflower Cheese</td>\n",
       "      <td>['cauliflower', 'broccoli', 'margarine', 'flou...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vegetable Fingers</td>\n",
       "      <td>['carrot', 'potato', 'sweet potato']</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beef Casserole</td>\n",
       "      <td>['onion', 'vegetable oil', 'beef', 'steak', 'c...</td>\n",
       "      <td>family food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Toast Fingers</td>\n",
       "      <td>['wholemeal bread']</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pumpkin Polenta Fingers</td>\n",
       "      <td>['water', 'polenta', 'pumpkin', 'parmesan chee...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rice Pudding</td>\n",
       "      <td>['rice', 'milk', 'sugar', 'vanilla essence']</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hummus</td>\n",
       "      <td>['chickpeas', 'garlic', 'lemon juice', 'milk',...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baked Bean Pie</td>\n",
       "      <td>['baked beans', 'zucchini', 'potatoes', 'milk'...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Cassava Porridge with Fish Sauce and Lemon (Bu...   \n",
       "1                         Bitterballs (Bitterballen)   \n",
       "2                        Broccoli/Cauliflower Cheese   \n",
       "3                                  Vegetable Fingers   \n",
       "4                                     Beef Casserole   \n",
       "5                                      Toast Fingers   \n",
       "6                            Pumpkin Polenta Fingers   \n",
       "7                                       Rice Pudding   \n",
       "8                                             Hummus   \n",
       "9                                     Baked Bean Pie   \n",
       "\n",
       "                                      ner_ingredient      texture  \n",
       "0  ['cassava', 'fish', 'chicken', 'coconut oil', ...         NONE  \n",
       "1  ['beef', 'potato starch', 'milk', 'egg', 'marg...  family food  \n",
       "2  ['cauliflower', 'broccoli', 'margarine', 'flou...         NONE  \n",
       "3               ['carrot', 'potato', 'sweet potato']         NONE  \n",
       "4  ['onion', 'vegetable oil', 'beef', 'steak', 'c...  family food  \n",
       "5                                ['wholemeal bread']         NONE  \n",
       "6  ['water', 'polenta', 'pumpkin', 'parmesan chee...         NONE  \n",
       "7       ['rice', 'milk', 'sugar', 'vanilla essence']         NONE  \n",
       "8  ['chickpeas', 'garlic', 'lemon juice', 'milk',...         NONE  \n",
       "9  ['baked beans', 'zucchini', 'potatoes', 'milk'...         NONE  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def determine_texture(row, TEXTURE_KEYWORDS):\n",
    "    if pd.isna(row.get(\"texture\")) or row[\"texture\"] in (\"\", \" \", None, \"NONE\"):\n",
    "        return classify_recipe_texture(\n",
    "            recipe_name=row[\"name\"],\n",
    "            ner_ingredients=row[\"ner_ingredient_string\"],\n",
    "            instructions_list=row[\"instructions\"],\n",
    "            TEXTURE_KEYWORDS=TEXTURE_KEYWORDS\n",
    "        )\n",
    "    return row[\"texture\"]\n",
    "\n",
    "df['texture'] = df.apply(determine_texture, axis=1, TEXTURE_KEYWORDS=texture_config)\n",
    "\n",
    "df[['name', 'ner_ingredient', 'texture']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7359f31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total recipes with 'NONE' texture: 814\n",
      "Total rows with missing texture: 0\n"
     ]
    }
   ],
   "source": [
    "#total NONE texture group \n",
    "total_none_texture = df[df['texture'] == 'NONE']\n",
    "print(f\"Total recipes with 'NONE' texture: {len(total_none_texture)}\")\n",
    "\n",
    "#any missing value of texture \n",
    "missing_texture = df[df['texture'].isnull() | (df['texture'] == '')]\n",
    "count = 0 \n",
    "if not missing_texture.empty:\n",
    "    count = len(missing_texture)\n",
    "    print(f\"Found {count} rows with missing or empty texture values.\")\n",
    "    print(missing_texture[['name', 'ner_ingredient', 'texture']])\n",
    "\n",
    "print(f\"Total rows with missing texture: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8850488",
   "metadata": {},
   "source": [
    "<p>PS: With the current dictionary, 814 recipes aren't detected, therefore need manual checking before finalizing </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c34fb8",
   "metadata": {},
   "source": [
    "##### **Origin and Region Mapping**\n",
    "\n",
    "Mapping origin values to origin_id using the countrymap sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2920a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countrymap columns: ['pk', 'country', 'region', 'flag_code']\n",
      "Countrymap shape: (76, 4)\n",
      "\n",
      "First 5 rows of countrymap:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk</th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>flag_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>China</td>\n",
       "      <td>Asian</td>\n",
       "      <td>cn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Asian</td>\n",
       "      <td>jp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>Asian</td>\n",
       "      <td>kr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mongolia</td>\n",
       "      <td>Asian</td>\n",
       "      <td>mn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>Asian</td>\n",
       "      <td>np</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pk      country region flag_code\n",
       "0   1        China  Asian        cn\n",
       "1   2        Japan  Asian        jp\n",
       "2   3  South Korea  Asian        kr\n",
       "3   4     Mongolia  Asian        mn\n",
       "4   5        Nepal  Asian        np"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the countrymap sheet\n",
    "countrymap_df = pd.read_excel('1st_dataset.xlsx', sheet_name='countrymap ')\n",
    "print(\"Countrymap columns:\", countrymap_df.columns.tolist())\n",
    "print(\"Countrymap shape:\", countrymap_df.shape)\n",
    "print(\"\\nFirst 5 rows of countrymap:\")\n",
    "display(countrymap_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c42a303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE ORIGIN VALUES IN MAIN DATASET:\n",
      "==================================================\n",
      "Total unique origins: 31\n",
      "\n",
      "Origin value counts:\n",
      "origin\n",
      "Indonesia      758\n",
      "french         141\n",
      "uk             100\n",
      "UK              56\n",
      "New Zealand     52\n",
      "Australia       30\n",
      "America         30\n",
      "Malaysia        24\n",
      "Indonesian      22\n",
      "China           20\n",
      "Philippines     14\n",
      "India           14\n",
      "Afghanistan      8\n",
      "Germany          7\n",
      "Bhutan           5\n",
      "Thailand         5\n",
      "Japan            5\n",
      "Singapore        5\n",
      "Nepal            5\n",
      "Mongolia         4\n",
      "South Korea      3\n",
      "Lao PDR          3\n",
      "Bangladesh       2\n",
      "Brunei           2\n",
      "Laos             1\n",
      "Myanmar          1\n",
      "Maldives         1\n",
      "Cambodia         1\n",
      "Japan            1\n",
      "China            1\n",
      "Belgium          1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"UNIQUE ORIGIN VALUES IN MAIN DATASET:\")\n",
    "print(\"=\"*50)\n",
    "unique_origins = df['origin'].dropna().unique()\n",
    "print(f\"Total unique origins: {len(unique_origins)}\")\n",
    "print(\"\\nOrigin value counts:\")\n",
    "print(df['origin'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2f3094c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Mapping dictionary created with 80 entries.\n"
     ]
    }
   ],
   "source": [
    "country_to_id = {}\n",
    "\n",
    "# Step 1: Populate the dictionary using lowercase country names\n",
    "for _, row in countrymap_df.iterrows():\n",
    "    country = str(row['country']).strip().lower()  # normalize\n",
    "    origin_id = row['pk']\n",
    "    region = row['region']\n",
    "    \n",
    "    country_to_id[country] = {'id': origin_id, 'region': region}\n",
    "\n",
    "# Step 2: Add alternative lowercase names (also normalized)\n",
    "alternatives = {\n",
    "    'french': 'france',\n",
    "    'uk': 'united kingdom', \n",
    "    'america': 'united states',\n",
    "    'usa': 'united states',\n",
    "    'indonesian': 'indonesia',\n",
    "    'lao pdr': 'laos',\n",
    "    'japan ': 'japan',\n",
    "}\n",
    "\n",
    "for alt, standard in alternatives.items():\n",
    "    alt = alt.strip().lower()\n",
    "    standard = standard.strip().lower()\n",
    "    if standard in country_to_id:\n",
    "        country_to_id[alt] = country_to_id[standard]\n",
    "\n",
    "print(\"✅ Mapping dictionary created with\", len(country_to_id), \"entries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3c367de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map origin to origin_id and region\n",
    "def map_origin(origin_value):\n",
    "    if pd.isna(origin_value):\n",
    "        return None, None\n",
    "    \n",
    "    origin_str = str(origin_value).strip().lower()  # Normalize for consistent lookup\n",
    "    \n",
    "    if origin_str in country_to_id:\n",
    "        return country_to_id[origin_str]['id'], country_to_id[origin_str]['region']\n",
    "    \n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ba459f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛠️ Applying origin mapping...\n",
      "✅ Origin mapping completed.\n",
      "✅ Mapped origins: 10\n",
      "❌ Unmapped origins: 1\n",
      "📋 Test results:\n",
      "             origin  origin_id       mapped_region\n",
      "0               USA       46.0            American\n",
      "1               usa       46.0            American\n",
      "2              UsA        46.0            American\n",
      "3     United States       46.0            American\n",
      "4            french       38.0  Western / European\n",
      "5                UK       39.0  Western / European\n",
      "6                uk       39.0  Western / European\n",
      "7        Indonesian        9.0     Southeast Asian\n",
      "8              Laos       14.0     Southeast Asian\n",
      "9            Japan         2.0               Asian\n",
      "10  NotARealCountry        NaN                None\n"
     ]
    }
   ],
   "source": [
    "# Sample test cases to check various formats\n",
    "test_origins = ['USA', 'usa', 'UsA ', ' United States', 'french', 'UK', 'uk', 'Indonesian', 'Laos', 'Japan ', 'NotARealCountry']\n",
    "test_df = pd.DataFrame({'origin': test_origins})\n",
    "# Apply mapping\n",
    "print(\"🛠️ Applying origin mapping...\")\n",
    "mapping_results = test_df['origin'].apply(map_origin)\n",
    "test_df['origin_id'] = [result[0] for result in mapping_results]\n",
    "test_df['mapped_region'] = [result[1] for result in mapping_results]\n",
    "\n",
    "# Summary\n",
    "print(\"✅ Origin mapping completed.\")\n",
    "print(f\"✅ Mapped origins: {test_df['origin_id'].notna().sum()}\")\n",
    "print(f\"❌ Unmapped origins: {test_df['origin_id'].isna().sum()}\")\n",
    "print(\"📋 Test results:\")\n",
    "print(test_df[['origin', 'origin_id', 'mapped_region']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40dd7c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying origin mapping...\n",
      "✅ Origin mapping completed\n",
      "Mapped origins: 1322\n",
      "Unmapped origins: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_id</th>\n",
       "      <th>mapped_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>9</td>\n",
       "      <td>Southeast Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>9</td>\n",
       "      <td>Southeast Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>68</td>\n",
       "      <td>Oceanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>68</td>\n",
       "      <td>Oceanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>68</td>\n",
       "      <td>Oceanic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      origin  origin_id    mapped_region\n",
       "0  Indonesia          9  Southeast Asian\n",
       "1  Indonesia          9  Southeast Asian\n",
       "2  Australia         68          Oceanic\n",
       "3  Australia         68          Oceanic\n",
       "4  Australia         68          Oceanic"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply mapping\n",
    "print(\"Applying origin mapping...\")\n",
    "mapping_results = df['origin'].apply(map_origin)\n",
    "df['origin_id'] = [result[0] for result in mapping_results]\n",
    "df['mapped_region'] = [result[1] for result in mapping_results]\n",
    "\n",
    "print(\"✅ Origin mapping completed\")\n",
    "print(f\"Mapped origins: {df['origin_id'].notna().sum()}\")\n",
    "print(f\"Unmapped origins: {df['origin_id'].isna().sum()}\")\n",
    "\n",
    "display(df[['origin', 'origin_id', 'mapped_region']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f350511",
   "metadata": {},
   "source": [
    "##### **Formatting Difficulty**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ad025de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prep_time</th>\n",
       "      <th>cook_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prep_time  cook_time\n",
       "0       15.0       45.0\n",
       "1       30.0       30.0\n",
       "2       10.0       20.0\n",
       "3        5.0       10.0\n",
       "4       10.0        2.0\n",
       "5        5.0       10.0\n",
       "6       10.0       40.0\n",
       "7        5.0       15.0\n",
       "8        5.0       10.0\n",
       "9       10.0       30.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_min(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    match = re.search(r'\\d+', str(text))\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    return None\n",
    "\n",
    "# Apply the function to prep_time and cook_time columns\n",
    "df['prep_time'] = df['prep_time'].apply(remove_min)\n",
    "df['cook_time'] = df['cook_time'].apply(remove_min)\n",
    "\n",
    "df[['prep_time', 'cook_time']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e14743bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "def parse_ingredients(text):\n",
    "    \"\"\"\n",
    "    Extracts lines that start with '-' from a block of text and returns a list of ingredients.\n",
    "    \"\"\"\n",
    "    ingredients = []\n",
    "    num_ingredient=0\n",
    "    # print(text)\n",
    "    for line in text.split('\\n'):\n",
    "        stripped = line.strip()\n",
    "        if stripped.startswith('-'):\n",
    "            ingredients.append(stripped[1:].strip())\n",
    "            num_ingredient+=1\n",
    "    return num_ingredient\n",
    "\n",
    "\n",
    "def parse_instructions(text):\n",
    "    \"\"\"\n",
    "    Extracts numbered steps from a block of text and returns a list of instruction strings.\n",
    "    \"\"\"\n",
    "    instructions = []\n",
    "    num_instruction=0\n",
    "    for line in text.splitlines():\n",
    "        stripped = line.strip()\n",
    "        if stripped.startswith(str(num_instruction+1)+'.'):\n",
    "            instructions.append(stripped[len(str(num_instruction+1))+1:].strip())\n",
    "            num_instruction+=1\n",
    "    return num_instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bda05900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_difficulty(ingredients, instructions):\n",
    "    ingredients = codecs.decode(ingredients, 'unicode_escape')\n",
    "    instructions = codecs.decode(instructions, 'unicode_escape')\n",
    "    num_ingredients = parse_ingredients(ingredients)\n",
    "    num_steps = parse_instructions(instructions)\n",
    "    # print(f\"Number of ingredients: {num_ingredients}\")\n",
    "    # print(f\"Number of steps: {num_steps}\")\n",
    "    if num_ingredients <= 4 and num_steps <= 5:\n",
    "        return \"Easy\"\n",
    "    elif num_ingredients <= 8 and num_steps <= 8:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Hard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "671ac456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>difficulty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitterballs (Bitterballen)</td>\n",
       "      <td>Hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Broccoli/Cauliflower Cheese</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vegetable Fingers</td>\n",
       "      <td>Easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beef Casserole</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Toast Fingers</td>\n",
       "      <td>Easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pumpkin Polenta Fingers</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rice Pudding</td>\n",
       "      <td>Easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hummus</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baked Bean Pie</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name difficulty\n",
       "0  Cassava Porridge with Fish Sauce and Lemon (Bu...     Medium\n",
       "1                         Bitterballs (Bitterballen)       Hard\n",
       "2                        Broccoli/Cauliflower Cheese     Medium\n",
       "3                                  Vegetable Fingers       Easy\n",
       "4                                     Beef Casserole     Medium\n",
       "5                                      Toast Fingers       Easy\n",
       "6                            Pumpkin Polenta Fingers     Medium\n",
       "7                                       Rice Pudding       Easy\n",
       "8                                             Hummus     Medium\n",
       "9                                     Baked Bean Pie     Medium"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate difficulty\n",
    "df['difficulty'] = df.apply(\n",
    "    lambda row: estimate_difficulty(row['ingredients'], row['instructions']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df[['name', 'difficulty']].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f7d5c",
   "metadata": {},
   "source": [
    "##### **Determine Choking Hazard**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "2851e5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all_choking_hazards': ['whole blueberries',\n",
      "                         'grapes',\n",
      "                         'whole cherry tomatoes',\n",
      "                         'whole strawberries',\n",
      "                         'raw apple chunks',\n",
      "                         'raw pear chunks',\n",
      "                         'whole grapes',\n",
      "                         'whole raspberries',\n",
      "                         'whole blackberries',\n",
      "                         'whole peaches',\n",
      "                         'melon balls',\n",
      "                         'raw carrot sticks',\n",
      "                         'raw bell pepper',\n",
      "                         'raw cucumber',\n",
      "                         'raw zucchini',\n",
      "                         'raw broccoli florets',\n",
      "                         'raw cauliflower',\n",
      "                         'raw green beans',\n",
      "                         'whole edamame',\n",
      "                         'whole peas',\n",
      "                         'whole lentils',\n",
      "                         'whole chickpeas',\n",
      "                         'whole kidney beans',\n",
      "                         'soybeans',\n",
      "                         'natto',\n",
      "                         'udon noodles',\n",
      "                         'rice cakes',\n",
      "                         'gummy candies',\n",
      "                         'marshmallows',\n",
      "                         'caramels',\n",
      "                         'chewing gum',\n",
      "                         'popcorn',\n",
      "                         'chicken chunks',\n",
      "                         'beef cubes',\n",
      "                         'turkey cubes',\n",
      "                         'salmon bites',\n",
      "                         'hot dogs',\n",
      "                         'sausage slices',\n",
      "                         'large meatballs',\n",
      "                         'whole almonds',\n",
      "                         'walnuts',\n",
      "                         'peanuts',\n",
      "                         'cashews',\n",
      "                         'sunflower seeds',\n",
      "                         'chia seeds',\n",
      "                         'flaxseeds',\n",
      "                         'honeycomb',\n",
      "                         'hard candy',\n",
      "                         'jelly beans',\n",
      "                         'gummy bears',\n",
      "                         'pretzels',\n",
      "                         'bread crusts',\n",
      "                         'toasted bread cubes',\n",
      "                         'crackers',\n",
      "                         'not cooked until soft',\n",
      "                         'left whole',\n",
      "                         'cut into large pieces',\n",
      "                         'bake instead of steam',\n",
      "                         'not mashed',\n",
      "                         'not pureed'],\n",
      " 'beans_and_legumes': ['whole edamame',\n",
      "                       'whole peas',\n",
      "                       'whole lentils',\n",
      "                       'whole chickpeas',\n",
      "                       'whole kidney beans',\n",
      "                       'soybeans',\n",
      "                       'natto'],\n",
      " 'hard_raw_vegetables': ['raw carrot sticks',\n",
      "                         'raw bell pepper',\n",
      "                         'raw cucumber',\n",
      "                         'raw zucchini',\n",
      "                         'raw broccoli florets',\n",
      "                         'raw cauliflower',\n",
      "                         'raw green beans'],\n",
      " 'meat_chunks': ['chicken chunks',\n",
      "                 'beef cubes',\n",
      "                 'turkey cubes',\n",
      "                 'salmon bites',\n",
      "                 'hot dogs',\n",
      "                 'sausage slices',\n",
      "                 'large meatballs'],\n",
      " 'nuts_and_seeds': ['whole almonds',\n",
      "                    'walnuts',\n",
      "                    'peanuts',\n",
      "                    'cashews',\n",
      "                    'sunflower seeds',\n",
      "                    'chia seeds',\n",
      "                    'flaxseeds',\n",
      "                    'honeycomb'],\n",
      " 'other_choking_risks': ['hard candy',\n",
      "                         'jelly beans',\n",
      "                         'gummy bears',\n",
      "                         'pretzels',\n",
      "                         'bread crusts',\n",
      "                         'toasted bread cubes',\n",
      "                         'crackers'],\n",
      " 'sticky_slippery_foods': ['udon noodles',\n",
      "                           'rice cakes',\n",
      "                           'gummy candies',\n",
      "                           'marshmallows',\n",
      "                           'caramels',\n",
      "                           'chewing gum',\n",
      "                           'popcorn'],\n",
      " 'unsafe_preparation_methods': ['not cooked until soft',\n",
      "                                'left whole',\n",
      "                                'cut into large pieces',\n",
      "                                'bake instead of steam',\n",
      "                                'not mashed',\n",
      "                                'not pureed'],\n",
      " 'whole_or_firm_fruits': ['whole blueberries',\n",
      "                          'grapes',\n",
      "                          'whole cherry tomatoes',\n",
      "                          'whole strawberries',\n",
      "                          'raw apple chunks',\n",
      "                          'raw pear chunks',\n",
      "                          'whole grapes',\n",
      "                          'whole raspberries',\n",
      "                          'whole blackberries',\n",
      "                          'whole peaches',\n",
      "                          'melon balls']}\n"
     ]
    }
   ],
   "source": [
    "# Load the module\n",
    "import importlib\n",
    "\n",
    "choking_hazard_path = os.path.join(os.getcwd(), \"preprocessing_techniques\", \"mappers\", \"choking_hazard_classifiers.py\")\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"choking_hazard\", choking_hazard_path)\n",
    "choking_hazard_file = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(choking_hazard_file)\n",
    "\n",
    "# Access the config\n",
    "choking_hazard  = choking_hazard_file.choking_hazard\n",
    "pprint(choking_hazard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "529f866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_choking_hazard(row):\n",
    "    \"\"\"\n",
    "    Detects baby food choking hazards using NER ingredients + instructions.\n",
    "    \n",
    "    Parameters:\n",
    "        row: DataFrame row with ner_ingredient, ingredient, and instructions\n",
    "    \n",
    "    Returns:\n",
    "        str: \"Yes\" or \"No\"\n",
    "    \"\"\"\n",
    "    # Step 1: Get & normalize ingredients\n",
    "    ner_ingredients = row.get(\"ner_ingredient\", [])\n",
    "    original_ingredients = row.get(\"ingredient\", \"\")\n",
    "    instructions = row.get(\"instructions\", \"\")\n",
    "    \n",
    "    # Convert list of ingredients to string for search\n",
    "    ner_ingredients_text = ' '.join([str(i).lower() for i in ner_ingredients])\n",
    "    \n",
    "    # Step 2: Clean instructions\n",
    "    cleaned_instructions = \"\"\n",
    "    if instructions:\n",
    "        if callable(getattr(instructions, 'lower', None)):\n",
    "            cleaned_instructions = instructions.lower()\n",
    "    \n",
    "    # Step 3: Combine all searchable text\n",
    "    combined_text = ' '.join([\n",
    "        ner_ingredients_text,\n",
    "        str(original_ingredients).lower(),\n",
    "        cleaned_instructions\n",
    "    ])\n",
    "    \n",
    "    # Step 4: Match against all_choking_hazards\n",
    "    matched_categories = []\n",
    "    for category, hazards in choking_hazard.items():\n",
    "        if category == \"all_choking_hazards\":\n",
    "            # Optional: Add a general safety fallback\n",
    "            for hazard in hazards:\n",
    "                if hazard in combined_text and \"all_choking_hazards\" not in matched_categories:\n",
    "                    matched_categories.append(\"all_choking_hazards\")\n",
    "                    break  # No need to keep checking once match found\n",
    "        else:\n",
    "            # Regular categories like fruits, veggies, etc.\n",
    "            for hazard in hazards:\n",
    "                if hazard in combined_text and category not in matched_categories:\n",
    "                    matched_categories.append(category)\n",
    "                    break  # Break inner loop after first match in this category\n",
    "    \n",
    "    if matched_categories:\n",
    "        return \"Yes\"\n",
    "    else:\n",
    "        return \"No\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "6deeff4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ner_ingredient_string</th>\n",
       "      <th>choking_hazards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>cassava,fish,chicken,coconut oil,chicken broth...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitterballs (Bitterballen)</td>\n",
       "      <td>beef,potato starch,milk,egg,margarine,salt,che...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Broccoli/Cauliflower Cheese</td>\n",
       "      <td>cauliflower,broccoli,margarine,flour,milk,ched...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vegetable Fingers</td>\n",
       "      <td>carrot,potato,sweet potato</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beef Casserole</td>\n",
       "      <td>onion,vegetable oil,beef,steak,carrots,potatoe...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Toast Fingers</td>\n",
       "      <td>wholemeal bread</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pumpkin Polenta Fingers</td>\n",
       "      <td>water,polenta,pumpkin,parmesan cheese,oil</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rice Pudding</td>\n",
       "      <td>rice,milk,sugar,vanilla essence</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hummus</td>\n",
       "      <td>chickpeas,garlic,lemon juice,milk,tahini</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baked Bean Pie</td>\n",
       "      <td>baked beans,zucchini,potatoes,milk,cheese,chives</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Cassava Porridge with Fish Sauce and Lemon (Bu...   \n",
       "1                         Bitterballs (Bitterballen)   \n",
       "2                        Broccoli/Cauliflower Cheese   \n",
       "3                                  Vegetable Fingers   \n",
       "4                                     Beef Casserole   \n",
       "5                                      Toast Fingers   \n",
       "6                            Pumpkin Polenta Fingers   \n",
       "7                                       Rice Pudding   \n",
       "8                                             Hummus   \n",
       "9                                     Baked Bean Pie   \n",
       "\n",
       "                               ner_ingredient_string choking_hazards  \n",
       "0  cassava,fish,chicken,coconut oil,chicken broth...              No  \n",
       "1  beef,potato starch,milk,egg,margarine,salt,che...              No  \n",
       "2  cauliflower,broccoli,margarine,flour,milk,ched...              No  \n",
       "3                         carrot,potato,sweet potato              No  \n",
       "4  onion,vegetable oil,beef,steak,carrots,potatoe...              No  \n",
       "5                                    wholemeal bread              No  \n",
       "6          water,polenta,pumpkin,parmesan cheese,oil              No  \n",
       "7                    rice,milk,sugar,vanilla essence              No  \n",
       "8           chickpeas,garlic,lemon juice,milk,tahini              No  \n",
       "9   baked beans,zucchini,potatoes,milk,cheese,chives              No  "
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply to every row in the DataFrame\n",
    "df['choking_hazards'] = df.apply(has_choking_hazard, axis=1)\n",
    "df[['name', 'ner_ingredient_string', 'choking_hazards']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e495371",
   "metadata": {},
   "source": [
    "##### Formatting Unique NER Ingredients To **Map Ingredient w/ Allergen Group**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa4565a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ingredients = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3971a16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning NER ingredient after checking \n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download required NLTK data (run once)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# Initialize NLTK lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_ingredient_symbols(ingredient_text):\n",
    "    \"\"\"\n",
    "    Enhanced ingredient cleaning using NLTK for baby food ingredients\n",
    "    \"\"\"\n",
    "    if not ingredient_text or pd.isna(ingredient_text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to string and strip\n",
    "    cleaned = str(ingredient_text).strip().lower()\n",
    "    \n",
    "    # Remove brackets and quotes\n",
    "    cleaned = re.sub(r'^[\\[\\'\\\"\\s]+', '', cleaned)\n",
    "    cleaned = re.sub(r'[\\]\\'\\\"\\s]+$', '', cleaned)\n",
    "    cleaned = re.sub(r'[\\[\\]\\'\\\"]', '', cleaned)\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
    "    \n",
    "    if not cleaned or len(cleaned) <= 1:\n",
    "        return \"\"\n",
    "    \n",
    "    # Split into words for processing\n",
    "    words = cleaned.split()\n",
    "    processed_words = []\n",
    "    \n",
    "    # Words to completely remove\n",
    "    words_to_remove = {\n",
    "        'baby', 'babies', 'infant', 'toddler', 'little', 'mini', 'small',\n",
    "        'organic', 'fresh', 'frozen', 'canned', 'dried', 'raw', 'cooked',\n",
    "        'steamed', 'boiled', 'mashed', 'pureed', 'chopped', 'diced',\n",
    "        'sliced', 'grated', 'peeled', 'unsalted', 'natural', 'pure',\n",
    "        'whole', 'half', 'quarter', 'piece', 'pieces'\n",
    "    }\n",
    "    \n",
    "    for word in words:\n",
    "        # Skip banned words\n",
    "        if word.lower() in words_to_remove:\n",
    "            continue\n",
    "        \n",
    "        # Use NLTK lemmatizer to handle plurals\n",
    "        singular_word = lemmatizer.lemmatize(word, 'n')  # 'n' for noun\n",
    "        \n",
    "        # If NLTK didn't change it, try custom food-specific rules\n",
    "        if singular_word == word:\n",
    "            singular_word = handle_food_plurals(word)\n",
    "        \n",
    "        if singular_word and len(singular_word) > 1:\n",
    "            processed_words.append(singular_word)\n",
    "    \n",
    "    result = ' '.join(processed_words).strip()\n",
    "    return result if result else \"\"\n",
    "\n",
    "def handle_food_plurals(word):\n",
    "    \"\"\"\n",
    "    Handle food-specific plurals that NLTK might miss\n",
    "    \"\"\"\n",
    "    # Special food cases\n",
    "    food_plurals = {\n",
    "        'potatoes': 'potato',\n",
    "        'tomatoes': 'tomato',\n",
    "        'mangoes': 'mango',\n",
    "        'avocados': 'avocado',\n",
    "        'bananas': 'banana',\n",
    "        'strawberries': 'strawberry',\n",
    "        'blueberries': 'blueberry',\n",
    "        'raspberries': 'raspberry',\n",
    "        'blackberries': 'blackberry',\n",
    "        'cranberries': 'cranberry',\n",
    "        'cherries': 'cherry',\n",
    "        'berries': 'berry',\n",
    "        'beans': 'bean',\n",
    "        'peas': 'pea',\n",
    "        'carrots': 'carrot',\n",
    "        'onions': 'onion',\n",
    "        'peppers': 'pepper',\n",
    "        'eggs': 'egg',\n",
    "        'nuts': 'nut',\n",
    "        'oats': 'oat',\n",
    "        'grains': 'grain',\n",
    "    }\n",
    "    \n",
    "    word_lower = word.lower()\n",
    "    \n",
    "    # Check special cases first\n",
    "    if word_lower in food_plurals:\n",
    "        return food_plurals[word_lower]\n",
    "    \n",
    "    # Apply general plural rules\n",
    "    # Words ending in 'ies' -> 'y'\n",
    "    if word_lower.endswith('ies') and len(word_lower) > 4:\n",
    "        return word_lower[:-3] + 'y'\n",
    "    \n",
    "    # Words ending in 'oes' -> 'o'\n",
    "    if word_lower.endswith('oes') and len(word_lower) > 4:\n",
    "        return word_lower[:-2]\n",
    "    \n",
    "    # Words ending in 's' -> remove 's'\n",
    "    if word_lower.endswith('s') and len(word_lower) > 2:\n",
    "        return word_lower[:-1]\n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90ac6c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTING NLTK-BASED CLEANING ===\n",
      "Before → After cleaning:\n",
      "'baby spinach' → 'spinach'\n",
      "'organic sweet potatoes' → 'sweet potato'\n",
      "'fresh strawberries' → 'strawberry'\n",
      "'mini carrots' → 'carrot'\n",
      "'cooked black beans' → 'black bean'\n",
      "'mashed bananas' → 'banana'\n",
      "'steamed broccoli florets' → 'broccoli floret'\n",
      "'pureed mangoes' → 'mango'\n",
      "'diced tomatoes' → 'tomato'\n",
      "'baby peas' → 'pea'\n"
     ]
    }
   ],
   "source": [
    "# Test the enhanced function\n",
    "print(\"=== TESTING NLTK-BASED CLEANING ===\")\n",
    "test_cases = [\n",
    "    \"baby spinach\",\n",
    "    \"organic sweet potatoes\", \n",
    "    \"fresh strawberries\",\n",
    "    \"mini carrots\",\n",
    "    \"cooked black beans\",\n",
    "    \"mashed bananas\",\n",
    "    \"steamed broccoli florets\",\n",
    "    \"pureed mangoes\",\n",
    "    \"diced tomatoes\",\n",
    "    \"baby peas\"\n",
    "]\n",
    "\n",
    "print(\"Before → After cleaning:\")\n",
    "for ingredient in test_cases:\n",
    "    cleaned = clean_ingredient_symbols(ingredient)\n",
    "    print(f\"'{ingredient}' → '{cleaned}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1dbe952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ingredient_string(ingredient_string):\n",
    "        if not isinstance(ingredient_string, str) or not ingredient_string.strip():\n",
    "            return \"\"\n",
    "        \n",
    "        ingredients = ingredient_string.split(',')\n",
    "        cleaned_ingredients = []\n",
    "        \n",
    "        for ingredient in ingredients:\n",
    "            cleaned_ingredient = clean_ingredient_symbols(ingredient)\n",
    "            if cleaned_ingredient:  # Only add non-empty ingredients\n",
    "                cleaned_ingredients.append(cleaned_ingredient)\n",
    "        # print(f\"Cleaned ingredients: {cleaned_ingredients}\")\n",
    "        return ','.join(cleaned_ingredients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60e200cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CLEANING NER INGREDIENTS ===\n",
      "\n",
      "✅ No rows were removed - all recipes retained valid ingredients\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clean_ner_ingredients(df_ingredients):\n",
    "    print(\"=== CLEANING NER INGREDIENTS ===\")\n",
    "    \n",
    "    # Apply cleaning to ner_ingredient_string column\n",
    "    df_ingredients['ner_ingredient_string'] = df_ingredients['ner_ingredient_string'].apply(clean_ingredient_string)\n",
    "    \n",
    "    # BEFORE removing rows, identify which ones will be deleted\n",
    "    initial_count = len(df_ingredients)\n",
    "    \n",
    "    # Find rows that will be deleted (empty or whitespace-only strings)\n",
    "    rows_to_delete = df_ingredients[df_ingredients['ner_ingredient_string'].apply(lambda x: len(str(x).strip()) == 0)]\n",
    "    \n",
    "    if len(rows_to_delete) > 0:\n",
    "        print(f\"\\n⚠️  ROWS TO BE DELETED ({len(rows_to_delete)} rows):\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Display information about deleted rows\n",
    "        for idx, row in rows_to_delete.iterrows():\n",
    "            print(f\"\\nRow Index: {idx}\")\n",
    "            print(f\"Recipe Name: {row.get('name', 'N/A')}\")\n",
    "            print(f\"Original ner_ingredient_string: '{row.get('ner_ingredient_string', 'N/A')}'\")\n",
    "            \n",
    "            # Show the original ner_ingredient if available\n",
    "            if 'ner_ingredient' in row:\n",
    "                print(f\"Original ner_ingredient: {row['ner_ingredient']}\")\n",
    "            \n",
    "            # Show original ingredients if available\n",
    "            if 'ingredient' in row:\n",
    "                original_ingredients = str(row['ingredient'])[:100] + \"...\" if len(str(row['ingredient'])) > 100 else str(row['ingredient'])\n",
    "                print(f\"Original ingredients: {original_ingredients}\")\n",
    "            \n",
    "            print(\"-\" * 40)\n",
    "        \n",
    "        # Optional: Save deleted rows to a separate file for analysis\n",
    "        rows_to_delete.to_excel('deleted_rows_analysis.xlsx', index=True)\n",
    "        print(f\"\\n💾 Saved deleted rows to 'deleted_rows_analysis.xlsx' for detailed analysis\")\n",
    "    \n",
    "    # Now remove the rows\n",
    "    df_ingredients = df_ingredients[df_ingredients['ner_ingredient_string'].apply(lambda x: len(str(x).strip()) > 0)]\n",
    "    removed_count = initial_count - len(df_ingredients)\n",
    "    \n",
    "    if removed_count > 0:\n",
    "        print(f\"\\n✅ Removed {removed_count} rows with no valid ingredients after cleaning\")\n",
    "        print(f\"Remaining rows: {len(df_ingredients)}\")\n",
    "    else:\n",
    "        print(\"\\n✅ No rows were removed - all recipes retained valid ingredients\")\n",
    "    \n",
    "    return df_ingredients\n",
    "\n",
    "# Apply the enhanced cleaning function\n",
    "df_ingredients = clean_ner_ingredients(df_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc1a625e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ner_ingredient_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>cassava,fish,chicken,coconut oil,chicken broth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitterballs (Bitterballen)</td>\n",
       "      <td>beef,potato starch,milk,egg,margarine,salt,che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Broccoli/Cauliflower Cheese</td>\n",
       "      <td>cauliflower,broccoli,margarine,flour,milk,ched...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vegetable Fingers</td>\n",
       "      <td>carrot,potato,sweet potato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beef Casserole</td>\n",
       "      <td>onion,vegetable oil,beef,steak,carrots,potatoe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Toast Fingers</td>\n",
       "      <td>wholemeal bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pumpkin Polenta Fingers</td>\n",
       "      <td>water,polenta,pumpkin,parmesan cheese,oil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rice Pudding</td>\n",
       "      <td>rice,milk,sugar,vanilla essence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hummus</td>\n",
       "      <td>chickpeas,garlic,lemon juice,milk,tahini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baked Bean Pie</td>\n",
       "      <td>baked beans,zucchini,potatoes,milk,cheese,chives</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Cassava Porridge with Fish Sauce and Lemon (Bu...   \n",
       "1                         Bitterballs (Bitterballen)   \n",
       "2                        Broccoli/Cauliflower Cheese   \n",
       "3                                  Vegetable Fingers   \n",
       "4                                     Beef Casserole   \n",
       "5                                      Toast Fingers   \n",
       "6                            Pumpkin Polenta Fingers   \n",
       "7                                       Rice Pudding   \n",
       "8                                             Hummus   \n",
       "9                                     Baked Bean Pie   \n",
       "\n",
       "                               ner_ingredient_string  \n",
       "0  cassava,fish,chicken,coconut oil,chicken broth...  \n",
       "1  beef,potato starch,milk,egg,margarine,salt,che...  \n",
       "2  cauliflower,broccoli,margarine,flour,milk,ched...  \n",
       "3                         carrot,potato,sweet potato  \n",
       "4  onion,vegetable oil,beef,steak,carrots,potatoe...  \n",
       "5                                    wholemeal bread  \n",
       "6          water,polenta,pumpkin,parmesan cheese,oil  \n",
       "7                    rice,milk,sugar,vanilla essence  \n",
       "8           chickpeas,garlic,lemon juice,milk,tahini  \n",
       "9   baked beans,zucchini,potatoes,milk,cheese,chives  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['name', 'ner_ingredient_string']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "521d4b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ner_ingredient_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>cassava,fish,chicken,coconut oil,chicken broth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitterballs (Bitterballen)</td>\n",
       "      <td>beef,potato starch,milk,egg,margarine,salt,che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Broccoli/Cauliflower Cheese</td>\n",
       "      <td>cauliflower,broccoli,margarine,flour,milk,ched...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vegetable Fingers</td>\n",
       "      <td>carrot,potato,sweet potato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beef Casserole</td>\n",
       "      <td>onion,vegetable oil,beef,steak,carrots,potatoe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Toast Fingers</td>\n",
       "      <td>wholemeal bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pumpkin Polenta Fingers</td>\n",
       "      <td>water,polenta,pumpkin,parmesan cheese,oil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rice Pudding</td>\n",
       "      <td>rice,milk,sugar,vanilla essence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hummus</td>\n",
       "      <td>chickpeas,garlic,lemon juice,milk,tahini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baked Bean Pie</td>\n",
       "      <td>baked beans,zucchini,potatoes,milk,cheese,chives</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Cassava Porridge with Fish Sauce and Lemon (Bu...   \n",
       "1                         Bitterballs (Bitterballen)   \n",
       "2                        Broccoli/Cauliflower Cheese   \n",
       "3                                  Vegetable Fingers   \n",
       "4                                     Beef Casserole   \n",
       "5                                      Toast Fingers   \n",
       "6                            Pumpkin Polenta Fingers   \n",
       "7                                       Rice Pudding   \n",
       "8                                             Hummus   \n",
       "9                                     Baked Bean Pie   \n",
       "\n",
       "                               ner_ingredient_string  \n",
       "0  cassava,fish,chicken,coconut oil,chicken broth...  \n",
       "1  beef,potato starch,milk,egg,margarine,salt,che...  \n",
       "2  cauliflower,broccoli,margarine,flour,milk,ched...  \n",
       "3                         carrot,potato,sweet potato  \n",
       "4  onion,vegetable oil,beef,steak,carrots,potatoe...  \n",
       "5                                    wholemeal bread  \n",
       "6          water,polenta,pumpkin,parmesan cheese,oil  \n",
       "7                    rice,milk,sugar,vanilla essence  \n",
       "8           chickpeas,garlic,lemon juice,milk,tahini  \n",
       "9   baked beans,zucchini,potatoes,milk,cheese,chives  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique ingredients found: 930\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_ingredients = []\n",
    "\n",
    "for ingredient_string in df_ingredients['ner_ingredient_string']:\n",
    "    if isinstance(ingredient_string, str) and ingredient_string.strip():\n",
    "        # Split by comma and clean each ingredient\n",
    "        ingredients = [ing.strip().lower() for ing in ingredient_string.split(',') if ing.strip()]\n",
    "        all_ingredients.extend(ingredients)\n",
    "\n",
    "display(df[['name', 'ner_ingredient_string']].head(10))\n",
    "print(f\"Total unique ingredients found: {len(set(all_ingredients))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02435324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CHECKING FOR REMAINING ISSUES ===\n",
      "✅ All problematic symbols have been cleaned!\n",
      "\n",
      "=== CLEANING RESULTS ===\n",
      "Examples of cleaned ingredients:\n",
      " 1. 'mayonnaise'\n",
      " 2. 'chicken seasoning'\n",
      " 3. 'tapioca'\n",
      " 4. 'petit suisse'\n",
      " 5. 'chicken abon'\n",
      " 6. 'rice milk'\n",
      " 7. 'kamote'\n",
      " 8. 'ground beef'\n",
      " 9. 'gla water'\n",
      "10. 'yellow sweet corn'\n",
      "\n",
      "Total unique ingredients after cleaning: 930\n",
      "Total ingredient instances: 8162\n"
     ]
    }
   ],
   "source": [
    "# Check for problematic ingredients again\n",
    "print(\"\\n=== CHECKING FOR REMAINING ISSUES ===\")\n",
    "problematic_ingredients = []\n",
    "\n",
    "for ingredient in all_ingredients:\n",
    "    # Check for symbols, empty strings, or unwanted characters\n",
    "    if any(char in ingredient for char in ['[', ']', '_', '___', '{', '}', '(', ')', '@', '#', '$', \"'\", '\"']):\n",
    "        problematic_ingredients.append(ingredient)\n",
    "\n",
    "if problematic_ingredients:\n",
    "    print(f\"Still found {len(problematic_ingredients)} ingredients with symbols:\")\n",
    "    for ing in set(problematic_ingredients):\n",
    "        count = problematic_ingredients.count(ing)\n",
    "        print(f\"  '{ing}' - appears {count} times\")\n",
    "else:\n",
    "    print(\"✅ All problematic symbols have been cleaned!\")\n",
    "\n",
    "# Show before and after examples\n",
    "print(\"\\n=== CLEANING RESULTS ===\")\n",
    "print(\"Examples of cleaned ingredients:\")\n",
    "unique_ingredients = list(set(all_ingredients))\n",
    "for i, ing in enumerate(unique_ingredients[:10]):\n",
    "    print(f\"{i+1:2d}. '{ing}'\")\n",
    "\n",
    "print(f\"\\nTotal unique ingredients after cleaning: {len(unique_ingredients)}\")\n",
    "print(f\"Total ingredient instances: {len(all_ingredients)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "846a646a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created recipe-ingredient structure:\n",
      "   Original recipes: 1322\n",
      "   Recipe-ingredient records: 8176\n",
      "   Average ingredients per recipe: 6.18\n",
      "\n",
      "📋 Sample Recipe-Ingredient Structure:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>recipe_name</th>\n",
       "      <th>single_ingredient</th>\n",
       "      <th>ingredient_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>cassava</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>fish</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>chicken</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>coconut oil</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>chicken broth</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>lime juice</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>spinach</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Bitterballs (Bitterballen)</td>\n",
       "      <td>beef</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>Bitterballs (Bitterballen)</td>\n",
       "      <td>potato starch</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>Bitterballs (Bitterballen)</td>\n",
       "      <td>milk</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe_id                                        recipe_name  \\\n",
       "0          1  Cassava Porridge with Fish Sauce and Lemon (Bu...   \n",
       "1          1  Cassava Porridge with Fish Sauce and Lemon (Bu...   \n",
       "2          1  Cassava Porridge with Fish Sauce and Lemon (Bu...   \n",
       "3          1  Cassava Porridge with Fish Sauce and Lemon (Bu...   \n",
       "4          1  Cassava Porridge with Fish Sauce and Lemon (Bu...   \n",
       "5          1  Cassava Porridge with Fish Sauce and Lemon (Bu...   \n",
       "6          1  Cassava Porridge with Fish Sauce and Lemon (Bu...   \n",
       "7          2                         Bitterballs (Bitterballen)   \n",
       "8          2                         Bitterballs (Bitterballen)   \n",
       "9          2                         Bitterballs (Bitterballen)   \n",
       "\n",
       "  single_ingredient  ingredient_position  \n",
       "0           cassava                    1  \n",
       "1              fish                    2  \n",
       "2           chicken                    3  \n",
       "3       coconut oil                    4  \n",
       "4     chicken broth                    5  \n",
       "5        lime juice                    6  \n",
       "6           spinach                    7  \n",
       "7              beef                    1  \n",
       "8     potato starch                    2  \n",
       "9              milk                    3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'df' in locals() and 'ner_ingredient_string' in df.columns:\n",
    "    \n",
    "    # Create recipe-ingredient structure\n",
    "    recipe_ingredient_data = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        recipe_id = index + 1  # Creating recipe_id starting from 1\n",
    "        recipe_name = row.get('name', f'Recipe_{recipe_id}')  # Use actual name or fallback\n",
    "        ner_ingredient_string = str(row['ner_ingredient_string']).strip()\n",
    "        \n",
    "        if pd.isna(ner_ingredient_string) or ner_ingredient_string == 'nan' or ner_ingredient_string == '':\n",
    "            # Handle empty ingredient strings\n",
    "            recipe_ingredient_data.append({\n",
    "                'recipe_id': recipe_id,\n",
    "                'recipe_name': recipe_name,\n",
    "                'single_ingredient': None,\n",
    "                'ingredient_position': 0,\n",
    "                'original_ingredient_string': ner_ingredient_string\n",
    "            })\n",
    "        else:\n",
    "            # Split by comma and clean each ingredient\n",
    "            individual_ingredients = [ing.strip() for ing in ner_ingredient_string.split(',')]\n",
    "            individual_ingredients = [ing for ing in individual_ingredients if ing]  # Remove empty strings\n",
    "            \n",
    "            if individual_ingredients:\n",
    "                for position, ingredient in enumerate(individual_ingredients, 1):\n",
    "                    recipe_ingredient_data.append({\n",
    "                        'recipe_id': recipe_id,\n",
    "                        'recipe_name': recipe_name,\n",
    "                        'single_ingredient': ingredient,\n",
    "                        'ingredient_position': position,\n",
    "                        'original_ingredient_string': ner_ingredient_string\n",
    "                    })\n",
    "            else:\n",
    "                # Fallback for cases where split results in empty list\n",
    "                recipe_ingredient_data.append({\n",
    "                    'recipe_id': recipe_id,\n",
    "                    'recipe_name': recipe_name,\n",
    "                    'single_ingredient': ner_ingredient_string,\n",
    "                    'ingredient_position': 1,\n",
    "                    'original_ingredient_string': ner_ingredient_string\n",
    "                })\n",
    "    \n",
    "    # Create recipe-ingredient dataframe\n",
    "    recipe_ingredient_df = pd.DataFrame(recipe_ingredient_data)\n",
    "    \n",
    "    print(f\"✅ Created recipe-ingredient structure:\")\n",
    "    print(f\"   Original recipes: {len(df)}\")\n",
    "    print(f\"   Recipe-ingredient records: {len(recipe_ingredient_df)}\")\n",
    "    print(f\"   Average ingredients per recipe: {len(recipe_ingredient_df) / len(df):.2f}\")\n",
    "    \n",
    "    # Show sample structure\n",
    "    print(f\"\\n📋 Sample Recipe-Ingredient Structure:\")\n",
    "    sample_recipes = recipe_ingredient_df[recipe_ingredient_df['recipe_id'].isin([1, 2, 3])]\n",
    "    display(sample_recipes[['recipe_id', 'recipe_name', 'single_ingredient', 'ingredient_position']].head(10))\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Dataset not found or 'ner_ingredient_string' column missing\")\n",
    "    if 'df' in locals():\n",
    "        print(\"Available columns:\", [col for col in df.columns if 'ingredient' in str(col).lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "ed8c6c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Unique Ingredients Analysis:\n",
      "   Total unique ingredients: 1055\n",
      "   Sample unique ingredients: ['cassava', 'fish', 'chicken', 'coconut oil', 'chicken broth', 'lime juice', 'spinach', 'beef', 'potato starch', 'milk']\n"
     ]
    }
   ],
   "source": [
    "# Get unique ingredients\n",
    "unique_ingredients_list = recipe_ingredient_df['single_ingredient'].dropna().unique()\n",
    "print(f\"\\n📊 Unique Ingredients Analysis:\")\n",
    "print(f\"   Total unique ingredients: {len(unique_ingredients_list)}\")\n",
    "print(f\"   Sample unique ingredients: {list(unique_ingredients_list[:10])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "8226e391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with null values in 'single_ingredient', 'ingredient_position', or 'recipe_name':\n",
      "Number of rows with nulls: 13\n",
      "Sample rows with null values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>single_ingredient</th>\n",
       "      <th>ingredient_position</th>\n",
       "      <th>recipe_name</th>\n",
       "      <th>original_ingredient_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>Fish congee</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7783</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>Fruity Winter Oats Recipe</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>Italian Meatloaf with Salsa</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>Mini Meatballs with Pasta</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuna Salad</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7787</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>Pasta Chicken Bake</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>Vegetable Patties</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7789</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>Easy Chicken Dinner</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7790</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>Biscuits</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7791</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>Minestrone Soup</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     single_ingredient  ingredient_position                  recipe_name  \\\n",
       "2918              None                    0                  Fish congee   \n",
       "7783              None                    0    Fruity Winter Oats Recipe   \n",
       "7784              None                    0  Italian Meatloaf with Salsa   \n",
       "7785              None                    0    Mini Meatballs with Pasta   \n",
       "7786              None                    0                   Tuna Salad   \n",
       "7787              None                    0           Pasta Chicken Bake   \n",
       "7788              None                    0            Vegetable Patties   \n",
       "7789              None                    0          Easy Chicken Dinner   \n",
       "7790              None                    0                     Biscuits   \n",
       "7791              None                    0              Minestrone Soup   \n",
       "\n",
       "     original_ingredient_string  \n",
       "2918                             \n",
       "7783                             \n",
       "7784                             \n",
       "7785                             \n",
       "7786                             \n",
       "7787                             \n",
       "7788                             \n",
       "7789                             \n",
       "7790                             \n",
       "7791                             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping rows with null values in original_ingredient_string,...\n",
      "Remaining rows after dropping nulls: 8176\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in specific columns\n",
    "columns_to_check = ['single_ingredient', 'ingredient_position', 'recipe_name', 'original_ingredient_string']\n",
    "\n",
    "# Method 1: Check if ANY of these columns have null values in ANY row\n",
    "null_mask = recipe_ingredient_df[columns_to_check].isnull().any(axis=1)\n",
    "rows_with_nulls = recipe_ingredient_df[null_mask]\n",
    "\n",
    "print(\"Rows with null values in 'single_ingredient', 'ingredient_position', or 'recipe_name':\")\n",
    "print(f\"Number of rows with nulls: {len(rows_with_nulls)}\")\n",
    "if len(rows_with_nulls) > 0:\n",
    "    print(\"Sample rows with null values:\")\n",
    "    display(rows_with_nulls[columns_to_check].head(10))\n",
    "else:\n",
    "    print(\"✅ No null values found in these columns!\")\n",
    "\n",
    "#drop rows with null values in any of the if original_ingredient_string\n",
    "print(\"Dropping rows with null values in original_ingredient_string,...\")\n",
    "recipe_ingredient_df = recipe_ingredient_df.dropna(subset=['original_ingredient_string'])\n",
    "print(f\"Remaining rows after dropping nulls: {len(recipe_ingredient_df)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac3139c",
   "metadata": {},
   "source": [
    "Standarization of NER Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "e6a5cae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 LOADING NER STANDARDIZATION MAPPING\n",
      "============================================================\n",
      "✅ Loaded 930 standardization mappings\n",
      "\n",
      "📋 Sample standardization mappings:\n",
      "   'acai' → 'acai'\n",
      "   'agar agar' → 'agar-agar powder'\n",
      "   'agar-agar powder' → 'agar-agar powder'\n",
      "   'all purpose flour' → 'all purpose flour'\n",
      "   'all-purpose flour' → 'all purpose flour'\n",
      "   'almond' → 'almond'\n",
      "   'almond butter' → 'almond butter'\n",
      "   'almond milk' → 'almond milk'\n",
      "   'almond nut' → 'almond nut'\n",
      "   'alphabet pasta' → 'pasta'\n"
     ]
    }
   ],
   "source": [
    "print(\"🔄 LOADING NER STANDARDIZATION MAPPING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "standardization_file = 'ner_data_standarization.txt'\n",
    "\n",
    "# Load standardization mapping\n",
    "standardization_mapping = {}\n",
    "compound_ingredients = {}\n",
    "\n",
    "try:\n",
    "    with open(standardization_file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if ' --> ' in line:\n",
    "            original, standardized = line.split(' --> ', 1)\n",
    "            original = original.strip()\n",
    "            standardized = standardized.strip()\n",
    "            standardization_mapping[original] = standardized\n",
    "    \n",
    "    print(f\"✅ Loaded {len(standardization_mapping)} standardization mappings\")\n",
    "    \n",
    "    # Show sample mappings\n",
    "    print(\"\\n📋 Sample standardization mappings:\")\n",
    "    sample_items = list(standardization_mapping.items())[:10]\n",
    "    for original, standardized in sample_items:\n",
    "        print(f\"   '{original}' → '{standardized}'\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ File not found: {standardization_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "806dfe96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETECTING COMPOUND INGREDIENTS\n",
      "✅ Found 8 compound ingredients\n",
      "\n",
      "📋 TOP COMPOUND INGREDIENTS (sorted by frequency):\n",
      "--------------------------------------------------------------------------------\n",
      " 1. 'bumboo teri bubuk sesame seed'\n",
      "    Count: 1 | Reason: multiple_foods\n",
      "    Recipe IDs: [246]\n",
      "\n",
      " 2. 'oil clove garlic beef sweet soy sauce salt sugar rice water tofu'\n",
      "    Count: 1 | Reason: long_sentence\n",
      "    Recipe IDs: [338]\n",
      "\n",
      " 3. 'rice cooking oil clove garlic chicken broth salt shrimp carrot celery extra chicken broth'\n",
      "    Count: 1 | Reason: long_sentence\n",
      "    Recipe IDs: [607]\n",
      "\n",
      " 4. 'rice red sweet potato chicken broth long bean â salt margarine'\n",
      "    Count: 1 | Reason: long_sentence\n",
      "    Recipe IDs: [712]\n",
      "\n",
      " 5. 'seed baby lemon juice water formula milk'\n",
      "    Count: 1 | Reason: long_sentence\n",
      "    Recipe IDs: [783]\n",
      "\n",
      " 6. 'beef chicken broth'\n",
      "    Count: 1 | Reason: multiple_foods\n",
      "    Recipe IDs: [929]\n",
      "\n",
      " 7. 'low sodium vegetable chicken broth'\n",
      "    Count: 1 | Reason: mixed_pattern\n",
      "    Recipe IDs: [930]\n",
      "\n",
      " 8. 'roll egg noodle boiling water'\n",
      "    Count: 1 | Reason: multiple_foods\n",
      "    Recipe IDs: [1263]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def detect_compound_ingredients(recipe_ingredient_df):\n",
    "    \"\"\"\n",
    "    Step 1: Scan all ingredients and list compound sentences that need special handling.\n",
    "    \n",
    "    Args:\n",
    "        recipe_ingredient_df: DataFrame with single_ingredient column\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary of detected compound ingredients and their counts\n",
    "    \"\"\"\n",
    "    print(\"DETECTING COMPOUND INGREDIENTS\")\n",
    "    \n",
    "    compound_indicators = {\n",
    "        'multiple_foods': [],      # Multiple food items in one string\n",
    "        'long_sentences': [],      # More than 4 words\n",
    "        'known_patterns': []       # Known compound patterns\n",
    "    }\n",
    "    \n",
    "    # Criteria for compound detection\n",
    "    def is_likely_compound(ingredient_text):\n",
    "        if not ingredient_text or pd.isna(ingredient_text):\n",
    "            return False, \"null\"\n",
    "            \n",
    "        words = str(ingredient_text).strip().split()\n",
    "        word_count = len(words)\n",
    "        \n",
    "        # Check for multiple food indicators\n",
    "        food_keywords = ['oil', 'sauce', 'salt', 'sugar', 'water', 'milk', 'juice', 'broth', \n",
    "                        'beef', 'chicken', 'pork', 'fish', 'tofu', 'rice', 'noodle', 'egg', 'seed',\n",
    "                        'teri','sesame']\n",
    "        \n",
    "        food_count = sum(1 for word in words if word.lower() in food_keywords)\n",
    "        \n",
    "        # Classification logic\n",
    "        if word_count > 6:\n",
    "            return True, \"long_sentence\"\n",
    "        elif food_count >= 3:\n",
    "            return True, \"multiple_foods\"\n",
    "        elif word_count > 4 and food_count >= 2:\n",
    "            return True, \"mixed_pattern\"\n",
    "        else:\n",
    "            return False, \"simple\"\n",
    "    \n",
    "    # Scan all ingredients\n",
    "    compound_findings = {}\n",
    "    \n",
    "    for index, row in recipe_ingredient_df.iterrows():\n",
    "        ingredient = row['single_ingredient']\n",
    "        is_compound, reason = is_likely_compound(ingredient)\n",
    "        \n",
    "        if is_compound:\n",
    "            if ingredient not in compound_findings:\n",
    "                compound_findings[ingredient] = {\n",
    "                    'count': 0,\n",
    "                    'reason': reason,\n",
    "                    'recipe_ids': []\n",
    "                }\n",
    "            compound_findings[ingredient]['count'] += 1\n",
    "            compound_findings[ingredient]['recipe_ids'].append(row['recipe_id'])\n",
    "    \n",
    "    print(f\"✅ Found {len(compound_findings)} compound ingredients\")\n",
    "    \n",
    "    # Sort by frequency\n",
    "    sorted_compounds = sorted(compound_findings.items(), \n",
    "                            key=lambda x: x[1]['count'], \n",
    "                            reverse=True)\n",
    "    \n",
    "    print(f\"\\n📋 TOP COMPOUND INGREDIENTS (sorted by frequency):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, (ingredient, data) in enumerate(sorted_compounds[:15], 1):\n",
    "        print(f\"{i:2d}. '{ingredient}'\")\n",
    "        print(f\"    Count: {data['count']} | Reason: {data['reason']}\")\n",
    "        print(f\"    Recipe IDs: {data['recipe_ids'][:5]}{'...' if len(data['recipe_ids']) > 5 else ''}\")\n",
    "        print()\n",
    "    \n",
    "    return dict(sorted_compounds)\n",
    "\n",
    "# Run compound detection\n",
    "if 'recipe_ingredient_df' in locals():\n",
    "    detected_compounds = detect_compound_ingredients(recipe_ingredient_df)\n",
    "else:\n",
    "    print(\"❌ Recipe ingredient DataFrame not found. Run previous steps first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "15fbc41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 PREDEFINED COMPOUND PATTERNS\n",
      "============================================================\n",
      "Total predefined patterns: 8\n",
      "\n",
      "Pattern examples:\n",
      "1. 'oil clove garlic beef sweet soy sauce salt sugar rice water tofu'\n",
      "   → ['oil', 'clove garlic', 'beef', 'sweet soy sauce', 'salt', 'sugar', 'rice', 'water', 'tofu']\n",
      "\n",
      "2. 'rice red sweet potato chicken broth long bean salt margarine'\n",
      "   → ['rice', 'red sweet potato', 'chicken broth', 'long bean', 'salt', 'margarine']\n",
      "\n",
      "3. 'seed baby lemon juice water formula milk'\n",
      "   → ['lemon juice', 'water', 'formula milk']\n",
      "\n",
      "4. 'rice cooking oil clove garlic chicken broth salt shrimp carrot celery extra chicken broth'\n",
      "   → ['rice', 'cooking oil', 'clove garlic', 'chicken broth', 'salt', 'shrimp', 'carrot', 'celery', 'extra chicken broth']\n",
      "\n",
      "5. 'cooking oil clove garlic beef sweet soy sauce salt sugar'\n",
      "   → ['cooking oil', 'clove garlic', 'beef', 'sweet soy sauce', 'salt', 'sugar']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREDEFINED_COMPOUND_PATTERNS = {\n",
    "    # Exact matches from your problematic cases\n",
    "    'oil clove garlic beef sweet soy sauce salt sugar rice water tofu': [\n",
    "        'oil', 'clove garlic', 'beef', 'sweet soy sauce', 'salt', 'sugar', 'rice', 'water', 'tofu'\n",
    "    ],\n",
    "    'rice red sweet potato chicken broth long bean salt margarine': [\n",
    "        'rice', 'red sweet potato', 'chicken broth', 'long bean', 'salt', 'margarine'\n",
    "    ],\n",
    "    'seed baby lemon juice water formula milk': [\n",
    "        'lemon juice', 'water', 'formula milk'\n",
    "    ],\n",
    "    'rice cooking oil clove garlic chicken broth salt shrimp carrot celery extra chicken broth': [\n",
    "        'rice', 'cooking oil', 'clove garlic', 'chicken broth', 'salt', 'shrimp', 'carrot', 'celery', 'extra chicken broth'\n",
    "    ],\n",
    "    'cooking oil clove garlic beef sweet soy sauce salt sugar': [\n",
    "        'cooking oil', 'clove garlic', 'beef', 'sweet soy sauce', 'salt', 'sugar'\n",
    "    ],\n",
    "    'bumboo teri bubuk sesame seed': [\n",
    "        'anchovy powder', 'sesame seed'\n",
    "    ],\n",
    "    'roll egg noodle boiling water': [\n",
    "        'noodle', 'water'\n",
    "    ],\n",
    "    'chicken upper lower thigh wing': [\n",
    "        'chicken thigh', 'chicken wing'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"📋 PREDEFINED COMPOUND PATTERNS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total predefined patterns: {len(PREDEFINED_COMPOUND_PATTERNS)}\")\n",
    "print(\"\\nPattern examples:\")\n",
    "for i, (compound, parts) in enumerate(list(PREDEFINED_COMPOUND_PATTERNS.items())[:5], 1):\n",
    "    print(f\"{i}. '{compound}'\")\n",
    "    print(f\"   → {parts}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "cb89dc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_simple_ingredient_only(ingredient, mapping_dict):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        ingredient (str): Single ingredient to standardize\n",
    "        mapping_dict (dict): Standardization mapping rules\n",
    "        \n",
    "    Returns:\n",
    "        str: Standardized ingredient name\n",
    "    \"\"\"\n",
    "    if not ingredient or pd.isna(ingredient):\n",
    "        return None\n",
    "        \n",
    "    ingredient_clean = str(ingredient).strip().lower()\n",
    "    \n",
    "    # Direct mapping lookup only\n",
    "    if ingredient_clean in mapping_dict:\n",
    "        return mapping_dict[ingredient_clean]\n",
    "    \n",
    "    # If no mapping found, return cleaned original\n",
    "    return ingredient_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "251672a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_compound_ingredient_only(ingredient, predefined_patterns):\n",
    "    \"\"\"\n",
    "    PURE COMPOUND CHECKING FUNCTION - NO PROCESSING LOGIC\n",
    "    \n",
    "    Args:\n",
    "        ingredient (str): Ingredient to check\n",
    "        predefined_patterns (dict): Known compound patterns\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if compound, False if simple\n",
    "    \"\"\"\n",
    "    if not ingredient or pd.isna(ingredient):\n",
    "        return False\n",
    "        \n",
    "    ingredient_clean = str(ingredient).strip().lower()\n",
    "    \n",
    "    # Check if it's in our predefined compound patterns (exact match)\n",
    "    if ingredient_clean in predefined_patterns:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "f95a5a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 TESTING COMPOUND CHECKING FUNCTION\n",
      "==================================================\n",
      "Compound detection tests:\n",
      "  'water' → SIMPLE\n",
      "  'yoghurt' → SIMPLE\n",
      "  'oil clove garlic beef sweet soy sauce salt sugar rice water tofu' → COMPOUND\n",
      "  'rice red sweet potato chicken broth long bean salt margarine' → COMPOUND\n",
      "  'chicken' → SIMPLE\n",
      "  'cooking oil clove garlic chicken broth salt shrimp carrot celery' → SIMPLE\n"
     ]
    }
   ],
   "source": [
    "# Test compound checking function\n",
    "print(\"🧪 TESTING COMPOUND CHECKING FUNCTION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "compound_test_cases = [\n",
    "    'water',  # Simple\n",
    "    'yoghurt',  # Simple\n",
    "    'oil clove garlic beef sweet soy sauce salt sugar rice water tofu',  # Compound\n",
    "    'rice red sweet potato chicken broth long bean salt margarine',  # Compound\n",
    "    'chicken',  # Simple\n",
    "    'cooking oil clove garlic chicken broth salt shrimp carrot celery'  # Compound\n",
    "]\n",
    "\n",
    "print(\"Compound detection tests:\")\n",
    "for ingredient in compound_test_cases:\n",
    "    is_compound = is_compound_ingredient_only(ingredient, PREDEFINED_COMPOUND_PATTERNS)\n",
    "    print(f\"  '{ingredient}' → {'COMPOUND' if is_compound else 'SIMPLE'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "c754b2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_compound_ingredient_only(ingredient, predefined_patterns, mapping_dict):\n",
    "    \"\"\"\n",
    "    SIMPLIFIED COMPOUND PROCESSING - ONLY USES PREDEFINED PATTERNS\n",
    "    \n",
    "    Args:\n",
    "        ingredient (str): Compound ingredient to split and standardize\n",
    "        predefined_patterns (dict): Known compound splitting patterns\n",
    "        mapping_dict (dict): Standardization mapping rules (for individual parts)\n",
    "        \n",
    "    Returns:\n",
    "        list: List of standardized individual ingredients\n",
    "    \"\"\"\n",
    "    if not ingredient or pd.isna(ingredient):\n",
    "        return []\n",
    "        \n",
    "    ingredient_clean = str(ingredient).strip().lower()\n",
    "\n",
    "    if ingredient_clean in predefined_patterns:\n",
    "        # Use exact predefined pattern\n",
    "        individual_parts = predefined_patterns[ingredient_clean]\n",
    "        print(f\"  🎯 Using predefined pattern: '{ingredient_clean}' → {individual_parts}\")\n",
    "    else:\n",
    "        print(f\"  ❌ ERROR: '{ingredient_clean}' not found in predefined patterns!\")\n",
    "        return [ingredient_clean]  # Return as single ingredient\n",
    "    \n",
    "    # Apply simple mapping to each individual part\n",
    "    standardized_parts = []\n",
    "    for part in individual_parts:\n",
    "        standardized_part = standardize_simple_ingredient_only(part, mapping_dict)\n",
    "        standardized_parts.append(standardized_part)\n",
    "        print(f\"    '{part}' → '{standardized_part}'\")\n",
    "    \n",
    "    return standardized_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "12dd5a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 ADDING COMPOUND COLUMN TO EXISTING DATAFRAME\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>single_ingredient</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>cassava</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fish</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>chicken</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>coconut oil</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>chicken broth</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>lime juice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>spinach</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>beef</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>potato starch</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>milk</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe_id single_ingredient  compound\n",
       "0          1           cassava     False\n",
       "1          1              fish     False\n",
       "2          1           chicken     False\n",
       "3          1       coconut oil     False\n",
       "4          1     chicken broth     False\n",
       "5          1        lime juice     False\n",
       "6          1           spinach     False\n",
       "7          2              beef     False\n",
       "8          2     potato starch     False\n",
       "9          2              milk     False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add compound column to existing recipe_ingredient_df\n",
    "if 'recipe_ingredient_df' in locals() and 'PREDEFINED_COMPOUND_PATTERNS' in locals():\n",
    "    print(\"🔄 ADDING COMPOUND COLUMN TO EXISTING DATAFRAME\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Apply compound detection to each ingredient\n",
    "    recipe_ingredient_df['compound'] = recipe_ingredient_df['single_ingredient'].apply(\n",
    "        lambda ingredient: is_compound_ingredient_only(ingredient, PREDEFINED_COMPOUND_PATTERNS)\n",
    "    )\n",
    "\n",
    "display(recipe_ingredient_df[['recipe_id', 'single_ingredient', 'compound']].head(10)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "23dd7881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  🎯 Using predefined pattern: 'bumboo teri bubuk sesame seed' → ['anchovy powder', 'sesame seed']\n",
      "    'anchovy powder' → 'anchovy powder'\n",
      "    'sesame seed' → 'sesame seed'\n",
      "  🎯 Using predefined pattern: 'oil clove garlic beef sweet soy sauce salt sugar rice water tofu' → ['oil', 'clove garlic', 'beef', 'sweet soy sauce', 'salt', 'sugar', 'rice', 'water', 'tofu']\n",
      "    'oil' → 'oil'\n",
      "    'clove garlic' → 'garlic'\n",
      "    'beef' → 'beef'\n",
      "    'sweet soy sauce' → 'sweet soy sauce'\n",
      "    'salt' → 'salt'\n",
      "    'sugar' → 'sugar'\n",
      "    'rice' → 'rice'\n",
      "    'water' → 'water'\n",
      "    'tofu' → 'tofu'\n",
      "  🎯 Using predefined pattern: 'rice cooking oil clove garlic chicken broth salt shrimp carrot celery extra chicken broth' → ['rice', 'cooking oil', 'clove garlic', 'chicken broth', 'salt', 'shrimp', 'carrot', 'celery', 'extra chicken broth']\n",
      "    'rice' → 'rice'\n",
      "    'cooking oil' → 'cooking oil'\n",
      "    'clove garlic' → 'garlic'\n",
      "    'chicken broth' → 'chicken broth'\n",
      "    'salt' → 'salt'\n",
      "    'shrimp' → 'shrimp'\n",
      "    'carrot' → 'carrot'\n",
      "    'celery' → 'celery'\n",
      "    'extra chicken broth' → 'extra chicken broth'\n",
      "  🎯 Using predefined pattern: 'seed baby lemon juice water formula milk' → ['lemon juice', 'water', 'formula milk']\n",
      "    'lemon juice' → 'lemon juice'\n",
      "    'water' → 'water'\n",
      "    'formula milk' → 'formula milk'\n",
      "  🎯 Using predefined pattern: 'roll egg noodle boiling water' → ['noodle', 'water']\n",
      "    'noodle' → 'noodle'\n",
      "    'water' → 'water'\n",
      "  🎯 Using predefined pattern: 'chicken upper lower thigh wing' → ['chicken thigh', 'chicken wing']\n",
      "    'chicken thigh' → 'chicken thigh'\n",
      "    'chicken wing' → 'chicken wing'\n",
      "✅ Successfully embedded standardized_ingredient column!\n",
      "   Total rows processed: 8176\n",
      "   Compound ingredients: 6\n",
      "   Simple ingredients: 8170\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>recipe_name</th>\n",
       "      <th>single_ingredient</th>\n",
       "      <th>ingredient_position</th>\n",
       "      <th>original_ingredient_string</th>\n",
       "      <th>compound</th>\n",
       "      <th>standardized_ingredient</th>\n",
       "      <th>is_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>cassava</td>\n",
       "      <td>1</td>\n",
       "      <td>cassava,fish,chicken,coconut oil,chicken broth...</td>\n",
       "      <td>False</td>\n",
       "      <td>cassava</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>fish</td>\n",
       "      <td>2</td>\n",
       "      <td>cassava,fish,chicken,coconut oil,chicken broth...</td>\n",
       "      <td>False</td>\n",
       "      <td>fish</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>chicken</td>\n",
       "      <td>3</td>\n",
       "      <td>cassava,fish,chicken,coconut oil,chicken broth...</td>\n",
       "      <td>False</td>\n",
       "      <td>chicken</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>coconut oil</td>\n",
       "      <td>4</td>\n",
       "      <td>cassava,fish,chicken,coconut oil,chicken broth...</td>\n",
       "      <td>False</td>\n",
       "      <td>coconut oil</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>chicken broth</td>\n",
       "      <td>5</td>\n",
       "      <td>cassava,fish,chicken,coconut oil,chicken broth...</td>\n",
       "      <td>False</td>\n",
       "      <td>chicken broth</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8171</th>\n",
       "      <td>1322</td>\n",
       "      <td>Apple Crumble</td>\n",
       "      <td>flour</td>\n",
       "      <td>2</td>\n",
       "      <td>apples,flour,sugar,coconut,rolled oats,margarine</td>\n",
       "      <td>False</td>\n",
       "      <td>flour</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8172</th>\n",
       "      <td>1322</td>\n",
       "      <td>Apple Crumble</td>\n",
       "      <td>sugar</td>\n",
       "      <td>3</td>\n",
       "      <td>apples,flour,sugar,coconut,rolled oats,margarine</td>\n",
       "      <td>False</td>\n",
       "      <td>sugar</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8173</th>\n",
       "      <td>1322</td>\n",
       "      <td>Apple Crumble</td>\n",
       "      <td>coconut</td>\n",
       "      <td>4</td>\n",
       "      <td>apples,flour,sugar,coconut,rolled oats,margarine</td>\n",
       "      <td>False</td>\n",
       "      <td>coconut</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8174</th>\n",
       "      <td>1322</td>\n",
       "      <td>Apple Crumble</td>\n",
       "      <td>rolled oats</td>\n",
       "      <td>5</td>\n",
       "      <td>apples,flour,sugar,coconut,rolled oats,margarine</td>\n",
       "      <td>False</td>\n",
       "      <td>rolled oats</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8175</th>\n",
       "      <td>1322</td>\n",
       "      <td>Apple Crumble</td>\n",
       "      <td>margarine</td>\n",
       "      <td>6</td>\n",
       "      <td>apples,flour,sugar,coconut,rolled oats,margarine</td>\n",
       "      <td>False</td>\n",
       "      <td>margarine</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8176 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      recipe_id                                        recipe_name  \\\n",
       "0             1  Cassava Porridge with Fish Sauce and Lemon (Bu...   \n",
       "1             1  Cassava Porridge with Fish Sauce and Lemon (Bu...   \n",
       "2             1  Cassava Porridge with Fish Sauce and Lemon (Bu...   \n",
       "3             1  Cassava Porridge with Fish Sauce and Lemon (Bu...   \n",
       "4             1  Cassava Porridge with Fish Sauce and Lemon (Bu...   \n",
       "...         ...                                                ...   \n",
       "8171       1322                                      Apple Crumble   \n",
       "8172       1322                                      Apple Crumble   \n",
       "8173       1322                                      Apple Crumble   \n",
       "8174       1322                                      Apple Crumble   \n",
       "8175       1322                                      Apple Crumble   \n",
       "\n",
       "     single_ingredient  ingredient_position  \\\n",
       "0              cassava                    1   \n",
       "1                 fish                    2   \n",
       "2              chicken                    3   \n",
       "3          coconut oil                    4   \n",
       "4        chicken broth                    5   \n",
       "...                ...                  ...   \n",
       "8171             flour                    2   \n",
       "8172             sugar                    3   \n",
       "8173           coconut                    4   \n",
       "8174       rolled oats                    5   \n",
       "8175         margarine                    6   \n",
       "\n",
       "                             original_ingredient_string  compound  \\\n",
       "0     cassava,fish,chicken,coconut oil,chicken broth...     False   \n",
       "1     cassava,fish,chicken,coconut oil,chicken broth...     False   \n",
       "2     cassava,fish,chicken,coconut oil,chicken broth...     False   \n",
       "3     cassava,fish,chicken,coconut oil,chicken broth...     False   \n",
       "4     cassava,fish,chicken,coconut oil,chicken broth...     False   \n",
       "...                                                 ...       ...   \n",
       "8171   apples,flour,sugar,coconut,rolled oats,margarine     False   \n",
       "8172   apples,flour,sugar,coconut,rolled oats,margarine     False   \n",
       "8173   apples,flour,sugar,coconut,rolled oats,margarine     False   \n",
       "8174   apples,flour,sugar,coconut,rolled oats,margarine     False   \n",
       "8175   apples,flour,sugar,coconut,rolled oats,margarine     False   \n",
       "\n",
       "     standardized_ingredient  is_compound  \n",
       "0                    cassava        False  \n",
       "1                       fish        False  \n",
       "2                    chicken        False  \n",
       "3                coconut oil        False  \n",
       "4              chicken broth        False  \n",
       "...                      ...          ...  \n",
       "8171                   flour        False  \n",
       "8172                   sugar        False  \n",
       "8173                 coconut        False  \n",
       "8174             rolled oats        False  \n",
       "8175               margarine        False  \n",
       "\n",
       "[8176 rows x 8 columns]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standardized_ingredients_into_df(recipe_ingredient_df, predefined_patterns, mapping_dict):\n",
    "    \"\"\"\n",
    "    Alternative function that directly embeds standardized_ingredient column into the existing DataFrame\n",
    "    \n",
    "    Args:\n",
    "        recipe_ingredient_df: DataFrame with columns ['recipe_id', 'single_ingredient']\n",
    "        predefined_patterns: Dictionary of known compound patterns\n",
    "        mapping_dict: Dictionary for simple ingredient standardization\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Updated recipe_ingredient_df with standardized_ingredient column\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_standardized_ingredient(ingredient):\n",
    "        \"\"\"Helper function to get standardized ingredient for each row\"\"\"\n",
    "        if pd.isna(ingredient) or not ingredient:\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            # Check if compound\n",
    "            is_compound = is_compound_ingredient_only(ingredient, predefined_patterns)\n",
    "            \n",
    "            if is_compound:\n",
    "                # For compound ingredients, get the first part (or join all parts)\n",
    "                individual_parts = process_compound_ingredient_only(ingredient, predefined_patterns, mapping_dict)\n",
    "                if individual_parts:\n",
    "                    # Option 1: Return first part\n",
    "                    return individual_parts[0]\n",
    "                    # Option 2: Return all parts joined (uncomment below)\n",
    "                    # return ', '.join(individual_parts)\n",
    "                else:\n",
    "                    return str(ingredient).strip().lower()\n",
    "            else:\n",
    "                # For simple ingredients, apply direct mapping\n",
    "                return standardize_simple_ingredient_only(ingredient, mapping_dict)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing '{ingredient}': {e}\")\n",
    "            return str(ingredient).strip().lower()\n",
    "    \n",
    "    # Apply standardization to create new column\n",
    "    recipe_ingredient_df['standardized_ingredient'] = recipe_ingredient_df['single_ingredient'].apply(get_standardized_ingredient)\n",
    "    \n",
    "    # Add metadata columns\n",
    "    recipe_ingredient_df['is_compound'] = recipe_ingredient_df['single_ingredient'].apply(\n",
    "        lambda x: is_compound_ingredient_only(x, predefined_patterns) if pd.notna(x) else False\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Successfully embedded standardized_ingredient column!\")\n",
    "    print(f\"   Total rows processed: {len(recipe_ingredient_df)}\")\n",
    "    print(f\"   Compound ingredients: {recipe_ingredient_df['is_compound'].sum()}\")\n",
    "    print(f\"   Simple ingredients: {(~recipe_ingredient_df['is_compound']).sum()}\")\n",
    "    \n",
    "    return recipe_ingredient_df\n",
    "\n",
    "standardized_ingredients_into_df(recipe_ingredient_df, PREDEFINED_COMPOUND_PATTERNS, standardization_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce1f7af",
   "metadata": {},
   "source": [
    "Map Out Ingredient Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "0bcadf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_ingredient_name_symbols(ingredient_name):\n",
    "    \"\"\"\n",
    "    Clean unwanted symbols, quotes, and brackets from ingredient names\n",
    "    \n",
    "    Args:\n",
    "        ingredient_name: String containing the ingredient name\n",
    "        \n",
    "    Returns:\n",
    "        str: Cleaned ingredient name\n",
    "    \"\"\"\n",
    "    if pd.isna(ingredient_name) or ingredient_name == '':\n",
    "        return ingredient_name\n",
    "        \n",
    "    # Convert to string if not already\n",
    "    cleaned = str(ingredient_name)\n",
    "    \n",
    "    # Remove quotes (single and double)\n",
    "    cleaned = cleaned.replace(\"'\", \"\").replace('\"', \"\")\n",
    "    \n",
    "    # Remove brackets and parentheses\n",
    "    cleaned = cleaned.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    cleaned = cleaned.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    \n",
    "    # Remove other unwanted symbols but keep hyphens and spaces\n",
    "    cleaned = re.sub(r'[^\\w\\s\\-]', '', cleaned)\n",
    "    \n",
    "    # Clean up extra whitespace\n",
    "    cleaned = ' '.join(cleaned.split())\n",
    "    \n",
    "    # Remove leading/trailing whitespace\n",
    "    cleaned = cleaned.strip()\n",
    "    \n",
    "    return cleaned if cleaned else ingredient_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "b513ebf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 NA CHECK RESULTS:\n",
      "   Total rows: 8176\n",
      "   NA values in standardized_ingredient: 13\n",
      "   Percentage: 0.16%\n",
      "   NA rows with valid 'original_ingredient_string': 13\n",
      "\n",
      "📋 Sample NA rows with original data:\n",
      "     Row 2918: ''\n",
      "     Row 7783: ''\n",
      "     Row 7784: ''\n",
      "     Row 7785: ''\n",
      "     Row 7786: ''\n",
      "🔍 CHECKING FOR NA VALUES IN 'standardized_ingredient'\n",
      "============================================================\n",
      "📊 NA Analysis:\n",
      "   Total rows: 8176\n",
      "   NA values in 'standardized_ingredient': 13\n",
      "   Percentage NA: 0.16%\n",
      "\n",
      "🔍 Analyzing NA rows...\n",
      "   Using 'original_ingredient_string' as reference for original data\n",
      "\n",
      "📋 NA Row Analysis:\n",
      "   NA rows with valid original data: 0\n",
      "   NA rows without original data: 13\n",
      "\n",
      "🗑️  DROPPING: 13 rows with no original data\n",
      "   Sample rows being dropped:\n",
      "     Row 2918: Recipe 'Fish congee' - No original ingredient data\n",
      "     Row 7783: Recipe 'Fruity Winter Oats Recipe' - No original ingredient data\n",
      "     Row 7784: Recipe 'Italian Meatloaf with Salsa' - No original ingredient data\n",
      "     Row 7785: Recipe 'Mini Meatballs with Pasta' - No original ingredient data\n",
      "     Row 7786: Recipe 'Tuna Salad' - No original ingredient data\n",
      "\n",
      "✅ Dropped 13 rows with NA values\n",
      "   Remaining rows: 8163\n",
      "\n",
      "🔄 Creating ingredient master DataFrame from cleaned data...\n",
      "\n",
      "✅ Created ingredient master DataFrame:\n",
      "   Total unique ingredients: 990\n",
      "   Using column: standardized_ingredient\n",
      "   Cleaned unwanted symbols from ingredient names\n"
     ]
    }
   ],
   "source": [
    "def create_ingredient_master_df_with_na_check(recipe_ingredient_df, use_standardized=True):\n",
    "    \"\"\"\n",
    "    Create a master ingredient DataFrame with unique ingredient IDs and handle NA values\n",
    "    \n",
    "    Args:\n",
    "        recipe_ingredient_df: DataFrame with recipe-ingredient relationships\n",
    "        use_standardized: If True, use standardized_ingredient; if False, use single_ingredient\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (ingredient_df, ingredient_id_mapping, cleaned_df)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Choose which ingredient column to use\n",
    "    ingredient_column = 'standardized_ingredient' if use_standardized else 'single_ingredient'\n",
    "    \n",
    "    if ingredient_column not in recipe_ingredient_df.columns:\n",
    "        print(f\"❌ Column '{ingredient_column}' not found in recipe_ingredient_df\")\n",
    "        return None, None, None\n",
    "    \n",
    "    print(f\"🔍 CHECKING FOR NA VALUES IN '{ingredient_column}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check for NA values in standardized ingredient column\n",
    "    na_mask = recipe_ingredient_df[ingredient_column].isna()\n",
    "    na_count = na_mask.sum()\n",
    "    total_count = len(recipe_ingredient_df)\n",
    "    \n",
    "    print(f\"📊 NA Analysis:\")\n",
    "    print(f\"   Total rows: {total_count}\")\n",
    "    print(f\"   NA values in '{ingredient_column}': {na_count}\")\n",
    "    print(f\"   Percentage NA: {(na_count/total_count)*100:.2f}%\")\n",
    "    \n",
    "    if na_count > 0:\n",
    "        print(f\"\\n🔍 Analyzing NA rows...\")\n",
    "        na_rows = recipe_ingredient_df[na_mask].copy()\n",
    "        \n",
    "        # Check if there's an 'original_ingredient_string' column to reference\n",
    "        original_column = None\n",
    "        possible_original_columns = ['original_ingredient_string', 'single_ingredient', 'ingredient']\n",
    "        \n",
    "        for col in possible_original_columns:\n",
    "            if col in recipe_ingredient_df.columns and col != ingredient_column:\n",
    "                original_column = col\n",
    "                break\n",
    "        \n",
    "        if original_column:\n",
    "            print(f\"   Using '{original_column}' as reference for original data\")\n",
    "            \n",
    "            # Check which NA rows have valid original data\n",
    "            na_with_original = na_rows[na_rows[original_column].notna() & (na_rows[original_column] != '')]\n",
    "            na_without_original = na_rows[na_rows[original_column].isna() | (na_rows[original_column] == '')]\n",
    "            \n",
    "            print(f\"\\n📋 NA Row Analysis:\")\n",
    "            print(f\"   NA rows with valid original data: {len(na_with_original)}\")\n",
    "            print(f\"   NA rows without original data: {len(na_without_original)}\")\n",
    "            \n",
    "            # Show NA rows with valid original data (these need attention)\n",
    "            if len(na_with_original) > 0:\n",
    "                print(f\"\\n⚠️  HIGHLIGHT: NA rows with valid original data (need investigation):\")\n",
    "                display_cols = ['recipe_id', 'recipe_name', original_column, ingredient_column]\n",
    "                available_cols = [col for col in display_cols if col in na_with_original.columns]\n",
    "                \n",
    "                for idx, row in na_with_original.head(10).iterrows():\n",
    "                    print(f\"   Row {idx}:\")\n",
    "                    print(f\"     Recipe: {row.get('recipe_name', 'N/A')}\")\n",
    "                    print(f\"     Original: '{row.get(original_column, 'N/A')}'\")\n",
    "                    print(f\"     Standardized: {row.get(ingredient_column, 'N/A')}\")\n",
    "                    print()\n",
    "                \n",
    "                if len(na_with_original) > 10:\n",
    "                    print(f\"     ... and {len(na_with_original) - 10} more rows\")\n",
    "            \n",
    "            # Drop rows without original data\n",
    "            if len(na_without_original) > 0:\n",
    "                print(f\"\\n🗑️  DROPPING: {len(na_without_original)} rows with no original data\")\n",
    "                # Show sample of rows being dropped\n",
    "                print(\"   Sample rows being dropped:\")\n",
    "                for idx, row in na_without_original.head(5).iterrows():\n",
    "                    print(f\"     Row {idx}: Recipe '{row.get('recipe_name', 'N/A')}' - No original ingredient data\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"   ⚠️  No original ingredient column found for reference\")\n",
    "            print(f\"   Available columns: {list(recipe_ingredient_df.columns)}\")\n",
    "    \n",
    "    # Create cleaned DataFrame (drop rows with NA in standardized ingredient)\n",
    "    cleaned_df = recipe_ingredient_df.dropna(subset=[ingredient_column]).copy()\n",
    "    dropped_count = total_count - len(cleaned_df)\n",
    "    \n",
    "    if dropped_count > 0:\n",
    "        print(f\"\\n✅ Dropped {dropped_count} rows with NA values\")\n",
    "        print(f\"   Remaining rows: {len(cleaned_df)}\")\n",
    "    \n",
    "    # Continue with ingredient master creation using cleaned data\n",
    "    print(f\"\\n🔄 Creating ingredient master DataFrame from cleaned data...\")\n",
    "    \n",
    "    # Get unique ingredients and clean them\n",
    "    unique_ingredients = cleaned_df[ingredient_column].dropna().unique()\n",
    "    \n",
    "    # Clean all ingredient names to remove unwanted symbols\n",
    "    cleaned_ingredients = [clean_ingredient_name_symbols(ingredient) for ingredient in unique_ingredients]\n",
    "    \n",
    "    # Remove duplicates after cleaning and sort\n",
    "    unique_cleaned_ingredients = sorted(list(set(cleaned_ingredients)))\n",
    "    \n",
    "    # Create ingredient master DataFrame\n",
    "    ingredient_data = []\n",
    "    ingredient_id_mapping = {}\n",
    "    \n",
    "    for idx, ingredient in enumerate(unique_cleaned_ingredients, start=1):\n",
    "        if ingredient and ingredient.strip():  # Only add non-empty ingredients\n",
    "            ingredient_data.append({\n",
    "                'ingredient_id': idx,\n",
    "                'ingredient_name': ingredient\n",
    "            })\n",
    "            ingredient_id_mapping[ingredient] = idx\n",
    "    \n",
    "    ingredient_df = pd.DataFrame(ingredient_data)\n",
    "    \n",
    "    print(f\"\\n✅ Created ingredient master DataFrame:\")\n",
    "    print(f\"   Total unique ingredients: {len(ingredient_df)}\")\n",
    "    print(f\"   Using column: {ingredient_column}\")\n",
    "    print(f\"   Cleaned unwanted symbols from ingredient names\")\n",
    "    \n",
    "    return ingredient_df, ingredient_id_mapping, cleaned_df\n",
    "\n",
    "# Alternative: Simple function to just check NA values first\n",
    "def check_na_in_standardized_ingredients(recipe_ingredient_df):\n",
    "    \"\"\"\n",
    "    Quick function to check NA values in standardized ingredients\n",
    "    \"\"\"\n",
    "    ingredient_column = 'standardized_ingredient'\n",
    "    \n",
    "    if ingredient_column not in recipe_ingredient_df.columns:\n",
    "        print(f\"❌ Column '{ingredient_column}' not found\")\n",
    "        return\n",
    "    \n",
    "    # Check for NA values\n",
    "    na_mask = recipe_ingredient_df[ingredient_column].isna()\n",
    "    na_count = na_mask.sum()\n",
    "    \n",
    "    print(f\"🔍 NA CHECK RESULTS:\")\n",
    "    print(f\"   Total rows: {len(recipe_ingredient_df)}\")\n",
    "    print(f\"   NA values in standardized_ingredient: {na_count}\")\n",
    "    print(f\"   Percentage: {(na_count/len(recipe_ingredient_df))*100:.2f}%\")\n",
    "    \n",
    "    if na_count > 0:\n",
    "        na_rows = recipe_ingredient_df[na_mask]\n",
    "        \n",
    "        # Check original data\n",
    "        original_cols = ['original_ingredient_string', 'single_ingredient']\n",
    "        for col in original_cols:\n",
    "            if col in recipe_ingredient_df.columns:\n",
    "                has_original = na_rows[col].notna().sum()\n",
    "                print(f\"   NA rows with valid '{col}': {has_original}\")\n",
    "                \n",
    "                # Show sample\n",
    "                if has_original > 0:\n",
    "                    print(f\"\\n📋 Sample NA rows with original data:\")\n",
    "                    sample = na_rows[na_rows[col].notna()].head(5)\n",
    "                    for idx, row in sample.iterrows():\n",
    "                        print(f\"     Row {idx}: '{row[col]}'\")\n",
    "                break\n",
    "    else:\n",
    "        print(\"✅ No NA values found!\")\n",
    "\n",
    "# Usage examples:\n",
    "\n",
    "# Quick check first\n",
    "check_na_in_standardized_ingredients(recipe_ingredient_df)\n",
    "\n",
    "# Then use the enhanced function\n",
    "ingredient_df, ingredient_id_mapping, cleaned_recipe_df = create_ingredient_master_df_with_na_check(\n",
    "    recipe_ingredient_df, \n",
    "    use_standardized=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "9a208c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Sample of cleaned ingredient_df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredient_id</th>\n",
       "      <th>ingredient_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>acai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>agar-agar powder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>all purpose flour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>almond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>almond butter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>almond milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>almond nuts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>aluminum foil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>ambon banana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>ambrosia fruit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ingredient_id    ingredient_name\n",
       "0              1               acai\n",
       "1              2   agar-agar powder\n",
       "2              3  all purpose flour\n",
       "3              4             almond\n",
       "4              5      almond butter\n",
       "5              6        almond milk\n",
       "6              7        almond nuts\n",
       "7              8      aluminum foil\n",
       "8              9       ambon banana\n",
       "9             10     ambrosia fruit"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Checking for any remaining unwanted symbols...\n",
      "   Ingredients with quotes: 0\n",
      "   Ingredients with brackets: 0\n",
      "   ✅ All ingredient names are clean!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if ingredient_df is not None:\n",
    "    print(f\"\\n📋 Sample of cleaned ingredient_df:\")\n",
    "    display(ingredient_df.head(10))\n",
    "    \n",
    "    print(f\"\\n🔍 Checking for any remaining unwanted symbols...\")\n",
    "    # Check if any ingredient names still contain unwanted symbols\n",
    "    has_quotes = ingredient_df['ingredient_name'].str.contains(\"'|\\\"\", na=False).sum()\n",
    "    has_brackets = ingredient_df['ingredient_name'].str.contains(\"\\[|\\]|\\(|\\)\", na=False).sum()\n",
    "    \n",
    "    print(f\"   Ingredients with quotes: {has_quotes}\")\n",
    "    print(f\"   Ingredients with brackets: {has_brackets}\")\n",
    "    \n",
    "    if has_quotes > 0 or has_brackets > 0:\n",
    "        print(\"   ⚠️  Some unwanted symbols still found!\")\n",
    "        problematic = ingredient_df[\n",
    "            ingredient_df['ingredient_name'].str.contains(\"'|\\\"|\\[|\\]|\\(|\\)\", na=False)\n",
    "        ]\n",
    "        print(\"   Sample problematic ingredients:\")\n",
    "        display(problematic.head())\n",
    "    else:\n",
    "        print(\"   ✅ All ingredient names are clean!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf56e7c1",
   "metadata": {},
   "source": [
    "Map Out to the RecipeIngredient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "a9098ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ingredient_ids_to_recipe_df(recipe_ingredient_df, ingredient_id_mapping, use_standardized=True):\n",
    "    \"\"\"\n",
    "    Map ingredient IDs to the recipe ingredient DataFrame using cleaned ingredient names\n",
    "    \n",
    "    Args:\n",
    "        recipe_ingredient_df: DataFrame with recipe-ingredient relationships\n",
    "        ingredient_id_mapping: Dictionary mapping cleaned ingredient names to IDs\n",
    "        use_standardized: If True, use standardized_ingredient; if False, use single_ingredient\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Updated recipe_ingredient_df with ingredient_id column\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Choose which ingredient column to use\n",
    "    ingredient_column = 'standardized_ingredient' if use_standardized else 'single_ingredient'\n",
    "    \n",
    "    if ingredient_column not in recipe_ingredient_df.columns:\n",
    "        print(f\"❌ Column '{ingredient_column}' not found in recipe_ingredient_df\")\n",
    "        return recipe_ingredient_df\n",
    "    \n",
    "    # Create a copy to avoid modifying the original\n",
    "    final_recipe_ingredient = recipe_ingredient_df.copy()\n",
    "    \n",
    "    # Clean the ingredient names in the DataFrame and map to IDs\n",
    "    def get_ingredient_id(ingredient_name):\n",
    "        if pd.isna(ingredient_name):\n",
    "            return None\n",
    "        cleaned_name = clean_ingredient_name_symbols(ingredient_name)\n",
    "        return ingredient_id_mapping.get(cleaned_name, None)\n",
    "    \n",
    "    final_recipe_ingredient['ingredient_id'] = final_recipe_ingredient[ingredient_column].apply(get_ingredient_id)\n",
    "    \n",
    "    # Check mapping results\n",
    "    total_rows = len(final_recipe_ingredient)\n",
    "    mapped_rows = final_recipe_ingredient['ingredient_id'].notna().sum()\n",
    "    unmapped_rows = total_rows - mapped_rows\n",
    "    \n",
    "    print(f\"✅ Ingredient ID mapping complete:\")\n",
    "    print(f\"   Total rows: {total_rows}\")\n",
    "    print(f\"   Successfully mapped: {mapped_rows} ({(mapped_rows/total_rows)*100:.1f}%)\")\n",
    "    print(f\"   Unmapped: {unmapped_rows} ({(unmapped_rows/total_rows)*100:.1f}%)\")\n",
    "    \n",
    "    if unmapped_rows > 0:\n",
    "        print(f\"\\n🔍 Sample unmapped ingredients:\")\n",
    "        unmapped_sample = final_recipe_ingredient[final_recipe_ingredient['ingredient_id'].isna()][ingredient_column].dropna().unique()[:5]\n",
    "        for ingredient in unmapped_sample:\n",
    "            cleaned = clean_ingredient_name_symbols(ingredient)\n",
    "            print(f\"   Original: '{ingredient}' → Cleaned: '{cleaned}'\")\n",
    "    \n",
    "    return final_recipe_ingredient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "2ca1e868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recipe_id',\n",
       " 'recipe_name',\n",
       " 'single_ingredient',\n",
       " 'ingredient_position',\n",
       " 'original_ingredient_string',\n",
       " 'compound',\n",
       " 'standardized_ingredient',\n",
       " 'is_compound']"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_ingredient_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "ab71b94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ingredient ID mapping complete:\n",
      "   Total rows: 8176\n",
      "   Successfully mapped: 8163 (99.8%)\n",
      "   Unmapped: 13 (0.2%)\n",
      "\n",
      "🔍 Sample unmapped ingredients:\n",
      "\n",
      "📋 Sample of updated recipe_ingredient_df with IDs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>single_ingredient</th>\n",
       "      <th>standardized_ingredient</th>\n",
       "      <th>ingredient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>cassava</td>\n",
       "      <td>cassava</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fish</td>\n",
       "      <td>fish</td>\n",
       "      <td>326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>chicken</td>\n",
       "      <td>chicken</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>coconut oil</td>\n",
       "      <td>coconut oil</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>chicken broth</td>\n",
       "      <td>chicken broth</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>lime juice</td>\n",
       "      <td>lime juice</td>\n",
       "      <td>496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>spinach</td>\n",
       "      <td>spinach</td>\n",
       "      <td>813.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>beef</td>\n",
       "      <td>beef</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>potato starch</td>\n",
       "      <td>potato starch</td>\n",
       "      <td>668.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>milk</td>\n",
       "      <td>milk</td>\n",
       "      <td>537.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe_id single_ingredient standardized_ingredient  ingredient_id\n",
       "0          1           cassava                 cassava          154.0\n",
       "1          1              fish                    fish          326.0\n",
       "2          1           chicken                 chicken          181.0\n",
       "3          1       coconut oil             coconut oil          230.0\n",
       "4          1     chicken broth           chicken broth          184.0\n",
       "5          1        lime juice              lime juice          496.0\n",
       "6          1           spinach                 spinach          813.0\n",
       "7          2              beef                    beef           72.0\n",
       "8          2     potato starch           potato starch          668.0\n",
       "9          2              milk                    milk          537.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Final DataFrame Statistics:\n",
      "   Recipe DataFrame shape: (8176, 9)\n",
      "   Unique recipes: 1322\n",
      "   Unique ingredients: 990\n",
      "   Recipe-ingredient relationships: 8176\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Map ingredient IDs back to recipe DataFrame\n",
    "\n",
    "recipe_ingredient_df_with_ids = map_ingredient_ids_to_recipe_df(\n",
    "    recipe_ingredient_df,\n",
    "    ingredient_id_mapping,\n",
    "    use_standardized=True\n",
    ")\n",
    "\n",
    "print(f\"\\n📋 Sample of updated recipe_ingredient_df with IDs:\")\n",
    "sample_cols = ['recipe_id', 'single_ingredient', 'standardized_ingredient', 'ingredient_id']\n",
    "available_cols = [col for col in sample_cols if col in recipe_ingredient_df_with_ids.columns]\n",
    "display(recipe_ingredient_df_with_ids[available_cols].head(10))\n",
    "\n",
    "print(f\"\\n📊 Final DataFrame Statistics:\")\n",
    "print(f\"   Recipe DataFrame shape: {recipe_ingredient_df_with_ids.shape}\")\n",
    "print(f\"   Unique recipes: {recipe_ingredient_df_with_ids['recipe_id'].nunique()}\")\n",
    "print(f\"   Unique ingredients: {len(ingredient_df)}\")\n",
    "print(f\"   Recipe-ingredient relationships: {len(recipe_ingredient_df_with_ids)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "e8cd9701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑️ DROPPING UNMAPPED INGREDIENTS\n",
      "========================================\n",
      "Before dropping:\n",
      "   Total rows: 8176\n",
      "   Unmapped ingredients: 13\n",
      "\n",
      "📋 Sample of rows to be dropped:\n",
      "   Row 2918: Recipe 449 - 'None'\n",
      "   Row 7783: Recipe 1246 - 'None'\n",
      "   Row 7784: Recipe 1247 - 'None'\n",
      "   Row 7785: Recipe 1248 - 'None'\n",
      "   Row 7786: Recipe 1249 - 'None'\n",
      "\n",
      "✅ After dropping:\n",
      "   Total rows: 8163\n",
      "   Dropped rows: 13\n",
      "   Retention rate: 99.8%\n"
     ]
    }
   ],
   "source": [
    "def drop_unmapped_ingredients(recipe_ingredient_df_with_ids):\n",
    "    \"\"\"\n",
    "    Drop rows where ingredient_id is null (unmapped ingredients)\n",
    "    \n",
    "    Args:\n",
    "        recipe_ingredient_df_with_ids: DataFrame with ingredient_id column\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Cleaned DataFrame without unmapped ingredients\n",
    "    \"\"\"\n",
    "    print(\"🗑️ DROPPING UNMAPPED INGREDIENTS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Count before dropping\n",
    "    total_before = len(recipe_ingredient_df_with_ids)\n",
    "    unmapped_count = recipe_ingredient_df_with_ids['ingredient_id'].isna().sum()\n",
    "    \n",
    "    print(f\"Before dropping:\")\n",
    "    print(f\"   Total rows: {total_before}\")\n",
    "    print(f\"   Unmapped ingredients: {unmapped_count}\")\n",
    "    \n",
    "    if unmapped_count > 0:\n",
    "        # Show sample of what will be dropped\n",
    "        print(f\"\\n📋 Sample of rows to be dropped:\")\n",
    "        unmapped_sample = recipe_ingredient_df_with_ids[\n",
    "            recipe_ingredient_df_with_ids['ingredient_id'].isna()\n",
    "        ][['recipe_id', 'single_ingredient', 'standardized_ingredient']].head(5)\n",
    "        \n",
    "        for idx, row in unmapped_sample.iterrows():\n",
    "            print(f\"   Row {idx}: Recipe {row['recipe_id']} - '{row['single_ingredient']}'\")\n",
    "        \n",
    "        # Drop unmapped ingredients\n",
    "        cleaned_df = recipe_ingredient_df_with_ids.dropna(subset=['ingredient_id'])\n",
    "        \n",
    "        # Reset index\n",
    "        cleaned_df = cleaned_df.reset_index(drop=True)\n",
    "        \n",
    "        # Show results\n",
    "        total_after = len(cleaned_df)\n",
    "        dropped_count = total_before - total_after\n",
    "        \n",
    "        print(f\"\\n✅ After dropping:\")\n",
    "        print(f\"   Total rows: {total_after}\")\n",
    "        print(f\"   Dropped rows: {dropped_count}\")\n",
    "        print(f\"   Retention rate: {(total_after/total_before)*100:.1f}%\")\n",
    "        \n",
    "        return cleaned_df\n",
    "    \n",
    "    else:\n",
    "        print(\"✅ No unmapped ingredients found - nothing to drop!\")\n",
    "        return recipe_ingredient_df_with_ids\n",
    "\n",
    "# Usage\n",
    "cleaned_recipe_ingredient_df = drop_unmapped_ingredients(recipe_ingredient_df_with_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "e0433638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Final Recipe-Ingredient DataFrame:\n",
      "   Shape: (8117, 2)\n",
      "   Unique recipe IDs: 1309\n",
      "   Unique ingredient IDs: 990\n"
     ]
    }
   ],
   "source": [
    "recipe_ingredient = cleaned_recipe_ingredient_df.copy()\n",
    "\n",
    "#take recipe_id and ingredient_id only\n",
    "recipe_ingredient = recipe_ingredient[['recipe_id', 'ingredient_id']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n📋 Final Recipe-Ingredient DataFrame:\")\n",
    "print(f\"   Shape: {recipe_ingredient.shape}\")\n",
    "print(f\"   Unique recipe IDs: {recipe_ingredient['recipe_id'].nunique()}\")\n",
    "print(f\"   Unique ingredient IDs: {recipe_ingredient['ingredient_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b93f38",
   "metadata": {},
   "source": [
    "##### Determine Allergen (ingredient and recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "e39b454a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countrymap columns: ['pk', 'name', 'description']\n",
      "Countrymap shape: (8, 3)\n",
      "\n",
      "First 5 rows of allergen:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dairy</td>\n",
       "      <td>Common infant allergen. Found in dairy products.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>egg</td>\n",
       "      <td>Can cause allergy even in small amounts.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>soy</td>\n",
       "      <td>Plant-based but common allergen, especially in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>tree_nuts</td>\n",
       "      <td>Tree nuts are a top allergen. Avoid early intr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>peanuts</td>\n",
       "      <td>Peanuts are a major allergen. Introduce carefu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pk       name                                        description\n",
       "0   1      dairy   Common infant allergen. Found in dairy products.\n",
       "1   2        egg           Can cause allergy even in small amounts.\n",
       "2   3        soy  Plant-based but common allergen, especially in...\n",
       "3   4  tree_nuts  Tree nuts are a top allergen. Avoid early intr...\n",
       "4   5    peanuts  Peanuts are a major allergen. Introduce carefu..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "allergen_map = pd.read_excel('1st_dataset.xlsx', sheet_name='allergen')\n",
    "print(\"Countrymap columns:\", allergen_map.columns.tolist())\n",
    "print(\"Countrymap shape:\", allergen_map.shape)\n",
    "print(\"\\nFirst 5 rows of allergen:\")\n",
    "display(allergen_map.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "6d94c436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'egg': {'allergen_group': 'egg',\n",
      "         'keywords': ['egg',\n",
      "                      'eggs',\n",
      "                      'egg white',\n",
      "                      'egg yolk',\n",
      "                      'omelette',\n",
      "                      'lecithin',\n",
      "                      'chicken egg',\n",
      "                      'duck egg',\n",
      "                      'quail egg'],\n",
      "         'notes': 'Can cause allergy even in small amounts.'},\n",
      " 'fish': {'allergen_group': 'fish',\n",
      "          'keywords': ['salmon',\n",
      "                       'cod',\n",
      "                       'tuna',\n",
      "                       'white fish',\n",
      "                       'trout',\n",
      "                       'sardines',\n",
      "                       'catfish',\n",
      "                       'tilapia',\n",
      "                       'codfish',\n",
      "                       'sardine',\n",
      "                       'anchovy',\n",
      "                       'dorado fish',\n",
      "                       'mackerel',\n",
      "                       'tenggiri fish',\n",
      "                       'snapper',\n",
      "                       'basa fish',\n",
      "                       'pollock',\n",
      "                       'sole',\n",
      "                       'flounder'],\n",
      "          'notes': 'Introduce after 6 months and watch for reactions.'},\n",
      " 'gluten': {'allergen_group': 'gluten',\n",
      "            'keywords': ['wheat',\n",
      "                         'barley',\n",
      "                         'rye',\n",
      "                         'bread',\n",
      "                         'pasta',\n",
      "                         'semolina',\n",
      "                         'flour',\n",
      "                         'beer',\n",
      "                         'panko',\n",
      "                         'cereals',\n",
      "                         'self-raising flour',\n",
      "                         'bread flour',\n",
      "                         'wheat bisk',\n",
      "                         'wholemeal bread',\n",
      "                         'wholemeal flour',\n",
      "                         'spelt flour',\n",
      "                         'barley flour',\n",
      "                         'rye',\n",
      "                         'rye bread',\n",
      "                         'couscous',\n",
      "                         'farina',\n",
      "                         'bulgur'],\n",
      "            'notes': 'Gluten comes from wheat/barley/rye. Celiac risk.'},\n",
      " 'milk': {'allergen_group': 'dairy',\n",
      "          'keywords': ['milk',\n",
      "                       'cheese',\n",
      "                       'butter',\n",
      "                       'yogurt',\n",
      "                       'whey',\n",
      "                       'casein',\n",
      "                       'cream',\n",
      "                       'ice cream',\n",
      "                       'paneer',\n",
      "                       'ghee',\n",
      "                       'milk formula',\n",
      "                       'powdered milk',\n",
      "                       'condensed milk',\n",
      "                       'evaporated milk',\n",
      "                       'plain milk',\n",
      "                       'whole milk',\n",
      "                       'skim milk',\n",
      "                       'formula milk',\n",
      "                       'formula milk powder',\n",
      "                       'rice milk',\n",
      "                       'soy milk',\n",
      "                       'almond milk',\n",
      "                       'coconut milk',\n",
      "                       'goat milk'],\n",
      "          'notes': 'Common infant allergen. Found in dairy products.'},\n",
      " 'nuts': {'allergen_group': 'tree_nuts',\n",
      "          'keywords': ['almonds',\n",
      "                       'cashews',\n",
      "                       'walnuts',\n",
      "                       'hazelnuts',\n",
      "                       'pecans',\n",
      "                       'macadamia',\n",
      "                       'pistachio',\n",
      "                       'pine nuts',\n",
      "                       'brazil nuts',\n",
      "                       'nutmeg',\n",
      "                       'nut paste',\n",
      "                       'nut butter',\n",
      "                       'hazelnut',\n",
      "                       'hazelnut flour',\n",
      "                       'cashew',\n",
      "                       'cashew butter',\n",
      "                       'almond butter',\n",
      "                       'almond milk',\n",
      "                       'almond flour',\n",
      "                       'nut',\n",
      "                       'nut extract'],\n",
      "          'notes': 'Tree nuts are a top allergen. Avoid early introduction '\n",
      "                   'unless guided.'},\n",
      " 'peanuts': {'allergen_group': 'peanuts',\n",
      "             'keywords': ['peanuts',\n",
      "                          'peanut butter',\n",
      "                          'ground nuts',\n",
      "                          'nut paste',\n",
      "                          'peanut',\n",
      "                          'peanut flour',\n",
      "                          'ground peanut',\n",
      "                          'peanut oil'],\n",
      "             'notes': 'Peanuts are a major allergen. Introduce carefully.'},\n",
      " 'shellfish': {'allergen_group': 'shellfish',\n",
      "               'keywords': ['shrimp',\n",
      "                            'crab',\n",
      "                            'lobster',\n",
      "                            'prawn',\n",
      "                            'scallops',\n",
      "                            'clams',\n",
      "                            'scallop',\n",
      "                            'crayfish',\n",
      "                            'squid',\n",
      "                            'octopus',\n",
      "                            'mussel',\n",
      "                            'oyster',\n",
      "                            'clam'],\n",
      "               'notes': 'Highly allergenic. Not recommended before 1 year.'},\n",
      " 'soy': {'allergen_group': 'soy',\n",
      "         'keywords': ['soy',\n",
      "                      'tofu',\n",
      "                      'edamame',\n",
      "                      'soy sauce',\n",
      "                      'soy milk',\n",
      "                      'tempeh',\n",
      "                      'miso',\n",
      "                      'soybean',\n",
      "                      'soybean flour',\n",
      "                      'soybean oil',\n",
      "                      'soya flour',\n",
      "                      'soya powder'],\n",
      "         'notes': 'Plant-based but common allergen, especially in infants.'}}\n"
     ]
    }
   ],
   "source": [
    "# Load the module\n",
    "import importlib\n",
    "\n",
    "allergen_path = os.path.join(os.getcwd(), \"preprocessing_techniques\", \"mappers\", \"allergen_mapper.py\")\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"allergen\", allergen_path)\n",
    "allergen_file = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(allergen_file)\n",
    "\n",
    "# Access the config\n",
    "allergen_tags = allergen_file.ALLERGEN_TAGS\n",
    "pprint(allergen_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "f937394a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredient_id</th>\n",
       "      <th>ingredient_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>acai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>agar-agar powder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>all purpose flour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>almond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>almond butter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>986</td>\n",
       "      <td>young beans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>987</td>\n",
       "      <td>young coconut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>988</td>\n",
       "      <td>young corn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>989</td>\n",
       "      <td>zucchini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>990</td>\n",
       "      <td>zucchinis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ingredient_id    ingredient_name\n",
       "0                1               acai\n",
       "1                2   agar-agar powder\n",
       "2                3  all purpose flour\n",
       "3                4             almond\n",
       "4                5      almond butter\n",
       "..             ...                ...\n",
       "985            986        young beans\n",
       "986            987      young coconut\n",
       "987            988         young corn\n",
       "988            989           zucchini\n",
       "989            990          zucchinis\n",
       "\n",
       "[990 rows x 2 columns]"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredient_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "30d5babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_match_confidence(ingredient_name, keyword):\n",
    "    \"\"\"Calculate confidence score for partial matches.\"\"\"\n",
    "    confidence = 0.6\n",
    "    if len(keyword) >= len(ingredient_name) * 0.5:\n",
    "        confidence += 0.2\n",
    "    if ingredient_name.startswith(keyword) or ingredient_name.endswith(keyword):\n",
    "        confidence += 0.2\n",
    "    if re.search(r'\\b' + re.escape(keyword) + r'\\b', ingredient_name):\n",
    "        confidence += 0.1\n",
    "    if len(keyword) <= 3 and len(ingredient_name) >= 10:\n",
    "        confidence -= 0.2\n",
    "    return min(0.95, max(0.0, confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "fe26e17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_allergen(ingredient_name, ALLERGEN_TAGS):\n",
    "    \"\"\"\n",
    "    Detect allergen in an ingredient name using a two-step strategy:\n",
    "    1. Check for exclusion terms\n",
    "    2. Exact then partial keyword matching\n",
    "    \n",
    "    Returns:\n",
    "        dict: {\n",
    "            'allergen_group': str or None,\n",
    "            'match_type': 'exact'/'partial' or None,\n",
    "            'matched_keyword': str or None,\n",
    "            'confidence': float\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Normalize input\n",
    "    ingredient_lower = ingredient_name.lower().strip()\n",
    "\n",
    "    # Exclusion Terms\n",
    "    exclusion_terms = [\"breast milk\", \"breastmilk\", \"formula milk\", \"formula\", \"breast\"]\n",
    "    if any(term in ingredient_lower for term in exclusion_terms):\n",
    "        return {\n",
    "            'allergen_group': None,\n",
    "            'match_type': None,\n",
    "            'matched_keyword': None,\n",
    "            'confidence': 0.0\n",
    "        }\n",
    "\n",
    "    # Step 1: Exact match\n",
    "    for allergen_name, data in ALLERGEN_TAGS.items():\n",
    "        keywords = data.get(\"keywords\", [])\n",
    "        allergen_group = data.get(\"allergen_group\", allergen_name)\n",
    "        for keyword in keywords:\n",
    "            if keyword.lower().strip() == ingredient_lower:\n",
    "                return {\n",
    "                    'allergen_group': allergen_group,\n",
    "                    'match_type': 'exact',\n",
    "                    'matched_keyword': keyword,\n",
    "                    'confidence': 1.0\n",
    "                }\n",
    "\n",
    "    # Step 2: Partial match\n",
    "    best_match = None\n",
    "    for allergen_name, data in ALLERGEN_TAGS.items():\n",
    "        keywords = data.get(\"keywords\", [])\n",
    "        allergen_group = data.get(\"allergen_group\", allergen_name)\n",
    "        for keyword in keywords:\n",
    "            keyword_lower = keyword.lower().strip()\n",
    "            if keyword_lower in ingredient_lower:\n",
    "                confidence = calculate_match_confidence(ingredient_lower, keyword_lower)\n",
    "                if not best_match or confidence > best_match['confidence']:\n",
    "                    best_match = {\n",
    "                        'allergen_group': allergen_group,\n",
    "                        'match_type': 'partial',\n",
    "                        'matched_keyword': keyword,\n",
    "                        'confidence': confidence\n",
    "                    }\n",
    "\n",
    "    if best_match and best_match['confidence'] >= 0.5:\n",
    "        return best_match\n",
    "\n",
    "    return {\n",
    "        'allergen_group': None,\n",
    "        'match_type': None,\n",
    "        'matched_keyword': None,\n",
    "        'confidence': 0.0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "319ce21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_allergen_group_id(allergen_group, allergen_mapping):\n",
    "    \"\"\"Map allergen group name to ID.\"\"\"\n",
    "    return allergen_mapping.get(allergen_group, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "ad245e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ingredients_with_allergens(df, allergen_df):\n",
    "\n",
    "    allergen_mapping = dict(zip(allergen_df['name'], allergen_df['pk']))\n",
    "\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        result = detect_allergen(row['ingredient_name'],allergen_tags)\n",
    "        result['ingredient_id'] = row['ingredient_id']\n",
    "        result['ingredient_name'] = row['ingredient_name']\n",
    "        result['allergen_group_id'] = get_allergen_group_id(result['allergen_group'], allergen_mapping)\n",
    "        result['isAllergen'] = result['allergen_group_id'] is not None\n",
    "        results.append(result)\n",
    "\n",
    "    result_df = pd.DataFrame(results)\n",
    "    return result_df[result_df.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "8b821088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allergen_group match_type matched_keyword  confidence  ingredient_id ingredient_name  allergen_group_id  isAllergen\n",
      "         dairy      exact      whole milk         1.0              1      Whole Milk                1.0        True\n",
      "          None       None            None         0.0              2     Breast Milk                NaN       False\n",
      "     tree_nuts      exact   almond butter         1.0              3   Almond Butter                4.0        True\n",
      "          None       None            None         0.0              4  Chicken Breast                NaN       False\n",
      "          fish    partial          salmon         0.9              5   Salmon Fillet                6.0        True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allergen_group</th>\n",
       "      <th>match_type</th>\n",
       "      <th>matched_keyword</th>\n",
       "      <th>confidence</th>\n",
       "      <th>ingredient_id</th>\n",
       "      <th>ingredient_name</th>\n",
       "      <th>allergen_group_id</th>\n",
       "      <th>isAllergen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dairy</td>\n",
       "      <td>exact</td>\n",
       "      <td>whole milk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Whole Milk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Breast Milk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tree_nuts</td>\n",
       "      <td>exact</td>\n",
       "      <td>almond butter</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Almond Butter</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Chicken Breast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fish</td>\n",
       "      <td>partial</td>\n",
       "      <td>salmon</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5</td>\n",
       "      <td>Salmon Fillet</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  allergen_group match_type matched_keyword  confidence  ingredient_id  \\\n",
       "0          dairy      exact      whole milk         1.0              1   \n",
       "1           None       None            None         0.0              2   \n",
       "2      tree_nuts      exact   almond butter         1.0              3   \n",
       "3           None       None            None         0.0              4   \n",
       "4           fish    partial          salmon         0.9              5   \n",
       "\n",
       "  ingredient_name  allergen_group_id  isAllergen  \n",
       "0      Whole Milk                1.0        True  \n",
       "1     Breast Milk                NaN       False  \n",
       "2   Almond Butter                4.0        True  \n",
       "3  Chicken Breast                NaN       False  \n",
       "4   Salmon Fillet                6.0        True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = [\n",
    "    {\"ingredient_id\": 1, \"ingredient_name\": \"Whole Milk\"},\n",
    "    {\"ingredient_id\": 2, \"ingredient_name\": \"Breast Milk\"},\n",
    "    {\"ingredient_id\": 3, \"ingredient_name\": \"Almond Butter\"},\n",
    "    {\"ingredient_id\": 4, \"ingredient_name\": \"Chicken Breast\"},\n",
    "    {\"ingredient_id\": 5, \"ingredient_name\": \"Salmon Fillet\"}\n",
    "]\n",
    "testing = pd.DataFrame(test_data)\n",
    "\n",
    "allergen_df = pd.DataFrame(allergen_tags)\n",
    "\n",
    "final_df = process_ingredients_with_allergens(testing, allergen_map)\n",
    "print(final_df.to_string(index=False))\n",
    "display(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "01403173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allergen_group</th>\n",
       "      <th>match_type</th>\n",
       "      <th>matched_keyword</th>\n",
       "      <th>confidence</th>\n",
       "      <th>ingredient_id</th>\n",
       "      <th>ingredient_name</th>\n",
       "      <th>allergen_group_id</th>\n",
       "      <th>isAllergen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dairy</td>\n",
       "      <td>exact</td>\n",
       "      <td>whole milk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Whole Milk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Breast Milk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tree_nuts</td>\n",
       "      <td>exact</td>\n",
       "      <td>almond butter</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Almond Butter</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Chicken Breast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fish</td>\n",
       "      <td>partial</td>\n",
       "      <td>salmon</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5</td>\n",
       "      <td>Salmon Fillet</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  allergen_group match_type matched_keyword  confidence  ingredient_id  \\\n",
       "0          dairy      exact      whole milk         1.0              1   \n",
       "1           None       None            None         0.0              2   \n",
       "2      tree_nuts      exact   almond butter         1.0              3   \n",
       "3           None       None            None         0.0              4   \n",
       "4           fish    partial          salmon         0.9              5   \n",
       "\n",
       "  ingredient_name  allergen_group_id  isAllergen  \n",
       "0      Whole Milk                1.0        True  \n",
       "1     Breast Milk                NaN       False  \n",
       "2   Almond Butter                4.0        True  \n",
       "3  Chicken Breast                NaN       False  \n",
       "4   Salmon Fillet                6.0        True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ingredient_df =process_ingredients_with_allergens(testing, allergen_map)\n",
    "\n",
    "display(ingredient_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "f53e59ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk</th>\n",
       "      <th>name</th>\n",
       "      <th>allergen_group_id</th>\n",
       "      <th>isAllergen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Whole Milk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Breast Milk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Almond Butter</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chicken Breast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Salmon Fillet</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pk            name  allergen_group_id  isAllergen\n",
       "0   1      Whole Milk                1.0        True\n",
       "1   2     Breast Milk                NaN       False\n",
       "2   3   Almond Butter                4.0        True\n",
       "3   4  Chicken Breast                NaN       False\n",
       "4   5   Salmon Fillet                6.0        True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_ingredient_df = ingredient_df.copy()\n",
    "final_ingredient_df = final_ingredient_df.rename(columns={\n",
    "    'ingredient_id': 'pk',\n",
    "    'ingredient_name': 'name',\n",
    "    'allergen_group_id': 'allergen_group_id',\n",
    "    'isAllergen': 'isAllergen'})\n",
    "\n",
    "#final_ingredient_df drop column other than pk, name, allergen_group_id, isAllergen\n",
    "final_ingredient_df = final_ingredient_df[['pk', 'name', 'allergen_group_id', 'isAllergen']]\n",
    "display(final_ingredient_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708ca92c",
   "metadata": {},
   "source": [
    "recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "3671f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_allergens(recipe_data, ALLERGEN_TAGS):\n",
    "    ner_ingredients = recipe_data.get(\"ner_ingredient_string\", [])\n",
    "    # Normalize ingredients (make sure they're lowercase and clean)\n",
    "    cleaned_ingredients = [str(i).strip().lower() for i in ner_ingredients if i]\n",
    "\n",
    "    # Combine into one searchable string\n",
    "    combined_text = ' '.join(cleaned_ingredients)\n",
    "    matched_allergens = []\n",
    "\n",
    "    # Define exclusion terms for breast milk and formula\n",
    "    exclusion_terms = [\"breast milk\", \"breastmilk\", \"formula milk\", \"formula\", \"breast\"]\n",
    "    # First check if the combined text contains any exclusion terms\n",
    "    has_exclusion_terms = any(exclusion in combined_text for exclusion in exclusion_terms)\n",
    "    for allergen, data in ALLERGEN_TAGS.items():\n",
    "        keywords = [kw.lower() for kw in data[\"keywords\"]]\n",
    "        \n",
    "        # For milk allergen specifically, skip entirely if exclusion terms found\n",
    "        if allergen == \"milk\" and has_exclusion_terms:\n",
    "            continue\n",
    "            \n",
    "        for keyword in keywords:\n",
    "            if keyword in combined_text:\n",
    "                # Check if this keyword match is actually part of an exclusion term\n",
    "                is_excluded = False\n",
    "                \n",
    "                # For example, if \"milk\" is found but it's part of \"breast milk\"\n",
    "                for exclusion in exclusion_terms:\n",
    "                    # Check all possible positions where keyword could be within exclusion term\n",
    "                    if (exclusion.startswith(keyword + \" \") or \n",
    "                        exclusion.endswith(\" \" + keyword) or \n",
    "                        \" \" + keyword + \" \" in exclusion or \n",
    "                        exclusion == keyword):\n",
    "                        \n",
    "                        # Only exclude if this exact exclusion term is in the text\n",
    "                        if exclusion in combined_text:\n",
    "                            is_excluded = True\n",
    "                            break\n",
    "                \n",
    "                if not is_excluded:\n",
    "                    matched_allergens.append(allergen)\n",
    "                    break  # No need to check other keywords for this allergen\n",
    "\n",
    "    return list(set(matched_allergens))  # Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "3d70deb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>allergen</th>\n",
       "      <th>hypoallergenic</th>\n",
       "      <th>choking_hazards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cassava Porridge with Fish Sauce and Lemon (Bu...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitterballs (Bitterballen)</td>\n",
       "      <td>[]</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Broccoli/Cauliflower Cheese</td>\n",
       "      <td>[]</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vegetable Fingers</td>\n",
       "      <td>[]</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beef Casserole</td>\n",
       "      <td>[]</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Toast Fingers</td>\n",
       "      <td>[]</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pumpkin Polenta Fingers</td>\n",
       "      <td>[]</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rice Pudding</td>\n",
       "      <td>[]</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hummus</td>\n",
       "      <td>[]</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baked Bean Pie</td>\n",
       "      <td>[]</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name allergen hypoallergenic  \\\n",
       "0  Cassava Porridge with Fish Sauce and Lemon (Bu...       []            Yes   \n",
       "1                         Bitterballs (Bitterballen)       []            Yes   \n",
       "2                        Broccoli/Cauliflower Cheese       []            Yes   \n",
       "3                                  Vegetable Fingers       []            Yes   \n",
       "4                                     Beef Casserole       []            Yes   \n",
       "5                                      Toast Fingers       []            Yes   \n",
       "6                            Pumpkin Polenta Fingers       []            Yes   \n",
       "7                                       Rice Pudding       []            Yes   \n",
       "8                                             Hummus       []            Yes   \n",
       "9                                     Baked Bean Pie       []            Yes   \n",
       "\n",
       "  choking_hazards  \n",
       "0              No  \n",
       "1              No  \n",
       "2              No  \n",
       "3              No  \n",
       "4              No  \n",
       "5              No  \n",
       "6              No  \n",
       "7              No  \n",
       "8              No  \n",
       "9              No  "
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['allergen'] = df.apply(\n",
    "    lambda row: detect_allergens(row, allergen_tags),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Update hypoallergenic column based on allergen data\n",
    "df['hypoallergenic'] = df['allergen'].apply(\n",
    "    lambda allergens: \"Yes\" if not allergens or len(allergens) == 0 else \"No\"\n",
    ")\n",
    "\n",
    "# Display results to verify\n",
    "df[['name', 'allergen', 'hypoallergenic', 'choking_hazards']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0dbcce",
   "metadata": {},
   "source": [
    "##### Classify Category of The Recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "f4cc1172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dairy_free': {'excluded_allergen_groups': ['milk'],\n",
      "                'excluded_ingredients': ['cheese',\n",
      "                                         'butter',\n",
      "                                         'yogurt',\n",
      "                                         'milk',\n",
      "                                         'whey',\n",
      "                                         'casein',\n",
      "                                         'cream',\n",
      "                                         'ice cream']},\n",
      " 'egg_free': {'excluded_allergen_groups': ['egg'],\n",
      "              'excluded_ingredients': ['eggs',\n",
      "                                       'egg white',\n",
      "                                       'egg yolk',\n",
      "                                       'lecithin',\n",
      "                                       'omelette']},\n",
      " 'gluten_free': {'excluded_allergen_groups': ['gluten'],\n",
      "                 'excluded_ingredients': ['wheat',\n",
      "                                          'barley',\n",
      "                                          'rye',\n",
      "                                          'bread',\n",
      "                                          'pasta',\n",
      "                                          'semolina',\n",
      "                                          'crackers',\n",
      "                                          'cookies',\n",
      "                                          'cereals',\n",
      "                                          'panko',\n",
      "                                          'flour (wheat)',\n",
      "                                          'beer']},\n",
      " 'halal': {'excluded_allergen_groups': ['pork'],\n",
      "           'excluded_ingredients': ['pork',\n",
      "                                    'bacon',\n",
      "                                    'ham',\n",
      "                                    'gelatin',\n",
      "                                    'alcohol',\n",
      "                                    'non_halal_meat'],\n",
      "           'notes': 'Follows halal food laws — no pork, alcohol, or non-halal '\n",
      "                    'meat'},\n",
      " 'non_halal': {'notes': 'Contains ingredients not allowed in halal diet',\n",
      "               'required_ingredients': ['pork',\n",
      "                                        'bacon',\n",
      "                                        'ham',\n",
      "                                        'gelatin',\n",
      "                                        'alcohol',\n",
      "                                        'non_halal_meat']},\n",
      " 'non_veg': {'notes': 'Default tag for any recipe containing meat or fish (no '\n",
      "                      'exclusions)'},\n",
      " 'nut_free': {'excluded_allergen_groups': ['nuts'],\n",
      "              'excluded_ingredients': ['almonds',\n",
      "                                       'cashews',\n",
      "                                       'walnuts',\n",
      "                                       'peanuts',\n",
      "                                       'hazelnuts',\n",
      "                                       'pecans',\n",
      "                                       'nut butter',\n",
      "                                       'nut milk',\n",
      "                                       'trail mix']},\n",
      " 'pescetarian': {'allowed_categories': ['plant_based',\n",
      "                                        'dairy',\n",
      "                                        'egg',\n",
      "                                        'seafood'],\n",
      "                 'excluded_allergen_groups': [],\n",
      "                 'excluded_ingredients': ['meat',\n",
      "                                          'bacon',\n",
      "                                          'gelatin',\n",
      "                                          'pork',\n",
      "                                          'lamb',\n",
      "                                          'chicken',\n",
      "                                          'beef'],\n",
      "                 'notes': 'Contains fish but no other meats.'},\n",
      " 'soy_free': {'excluded_allergen_groups': ['soy'],\n",
      "              'excluded_ingredients': ['soy',\n",
      "                                       'tofu',\n",
      "                                       'edamame',\n",
      "                                       'soy sauce',\n",
      "                                       'soy milk',\n",
      "                                       'tempeh',\n",
      "                                       'miso']},\n",
      " 'vegan': {'allowed_categories': ['plant_based'],\n",
      "           'excluded_allergen_groups': ['milk', 'egg', 'fish', 'shellfish'],\n",
      "           'excluded_ingredients': ['meat',\n",
      "                                    'chicken',\n",
      "                                    'beef',\n",
      "                                    'pork',\n",
      "                                    'lamb',\n",
      "                                    'bacon',\n",
      "                                    'gelatin',\n",
      "                                    'eggs',\n",
      "                                    'cheese',\n",
      "                                    'butter',\n",
      "                                    'yogurt',\n",
      "                                    'whey',\n",
      "                                    'casein',\n",
      "                                    'lard',\n",
      "                                    'milk',\n",
      "                                    'honey'],\n",
      "           'notes': 'No animal products. Safe only if choking hazard-free.'},\n",
      " 'vegetarian': {'allowed_categories': ['plant_based', 'dairy', 'egg'],\n",
      "                'excluded_allergen_groups': ['fish', 'shellfish'],\n",
      "                'excluded_ingredients': ['meat',\n",
      "                                         'chicken',\n",
      "                                         'beef',\n",
      "                                         'pork',\n",
      "                                         'lamb',\n",
      "                                         'gelatin',\n",
      "                                         'pork',\n",
      "                                         'bacon',\n",
      "                                         'ham',\n",
      "                                         'cod',\n",
      "                                         'salmon',\n",
      "                                         'tuna',\n",
      "                                         'shellfish',\n",
      "                                         'shrimp',\n",
      "                                         'lobster',\n",
      "                                         'crab',\n",
      "                                         'prawn'],\n",
      "                'notes': 'May contain dairy or eggs, but no meat.'}}\n"
     ]
    }
   ],
   "source": [
    "# Load the module\n",
    "import importlib\n",
    "\n",
    "category_path = os.path.join(os.getcwd(), \"preprocessing_techniques\", \"mappers\", \"category_dict.py\")\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"category\", category_path)\n",
    "category_file = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(category_file)\n",
    "\n",
    "# Access the config\n",
    "dietary_tags  = category_file.dietary_tags\n",
    "pprint(dietary_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "f73ac314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category columns: ['pk', 'name', 'description']\n",
      "Category shape: (11, 3)\n",
      "\n",
      "First 5 rows of Category:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>vegan</td>\n",
       "      <td>Allowed categories: plant_based\\nExcluded alle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>Allowed categories: plant_based, dairy, egg\\nE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pescetarian</td>\n",
       "      <td>Allowed categories: plant_based, dairy, egg, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>dairy free</td>\n",
       "      <td>Excluded allergen groups: milk\\nExcluded ingre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>egg free</td>\n",
       "      <td>Excluded allergen groups: egg\\nExcluded ingred...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pk         name                                        description\n",
       "0   1        vegan  Allowed categories: plant_based\\nExcluded alle...\n",
       "1   2   vegetarian  Allowed categories: plant_based, dairy, egg\\nE...\n",
       "2   3  pescetarian  Allowed categories: plant_based, dairy, egg, s...\n",
       "3   4   dairy free  Excluded allergen groups: milk\\nExcluded ingre...\n",
       "4   5     egg free  Excluded allergen groups: egg\\nExcluded ingred..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "category_map = pd.read_excel('1st_dataset.xlsx', sheet_name='category')\n",
    "print(\"Category columns:\", category_map.columns.tolist())\n",
    "print(\"Category shape:\", category_map.shape)\n",
    "print(\"\\nFirst 5 rows of Category:\")\n",
    "display(category_map.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "50627cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_recipe_categories(recipe_data, dietary_tags):\n",
    "    \"\"\"\n",
    "    Classifies a recipe into multiple dietary preference categories.\n",
    "    \n",
    "    Parameters:\n",
    "        recipe_data (dict): Must contain:\n",
    "            - 'ner_ingredients' (list or str)\n",
    "            - 'allergens' (list of detected allergen groups like ['milk', 'soy'])\n",
    "            - 'texture' (optional, for stage-based filtering)\n",
    "        \n",
    "        dietary_tags (dict): Dictionary mapping diet name → rules\n",
    "    \n",
    "    Returns:\n",
    "        dict: {\n",
    "            \"matched_tags\": list[str]  # e.g., ['vegan', 'soy', 'halal']\n",
    "        }\n",
    "    \"\"\"\n",
    "    ner_ingredient = recipe_data.get(\"ner_ingredient\", [])\n",
    "    # Normalize ingredients (make sure they're lowercase and clean)\n",
    "    cleaned_ingredients = [str(i).strip().lower() for i in ner_ingredient if i]\n",
    "    combined_text = ' '.join(cleaned_ingredients)\n",
    "\n",
    "    detected_allergens = recipe_data.get(\"allergen\", [])\n",
    "    allergen = [str(i).strip().lower() for i in detected_allergens if i]\n",
    "    allergen_text = ' '.join(allergen).lower()\n",
    "    matched_tags = []\n",
    "\n",
    "    for tag, rules in dietary_tags.items():\n",
    "        exclude_found = False\n",
    "\n",
    "        # Step 1: Check excluded ingredients\n",
    "        if \"excluded_ingredients\" in rules:\n",
    "            for word in rules[\"excluded_ingredients\"]:\n",
    "                if word.lower() in combined_text:\n",
    "                    exclude_found = True\n",
    "                    break\n",
    "\n",
    "        # Step 2: Check excluded allergen groups\n",
    "        if \"excluded_allergen_groups\" in rules:\n",
    "            for group in rules[\"excluded_allergen_groups\"]:\n",
    "                if group in allergen_text:\n",
    "                    exclude_found = True\n",
    "                    break\n",
    "\n",
    "        # Step 3: Required ingredients check (for non_halal etc.)\n",
    "        if \"required_ingredients\" in rules:\n",
    "            required_match = any(word in combined_text for word in rules[\"required_ingredients\"])\n",
    "            if not required_match:\n",
    "                continue  # Skip unless match found\n",
    "\n",
    "        # If no exclusion → match this tag\n",
    "        if not exclude_found:\n",
    "            matched_tags.append(tag)\n",
    "            \n",
    "    if not matched_tags and \"non_veg\" in dietary_tags:\n",
    "        matched_tags.append(\"non_veg\")    \n",
    "    \n",
    "    \n",
    "    return matched_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "64dbd5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_recipe(recipe_data, dietary_tags):\n",
    "    ner_ingredient = recipe_data.get(\"ner_ingredient\", [])\n",
    "    # Normalize ingredients (make sure they're lowercase and clean)\n",
    "    cleaned_ingredients = [str(i).strip().lower() for i in ner_ingredient if i]\n",
    "    combined_text = ' '.join(cleaned_ingredients)\n",
    "\n",
    "    detected_allergens = recipe_data.get(\"allergen\", [])\n",
    "    allergen = [str(i).strip().lower() for i in detected_allergens if i]\n",
    "    allergen_text = ' '.join(allergen).lower()\n",
    "\n",
    "    matched_tags = []\n",
    "\n",
    "    # Step 1: Match all possible tags\n",
    "    for tag, rules in dietary_tags.items():\n",
    "        exclude_found = False\n",
    "\n",
    "        # Step 1a: Check excluded ingredients\n",
    "        if \"excluded_ingredients\" in rules:\n",
    "            for word in rules[\"excluded_ingredients\"]:\n",
    "                if word.lower() in combined_text:\n",
    "                    exclude_found = True\n",
    "                    break\n",
    "\n",
    "        # Step 1b: Check excluded allergen groups\n",
    "        if \"excluded_allergen_groups\" in rules:\n",
    "            for group in rules[\"excluded_allergen_groups\"]:\n",
    "                if group in allergen_text:\n",
    "                    exclude_found = True\n",
    "                    break\n",
    "\n",
    "        # Step 1c: Required ingredients check (e.g., for non_halal)\n",
    "        if \"required_ingredients\" in rules:\n",
    "            required_match = any(word in combined_text for word in rules[\"required_ingredients\"])\n",
    "            if not required_match:\n",
    "                continue\n",
    "\n",
    "        if not exclude_found:\n",
    "            matched_tags.append(tag)\n",
    "\n",
    "    # Define categories\n",
    "    GENERAL_DIET_TAGS = [\"vegan\", \"vegetarian\", \"pescetarian\", \"non_veg\"]\n",
    "    RELIGIOUS_TAGS = [\"halal\", \"non_halal\"]\n",
    "    ALLERGEN_TAGS = [\"dairy_free\", \"egg_free\", \"soy_free\", \"nut_free\", \"gluten_free\"]\n",
    "\n",
    "    result = {\n",
    "        \"general_diet\": None,\n",
    "        \"religious_tag\": None,\n",
    "        \"allergen_tags\": [],\n",
    "    }\n",
    "\n",
    "    # Step 2: Select only one general diet (priority-based)\n",
    "    for tag in GENERAL_DIET_TAGS:\n",
    "        if tag in matched_tags:\n",
    "            result[\"general_diet\"] = tag\n",
    "            break\n",
    "    else:\n",
    "        # Fallback (shouldn't happen unless none of the 4 are valid)\n",
    "        result[\"general_diet\"] = \"non_veg\"\n",
    "\n",
    "    # Step 3: Select at most one religious tag (prefer halal over non_halal)\n",
    "    for tag in RELIGIOUS_TAGS:\n",
    "        if tag in matched_tags:\n",
    "            result[\"religious_tag\"] = tag\n",
    "            break\n",
    "\n",
    "    # Step 4: Select all applicable allergen-friendly tags\n",
    "    result[\"allergen_tags\"] = [tag for tag in matched_tags if tag in ALLERGEN_TAGS]\n",
    "\n",
    "    values = []\n",
    "    \n",
    "    # Add general diet if present\n",
    "    if result.get(\"general_diet\"):\n",
    "        values.append(result[\"general_diet\"])\n",
    "    \n",
    "    # Add religious tag if present\n",
    "    if result.get(\"religious_tag\"):\n",
    "        values.append(result[\"religious_tag\"])\n",
    "    \n",
    "    # Add allergen tags if present\n",
    "    allergen_tags = result.get(\"allergen_tags\", [])\n",
    "    if allergen_tags:\n",
    "        values.extend(allergen_tags)\n",
    "    \n",
    "    # Join all values with commas\n",
    "    return \", \".join(values)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "057267fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified Tags:\n",
      "vegan, halal, dairy_free, egg_free, soy_free, nut_free, gluten_free\n"
     ]
    }
   ],
   "source": [
    "sample_row = df.iloc[0].copy()  \n",
    "classified_tags = classify_recipe(sample_row, dietary_tags)\n",
    "print(\"Classified Tags:\")\n",
    "print(classified_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "f9bac8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ner_ingredient</th>\n",
       "      <th>dietary_tags</th>\n",
       "      <th>choking_hazard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['cassava', 'fish', 'chicken', 'coconut oil', ...</td>\n",
       "      <td>vegan, halal, dairy_free, egg_free, soy_free, ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['beef', 'potato starch', 'milk', 'egg', 'marg...</td>\n",
       "      <td>vegan, halal, dairy_free, egg_free, soy_free, ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['cauliflower', 'broccoli', 'margarine', 'flou...</td>\n",
       "      <td>vegan, halal, dairy_free, egg_free, soy_free, ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['carrot', 'potato', 'sweet potato']</td>\n",
       "      <td>vegan, halal, dairy_free, egg_free, soy_free, ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['onion', 'vegetable oil', 'beef', 'steak', 'c...</td>\n",
       "      <td>vegan, halal, dairy_free, egg_free, soy_free, ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['wholemeal bread']</td>\n",
       "      <td>vegan, halal, dairy_free, egg_free, soy_free, ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['water', 'polenta', 'pumpkin', 'parmesan chee...</td>\n",
       "      <td>vegan, halal, dairy_free, egg_free, soy_free, ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['rice', 'milk', 'sugar', 'vanilla essence']</td>\n",
       "      <td>vegan, halal, dairy_free, egg_free, soy_free, ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['chickpeas', 'garlic', 'lemon juice', 'milk',...</td>\n",
       "      <td>vegan, halal, dairy_free, egg_free, soy_free, ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['baked beans', 'zucchini', 'potatoes', 'milk'...</td>\n",
       "      <td>vegan, halal, dairy_free, egg_free, soy_free, ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      ner_ingredient  \\\n",
       "0  ['cassava', 'fish', 'chicken', 'coconut oil', ...   \n",
       "1  ['beef', 'potato starch', 'milk', 'egg', 'marg...   \n",
       "2  ['cauliflower', 'broccoli', 'margarine', 'flou...   \n",
       "3               ['carrot', 'potato', 'sweet potato']   \n",
       "4  ['onion', 'vegetable oil', 'beef', 'steak', 'c...   \n",
       "5                                ['wholemeal bread']   \n",
       "6  ['water', 'polenta', 'pumpkin', 'parmesan chee...   \n",
       "7       ['rice', 'milk', 'sugar', 'vanilla essence']   \n",
       "8  ['chickpeas', 'garlic', 'lemon juice', 'milk',...   \n",
       "9  ['baked beans', 'zucchini', 'potatoes', 'milk'...   \n",
       "\n",
       "                                        dietary_tags choking_hazard  \n",
       "0  vegan, halal, dairy_free, egg_free, soy_free, ...           None  \n",
       "1  vegan, halal, dairy_free, egg_free, soy_free, ...           None  \n",
       "2  vegan, halal, dairy_free, egg_free, soy_free, ...           None  \n",
       "3  vegan, halal, dairy_free, egg_free, soy_free, ...           None  \n",
       "4  vegan, halal, dairy_free, egg_free, soy_free, ...           None  \n",
       "5  vegan, halal, dairy_free, egg_free, soy_free, ...           None  \n",
       "6  vegan, halal, dairy_free, egg_free, soy_free, ...           None  \n",
       "7  vegan, halal, dairy_free, egg_free, soy_free, ...           None  \n",
       "8  vegan, halal, dairy_free, egg_free, soy_free, ...           None  \n",
       "9  vegan, halal, dairy_free, egg_free, soy_free, ...           None  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dietary_tags'] = df.apply(\n",
    "    lambda row: classify_recipe(row, dietary_tags),\n",
    "    axis=1)\n",
    "\n",
    "df[['ner_ingredient', 'dietary_tags', 'choking_hazard']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e370946e",
   "metadata": {},
   "source": [
    "Populating Nutrition Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "2bca9a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of None values in texture column: 0\n",
      "Number of 'None' string values in texture column: 0\n",
      "Number of empty strings in texture column: 0\n",
      "Number of 'NONE' values in texture column: 814\n"
     ]
    }
   ],
   "source": [
    "# Check count of texture None values\n",
    "none_count = df[df['texture'].isna()].shape[0]  # For actual None/NaN values\n",
    "print(f\"Number of None values in texture column: {none_count}\")\n",
    "\n",
    "# Check count of \"None\" string values\n",
    "none_string_count = df[df['texture'] == \"None\"].shape[0]\n",
    "print(f\"Number of 'None' string values in texture column: {none_string_count}\")\n",
    "\n",
    "# Check count of empty strings\n",
    "empty_string_count = df[df['texture'] == \"\"].shape[0]  \n",
    "print(f\"Number of empty strings in texture column: {empty_string_count}\")\n",
    "\n",
    "# Check count of \"NONE\" uppercase string values (as seen in your code elsewhere)\n",
    "none_upper_count = df[df['texture'] == \"NONE\"].shape[0]\n",
    "print(f\"Number of 'NONE' values in texture column: {none_upper_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "723d2edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique ingredients found: 0\n",
      "Unique ingredients:\n"
     ]
    }
   ],
   "source": [
    "# Flatten the list of lists to get all unique ingredients\n",
    "all_ingredients = set()\n",
    "for ingredient_list in df['ner_ingredient']:\n",
    "    if isinstance(ingredient_list, list):\n",
    "        all_ingredients.update(ingredient_list)\n",
    "\n",
    "print(f\"Total unique ingredients found: {len(all_ingredients)}\")\n",
    "print(\"Unique ingredients:\")\n",
    "for ingredient in sorted(all_ingredients):\n",
    "    print(f\"- {ingredient}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "749d51b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique ingredients found: 0\n",
      "\n",
      "Ingredient frequency (sorted by most common):\n",
      "\n",
      "Ingredient frequency (sorted alphabetically):\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each unique ingredient\n",
    "ingredient_counts = {}\n",
    "for ingredient_list in df['ner_ingredient']:\n",
    "    if isinstance(ingredient_list, list):\n",
    "        for ingredient in ingredient_list:\n",
    "            if ingredient in ingredient_counts:\n",
    "                ingredient_counts[ingredient] += 1\n",
    "            else:\n",
    "                ingredient_counts[ingredient] = 1\n",
    "\n",
    "# Sort ingredients by frequency (most common first)\n",
    "sorted_ingredients = sorted(ingredient_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total unique ingredients found: {len(ingredient_counts)}\")\n",
    "print(\"\\nIngredient frequency (sorted by most common):\")\n",
    "for ingredient, count in sorted_ingredients:\n",
    "    print(f\"- {ingredient}: {count} recipes\")\n",
    "\n",
    "# Alternatively, print alphabetically with counts\n",
    "print(\"\\nIngredient frequency (sorted alphabetically):\")\n",
    "for ingredient in sorted(ingredient_counts.keys()):\n",
    "    count = ingredient_counts[ingredient]\n",
    "    print(f\"- {ingredient}: {count} recipes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5927f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "465dd741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ingredients dataframe with 0 unique ingredients\n",
      "\n",
      "First 10 ingredients:\n",
      "Empty DataFrame\n",
      "Columns: [ingredient_id, ingredient_name]\n",
      "Index: []\n",
      "\n",
      "Last 5 ingredients:\n",
      "Empty DataFrame\n",
      "Columns: [ingredient_id, ingredient_name]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create unique ingredients dataframe with ingredient IDs\n",
    "unique_ingredients_list = sorted(list(all_ingredients))\n",
    "\n",
    "# Create ingredients dataframe with IDs\n",
    "ingredients_df = pd.DataFrame({\n",
    "    'ingredient_id': range(1, len(unique_ingredients_list) + 1),\n",
    "    'ingredient_name': unique_ingredients_list\n",
    "})\n",
    "\n",
    "print(f\"Created ingredients dataframe with {len(ingredients_df)} unique ingredients\")\n",
    "print(\"\\nFirst 10 ingredients:\")\n",
    "print(ingredients_df.head(10))\n",
    "print(\"\\nLast 5 ingredients:\")\n",
    "print(ingredients_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "c805ffe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing allergen detection:\n",
      "- milk: ['dairy']\n",
      "- egg: ['egg']\n",
      "- tofu: ['soy']\n",
      "- rice: []\n",
      "- peanut butter: ['peanuts']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Function to detect allergens for a single ingredient\n",
    "def detect_ingredient_allergens(ingredient_name, allergen_tags):\n",
    "    \"\"\"\n",
    "    Detect which allergens an ingredient contains based on allergen tags.\n",
    "    \n",
    "    Args:\n",
    "        ingredient_name (str): Name of the ingredient\n",
    "        allergen_tags (dict): Dictionary of allergen tags with keywords\n",
    "    \n",
    "    Returns:\n",
    "        list: List of allergen names that match the ingredient\n",
    "    \"\"\"\n",
    "    ingredient_lower = ingredient_name.lower().strip()\n",
    "    detected_allergens = []\n",
    "    \n",
    "    for allergen_name, allergen_data in allergen_tags.items():\n",
    "        keywords = allergen_data.get('keywords', [])\n",
    "        allergen_group = allergen_data.get('allergen_group', allergen_name)  # Get allergen_group, fallback to allergen_name\n",
    "                \n",
    "        # Check if any keyword matches the ingredient\n",
    "        for keyword in keywords:\n",
    "            # print(f\"Checking ingredient '{ingredient_name}' against allergen '{allergen_name}' with keyword '{keyword}'\")\n",
    "            if keyword.lower().strip() == ingredient_lower:\n",
    "                # print(f\"Detected allergen '{allergen_name}' for ingredient '{ingredient_name}'\")\n",
    "                if allergen_name not in detected_allergens:\n",
    "                    detected_allergens.append(allergen_group)\n",
    "                    # detected_allergens.append(allergen_name)\n",
    "                break  # No need to check other keywords for this allergen\n",
    "    \n",
    "    return detected_allergens\n",
    "\n",
    "# Test the function with a few examples\n",
    "test_ingredients = ['milk', 'egg', 'tofu', 'rice', 'peanut butter']\n",
    "print(\"Testing allergen detection:\")\n",
    "for ingredient in test_ingredients:\n",
    "    allergens = detect_ingredient_allergens(ingredient, allergen_tags)\n",
    "    print(f\"- {ingredient}: {allergens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "5ff5159a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detecting allergens for all ingredients...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDetecting allergens for all ingredients...\")\n",
    "ingredients_df['detected_allergens'] = ingredients_df['ingredient_name'].apply(\n",
    "    lambda x: detect_ingredient_allergens(x, allergen_tags)\n",
    ")\n",
    "\n",
    "# Filter ingredients with no allergens (empty list)\n",
    "ingredients_with_no_allergens = ingredients_df[ingredients_df['detected_allergens'].apply(len) == 0]\n",
    "\n",
    "# Store them in a separate dataframe\n",
    "null_allergen_ingredients_df = ingredients_with_no_allergens[['ingredient_id', 'ingredient_name']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "58f34197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 0 ingredients with NO allergens detected:\n",
      "\n",
      "Ingredients with no allergens:\n",
      "\n",
      "📊 Allergen Detection Summary:\n",
      "- Total ingredients: 0\n",
      "- Ingredients with allergens: 0\n",
      "- Ingredients with NO allergens: 0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[325], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Ingredients with allergens: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ingredients_df)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(null_allergen_ingredients_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Ingredients with NO allergens: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(null_allergen_ingredients_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Percentage with no allergens: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnull_allergen_ingredients_df\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mingredients_df\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Save the null allergen ingredients to a separate Excel file if needed\u001b[39;00m\n\u001b[0;32m     14\u001b[0m null_allergen_ingredients_df\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mingredients_with_no_allergens.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"\\nFound {len(null_allergen_ingredients_df)} ingredients with NO allergens detected:\")\n",
    "print(\"\\nIngredients with no allergens:\")\n",
    "for _, row in null_allergen_ingredients_df.iterrows():\n",
    "    print(f\"- ID: {row['ingredient_id']}, Name: '{row['ingredient_name']}'\")\n",
    "\n",
    "# Show summary statistics\n",
    "print(f\"\\n📊 Allergen Detection Summary:\")\n",
    "print(f\"- Total ingredients: {len(ingredients_df)}\")\n",
    "print(f\"- Ingredients with allergens: {len(ingredients_df) - len(null_allergen_ingredients_df)}\")\n",
    "print(f\"- Ingredients with NO allergens: {len(null_allergen_ingredients_df)}\")\n",
    "print(f\"- Percentage with no allergens: {len(null_allergen_ingredients_df)/len(ingredients_df)*100:.1f}%\")\n",
    "\n",
    "# Save the null allergen ingredients to a separate Excel file if needed\n",
    "null_allergen_ingredients_df.to_excel('ingredients_with_no_allergens.xlsx', index=False)\n",
    "print(f\"\\n✅ Saved {len(null_allergen_ingredients_df)} ingredients with no allergens to 'ingredients_with_no_allergens.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d14f3",
   "metadata": {},
   "source": [
    "## 🔗 Connect Allergen Group IDs with Ingredient IDs\n",
    "\n",
    "Based on allergen tags mapping to ensure 1 ingredient maps to 1 primary allergen only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672ebda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_allergens(recipe_data, ALLERGEN_TAGS):\n",
    "    ner_ingredients = recipe_data.get(\"ner_ingredient_string\", [])\n",
    "    # Normalize ingredients (make sure they're lowercase and clean)\n",
    "    cleaned_ingredients = [str(i).strip().lower() for i in ner_ingredients if i]\n",
    "\n",
    "    # Combine into one searchable string\n",
    "    combined_text = ' '.join(cleaned_ingredients)\n",
    "    matched_allergens = []\n",
    "\n",
    "    # Define exclusion terms for breast milk and formula\n",
    "    exclusion_terms = [\"breast milk\", \"breastmilk\", \"formula milk\", \"formula\", \"breast\"]\n",
    "    # First check if the combined text contains any exclusion terms\n",
    "    has_exclusion_terms = any(exclusion in combined_text for exclusion in exclusion_terms)\n",
    "    for allergen, data in ALLERGEN_TAGS.items():\n",
    "        keywords = [kw.lower() for kw in data[\"keywords\"]]\n",
    "        \n",
    "        # For milk allergen specifically, skip entirely if exclusion terms found\n",
    "        if allergen == \"milk\" and has_exclusion_terms:\n",
    "            continue\n",
    "            \n",
    "        for keyword in keywords:\n",
    "            if keyword in combined_text:\n",
    "                # Check if this keyword match is actually part of an exclusion term\n",
    "                is_excluded = False\n",
    "                \n",
    "                # For example, if \"milk\" is found but it's part of \"breast milk\"\n",
    "                for exclusion in exclusion_terms:\n",
    "                    # Check all possible positions where keyword could be within exclusion term\n",
    "                    if (exclusion.startswith(keyword + \" \") or \n",
    "                        exclusion.endswith(\" \" + keyword) or \n",
    "                        \" \" + keyword + \" \" in exclusion or \n",
    "                        exclusion == keyword):\n",
    "                        \n",
    "                        # Only exclude if this exact exclusion term is in the text\n",
    "                        if exclusion in combined_text:\n",
    "                            is_excluded = True\n",
    "                            break\n",
    "                \n",
    "                if not is_excluded:\n",
    "                    matched_allergens.append(allergen)\n",
    "                    break  # No need to check other keywords for this allergen\n",
    "\n",
    "    return list(set(matched_allergens))  # Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaae4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_allergen_with_strategy(ingredient_name, allergen_tags):\n",
    "    \"\"\"\n",
    "    Advanced allergen detection using two-step matching strategy:\n",
    "    1. Exact matching - check if ingredient name exactly matches any keyword\n",
    "    2. Partial keyword matching - check if any allergen keyword appears in ingredient name\n",
    "    \n",
    "    Args:\n",
    "        ingredient_name (str): Name of the ingredient to check\n",
    "        allergen_tags (dict): Dictionary of allergen information\n",
    "    \n",
    "    Returns:\n",
    "        dict: {\n",
    "            'allergen_group': str or None,\n",
    "            'match_type': 'exact' or 'partial' or None,\n",
    "            'matched_keyword': str or None,\n",
    "            'confidence': float (0.0 to 1.0)\n",
    "        }\n",
    "    \"\"\"\n",
    "    ingredient_lower = ingredient_name.lower().strip()\n",
    "    exclusion_terms = [\"breast milk\", \"breastmilk\", \"formula milk\", \"formula\", \"breast\"]\n",
    "    # Step 1: Exact matching (highest priority)\n",
    "    for allergen_name, allergen_data in allergen_tags.items():\n",
    "        keywords = allergen_data.get('keywords', [])\n",
    "        allergen_group = allergen_data.get('allergen_group', allergen_name)\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            keyword_lower = keyword.lower().strip()\n",
    "            if keyword_lower == ingredient_lower:\n",
    "                return {\n",
    "                    'allergen_group': allergen_group,\n",
    "                    'match_type': 'exact',\n",
    "                    'matched_keyword': keyword,\n",
    "                    'confidence': 1.0\n",
    "                }\n",
    "    \n",
    "    # Step 2: Partial keyword matching (lower priority)\n",
    "    partial_matches = []\n",
    "    \n",
    "    for allergen_name, allergen_data in allergen_tags.items():\n",
    "        keywords = allergen_data.get('keywords', [])\n",
    "        allergen_group = allergen_data.get('allergen_group', allergen_name)\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            keyword_lower = keyword.lower().strip()\n",
    "            \n",
    "            # Check if keyword appears as a word in ingredient name\n",
    "            if keyword_lower in ingredient_lower:\n",
    "                # Calculate confidence based on match quality\n",
    "                confidence = calculate_match_confidence(ingredient_lower, keyword_lower)\n",
    "                \n",
    "                partial_matches.append({\n",
    "                    'allergen_group': allergen_group,\n",
    "                    'match_type': 'partial',\n",
    "                    'matched_keyword': keyword,\n",
    "                    'confidence': confidence,\n",
    "                    'allergen_name': allergen_name\n",
    "                })\n",
    "    \n",
    "    # If partial matches found, return the best one\n",
    "    if partial_matches:\n",
    "        # Sort by confidence (highest first)\n",
    "        partial_matches.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "        best_match = partial_matches[0]\n",
    "        \n",
    "        # Only return if confidence is above threshold\n",
    "        if best_match['confidence'] >= 0.5:\n",
    "            return {\n",
    "                'allergen_group': best_match['allergen_group'],\n",
    "                'match_type': best_match['match_type'],\n",
    "                'matched_keyword': best_match['matched_keyword'],\n",
    "                'confidence': best_match['confidence']\n",
    "            }\n",
    "    \n",
    "    # No match found\n",
    "    return {\n",
    "        'allergen_group': None,\n",
    "        'match_type': None,\n",
    "        'matched_keyword': None,\n",
    "        'confidence': 0.0\n",
    "    }\n",
    "\n",
    "def calculate_match_confidence(ingredient_name, keyword):\n",
    "    \"\"\"\n",
    "    Calculate confidence score for partial matches based on various factors.\n",
    "    \n",
    "    Args:\n",
    "        ingredient_name (str): The ingredient name (lowercase)\n",
    "        keyword (str): The allergen keyword (lowercase)\n",
    "    \n",
    "    Returns:\n",
    "        float: Confidence score between 0.0 and 1.0\n",
    "    \"\"\"\n",
    "    # Base confidence for any partial match\n",
    "    confidence = 0.6\n",
    "    \n",
    "    # Boost confidence if keyword is a significant portion of ingredient name\n",
    "    if len(keyword) >= len(ingredient_name) * 0.5:\n",
    "        confidence += 0.2\n",
    "    \n",
    "    # Boost confidence if keyword appears at start or end\n",
    "    if ingredient_name.startswith(keyword) or ingredient_name.endswith(keyword):\n",
    "        confidence += 0.2\n",
    "    \n",
    "    # Boost confidence if keyword appears as a complete word (surrounded by spaces or boundaries)\n",
    "    import re\n",
    "    if re.search(r'\\b' + re.escape(keyword) + r'\\b', ingredient_name):\n",
    "        confidence += 0.1\n",
    "    \n",
    "    # Reduce confidence for very short keywords in long ingredient names\n",
    "    if len(keyword) <= 3 and len(ingredient_name) >= 10:\n",
    "        confidence -= 0.2\n",
    "    \n",
    "    # Cap confidence at 0.95 for partial matches (exact matches get 1.0)\n",
    "    return min(0.95, max(0.0, confidence))\n",
    "\n",
    "def detect_allergen_simple(ingredient_name, allergen_tags):\n",
    "    \"\"\"\n",
    "    Simplified version that returns just the allergen group (backward compatibility).\n",
    "    \n",
    "    Args:\n",
    "        ingredient_name (str): Name of the ingredient\n",
    "        allergen_tags (dict): Dictionary of allergen tags\n",
    "    \n",
    "    Returns:\n",
    "        str or None: Allergen group name or None\n",
    "    \"\"\"\n",
    "    result = detect_allergen_with_strategy(ingredient_name, allergen_tags)\n",
    "    return result.get('allergen_group')\n",
    "\n",
    "def test_allergen_detection():\n",
    "    \"\"\"\n",
    "    Test function to demonstrate the matching strategy.\n",
    "    \"\"\"\n",
    "    test_ingredients = [\n",
    "        \"milk\",                    # Exact match\n",
    "        \"whole milk\",             # Partial match  \n",
    "        \"milk chocolate\",         # Partial match\n",
    "        \"almond butter\",          # Exact match (tree nuts)\n",
    "        \"peanut oil\",            # Exact match (peanuts)\n",
    "        \"wheat flour\",           # Partial match (gluten)\n",
    "        \"salmon fillet\",         # Partial match (fish)\n",
    "        \"chicken breast\",        # No match\n",
    "        \"egg white powder\",      # Partial match (egg)\n",
    "        \"soy sauce concentrate\"  # Partial match (soy)\n",
    "    ]\n",
    "    \n",
    "    print(\"🧪 TESTING ALLERGEN DETECTION STRATEGY\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for ingredient in test_ingredients:\n",
    "        result = detect_allergen_with_strategy(ingredient, ALLERGEN_TAGS)\n",
    "        \n",
    "        if result['allergen_group']:\n",
    "            print(f\"✅ '{ingredient}':\")\n",
    "            print(f\"   → Allergen: {result['allergen_group']}\")\n",
    "            print(f\"   → Match type: {result['match_type']}\")\n",
    "            print(f\"   → Matched keyword: '{result['matched_keyword']}'\")\n",
    "            print(f\"   → Confidence: {result['confidence']:.2f}\")\n",
    "        else:\n",
    "            print(f\"❌ '{ingredient}': No allergen detected\")\n",
    "        print()\n",
    "\n",
    "# Uncomment to run test\n",
    "# test_allergen_detection()\n",
    "\n",
    "# Quick test examples\n",
    "if __name__ == \"__main__\":\n",
    "    # Test the function with a few examples\n",
    "    test_cases = [\"milk\", \"wheat flour\", \"almond butter\", \"chicken\", \"egg white\"]\n",
    "    \n",
    "    print(\"Quick Test Results:\")\n",
    "    for ingredient in test_cases:\n",
    "        result = detect_allergen_with_strategy(ingredient, ALLERGEN_TAGS)\n",
    "        if result['allergen_group']:\n",
    "            print(f\"  {ingredient} → {result['allergen_group']} ({result['match_type']}, {result['confidence']:.2f})\")\n",
    "        else:\n",
    "            print(f\"  {ingredient} → No allergen detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d7f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 CONNECTING ALLERGEN GROUP IDs WITH INGREDIENT IDs\n",
      "============================================================\n",
      "📊 Available allergen groups:\n",
      "   - dairy (ID: 1)\n",
      "   - egg (ID: 2)\n",
      "   - soy (ID: 3)\n",
      "   - tree_nuts (ID: 4)\n",
      "   - peanuts (ID: 5)\n",
      "   - fish (ID: 6)\n",
      "   - shellfish (ID: 7)\n",
      "   - gluten (ID: 8)\n",
      "\n",
      "🔍 Detecting primary allergens for 990 ingredients...\n",
      "\n",
      "✅ ALLERGEN MAPPING RESULTS:\n",
      "   Total ingredients: 990\n",
      "   Ingredients with allergens: 67 (6.8%)\n",
      "   Ingredients without allergens: 923 (93.2%)\n",
      "\n",
      "📊 Breakdown by allergen group:\n",
      "   - dairy (ID: 1): 17 ingredients\n",
      "   - gluten (ID: 8): 11 ingredients\n",
      "   - fish (ID: 6): 10 ingredients\n",
      "   - soy (ID: 3): 8 ingredients\n",
      "   - tree_nuts (ID: 4): 7 ingredients\n",
      "   - egg (ID: 2): 7 ingredients\n",
      "   - shellfish (ID: 7): 5 ingredients\n",
      "   - peanuts (ID: 5): 2 ingredients\n",
      "\n",
      "📋 Sample mapped ingredients:\n",
      "   - ID: 5, Name: 'almond butter', Allergen: tree_nuts (Group ID: 4.0)\n",
      "   - ID: 6, Name: 'almond milk', Allergen: tree_nuts (Group ID: 4.0)\n",
      "   - ID: 12, Name: 'anchovy', Allergen: fish (Group ID: 6.0)\n",
      "   - ID: 60, Name: 'barley', Allergen: gluten (Group ID: 8.0)\n",
      "   - ID: 110, Name: 'bread', Allergen: gluten (Group ID: 8.0)\n",
      "   - ID: 113, Name: 'bread flour', Allergen: gluten (Group ID: 8.0)\n",
      "   - ID: 132, Name: 'butter', Allergen: dairy (Group ID: 1.0)\n",
      "   - ID: 152, Name: 'cashew', Allergen: tree_nuts (Group ID: 4.0)\n",
      "   - ID: 153, Name: 'cashew butter', Allergen: tree_nuts (Group ID: 4.0)\n",
      "   - ID: 157, Name: 'catfish', Allergen: fish (Group ID: 6.0)\n",
      "\n",
      "📋 Sample ingredients without allergens:\n",
      "   - ID: 1, Name: 'acai'\n",
      "   - ID: 2, Name: 'agar-agar powder'\n",
      "   - ID: 3, Name: 'all purpose flour'\n",
      "   - ID: 4, Name: 'almond'\n",
      "   - ID: 7, Name: 'almond nuts'\n"
     ]
    }
   ],
   "source": [
    "def detect_primary_allergen_for_ingredient(ingredient_name, allergen_tags):\n",
    "    \"\"\"\n",
    "    Detect the primary allergen for a single ingredient based on allergen tags.\n",
    "    Ensures 1 ingredient maps to 1 primary allergen only.\n",
    "    \n",
    "    Args:\n",
    "        ingredient_name (str): Name of the ingredient\n",
    "        allergen_tags (dict): Dictionary of allergen tags with keywords\n",
    "    \n",
    "    Returns:\n",
    "        str or None: Primary allergen group name, or None if no allergen detected\n",
    "    \"\"\"\n",
    "    ingredient_lower = ingredient_name.lower().strip()\n",
    "    detected_allergens = []\n",
    "    \n",
    "    # Priority order for allergens (most specific to least specific)\n",
    "    allergen_priority = [\n",
    "        'shellfish', 'fish', 'peanuts', 'tree_nuts', 'egg', 'dairy', 'soy', 'gluten'\n",
    "    ]\n",
    "    \n",
    "    # First pass: detect all matching allergens\n",
    "    for allergen_name, allergen_data in allergen_tags.items():\n",
    "        keywords = allergen_data.get('keywords', [])\n",
    "        allergen_group = allergen_data.get('allergen_group', allergen_name)\n",
    "        \n",
    "        # Check if any keyword matches the ingredient exactly\n",
    "        for keyword in keywords:\n",
    "            if keyword.lower().strip() == ingredient_lower:\n",
    "                detected_allergens.append(allergen_group)\n",
    "                break  # No need to check other keywords for this allergen\n",
    "    \n",
    "    # If no allergens detected, return None\n",
    "    if not detected_allergens:\n",
    "        return None\n",
    "    \n",
    "    # If only one allergen detected, return it\n",
    "    if len(detected_allergens) == 1:\n",
    "        return detected_allergens[0]\n",
    "    \n",
    "    # If multiple allergens detected, select based on priority\n",
    "    for priority_allergen in allergen_priority:\n",
    "        if priority_allergen in detected_allergens:\n",
    "            return priority_allergen\n",
    "    \n",
    "    # Fallback: return the first detected allergen\n",
    "    return detected_allergens[0]\n",
    "\n",
    "\n",
    "def add_allergen_group_id_to_ingredients(ingredient_df, allergen_df, allergen_tags):\n",
    "    \"\"\"\n",
    "    Add allergen_group_id column to ingredient_df based on allergen detection.\n",
    "    \n",
    "    Args:\n",
    "        ingredient_df: DataFrame with ingredient_id and ingredient_name\n",
    "        allergen_df: DataFrame with allergen group information (pk, name, description)\n",
    "        allergen_tags: Dictionary of allergen tags for detection\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Updated ingredient_df with allergen_group_id column\n",
    "    \"\"\"\n",
    "    print(\"🔗 CONNECTING ALLERGEN GROUP IDs WITH INGREDIENT IDs\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create a mapping from allergen group name to allergen group ID\n",
    "    allergen_name_to_id = dict(zip(allergen_df['name'], allergen_df['pk']))\n",
    "    \n",
    "    print(f\"📊 Available allergen groups:\")\n",
    "    for name, pk in allergen_name_to_id.items():\n",
    "        print(f\"   - {name} (ID: {pk})\")\n",
    "    \n",
    "    # Create a copy of ingredient_df to avoid modifying the original\n",
    "    updated_ingredient_df = ingredient_df.copy()\n",
    "    \n",
    "    # Detect primary allergen for each ingredient\n",
    "    print(f\"\\n🔍 Detecting primary allergens for {len(updated_ingredient_df)} ingredients...\")\n",
    "    \n",
    "    primary_allergens = []\n",
    "    allergen_group_ids = []\n",
    "    \n",
    "    for _, row in updated_ingredient_df.iterrows():\n",
    "        ingredient_name = row['ingredient_name']\n",
    "        primary_allergen = detect_primary_allergen_for_ingredient(ingredient_name, allergen_tags)\n",
    "        primary_allergens.append(primary_allergen)\n",
    "        \n",
    "        # Map to allergen group ID\n",
    "        if primary_allergen and primary_allergen in allergen_name_to_id:\n",
    "            allergen_group_id = allergen_name_to_id[primary_allergen]\n",
    "        else:\n",
    "            allergen_group_id = None  # No allergen detected\n",
    "        \n",
    "        allergen_group_ids.append(allergen_group_id)\n",
    "    \n",
    "    # Add the new columns\n",
    "    updated_ingredient_df['primary_allergen'] = primary_allergens\n",
    "    updated_ingredient_df['allergen_group_id'] = allergen_group_ids\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_ingredients = len(updated_ingredient_df)\n",
    "    ingredients_with_allergens = updated_ingredient_df['allergen_group_id'].notna().sum()\n",
    "    ingredients_without_allergens = total_ingredients - ingredients_with_allergens\n",
    "    \n",
    "    print(f\"\\n✅ ALLERGEN MAPPING RESULTS:\")\n",
    "    print(f\"   Total ingredients: {total_ingredients}\")\n",
    "    print(f\"   Ingredients with allergens: {ingredients_with_allergens} ({ingredients_with_allergens/total_ingredients*100:.1f}%)\")\n",
    "    print(f\"   Ingredients without allergens: {ingredients_without_allergens} ({ingredients_without_allergens/total_ingredients*100:.1f}%)\")\n",
    "    \n",
    "    # Show breakdown by allergen group\n",
    "    allergen_counts = updated_ingredient_df['primary_allergen'].value_counts()\n",
    "    print(f\"\\n📊 Breakdown by allergen group:\")\n",
    "    for allergen, count in allergen_counts.items():\n",
    "        if allergen:  # Skip None values\n",
    "            allergen_id = allergen_name_to_id.get(allergen, 'Unknown')\n",
    "            print(f\"   - {allergen} (ID: {allergen_id}): {count} ingredients\")\n",
    "    \n",
    "    # Show sample of mapped ingredients\n",
    "    print(f\"\\n📋 Sample mapped ingredients:\")\n",
    "    sample_with_allergens = updated_ingredient_df[updated_ingredient_df['allergen_group_id'].notna()].head(10)\n",
    "    for _, row in sample_with_allergens.iterrows():\n",
    "        print(f\"   - ID: {row['ingredient_id']}, Name: '{row['ingredient_name']}', Allergen: {row['primary_allergen']} (Group ID: {row['allergen_group_id']})\")\n",
    "    \n",
    "    # Show sample of ingredients without allergens\n",
    "    sample_without_allergens = updated_ingredient_df[updated_ingredient_df['allergen_group_id'].isna()].head(5)\n",
    "    if len(sample_without_allergens) > 0:\n",
    "        print(f\"\\n📋 Sample ingredients without allergens:\")\n",
    "        for _, row in sample_without_allergens.iterrows():\n",
    "            print(f\"   - ID: {row['ingredient_id']}, Name: '{row['ingredient_name']}'\")\n",
    "    \n",
    "    return updated_ingredient_df\n",
    "\n",
    "\n",
    "# Apply the function to add allergen group IDs\n",
    "ingredient_df_with_allergens = add_allergen_group_id_to_ingredients(\n",
    "    ingredient_df, \n",
    "    allergen_df, \n",
    "    allergen_tags\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "81a55f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 VALIDATION AND ANALYSIS OF ALLERGEN MAPPING\n",
      "==================================================\n",
      "📊 Updated ingredient_df structure:\n",
      "   Columns: ['ingredient_id', 'ingredient_name', 'primary_allergen', 'allergen_group_id']\n",
      "   Shape: (990, 4)\n",
      "\n",
      "📈 Detailed allergen group mapping:\n",
      "   dairy (Group ID: 1.0): 17 ingredients\n",
      "   egg (Group ID: 2.0): 7 ingredients\n",
      "   fish (Group ID: 6.0): 10 ingredients\n",
      "   gluten (Group ID: 8.0): 11 ingredients\n",
      "   peanuts (Group ID: 5.0): 2 ingredients\n",
      "   shellfish (Group ID: 7.0): 5 ingredients\n",
      "   soy (Group ID: 3.0): 8 ingredients\n",
      "   tree_nuts (Group ID: 4.0): 7 ingredients\n",
      "\n",
      "🔍 Example allergen mappings:\n",
      "\n",
      "   DAIRY examples:\n",
      "     - 'butter' → Group ID: 1.0\n",
      "     - 'cheese' → Group ID: 1.0\n",
      "     - 'coconut milk' → Group ID: 1.0\n",
      "\n",
      "   EGG examples:\n",
      "     - 'chicken egg' → Group ID: 2.0\n",
      "     - 'duck egg' → Group ID: 2.0\n",
      "     - 'egg' → Group ID: 2.0\n",
      "\n",
      "   SOY examples:\n",
      "     - 'edamame' → Group ID: 3.0\n",
      "     - 'miso' → Group ID: 3.0\n",
      "     - 'soy sauce' → Group ID: 3.0\n",
      "\n",
      "   GLUTEN examples:\n",
      "     - 'barley' → Group ID: 8.0\n",
      "     - 'bread' → Group ID: 8.0\n",
      "     - 'bread flour' → Group ID: 8.0\n",
      "\n",
      "   TREE_NUTS examples:\n",
      "     - 'almond butter' → Group ID: 4.0\n",
      "     - 'almond milk' → Group ID: 4.0\n",
      "     - 'cashew' → Group ID: 4.0\n",
      "\n",
      "💾 Saved updated ingredient dataframe to 'ingredient_master_with_allergens.xlsx'\n",
      "\n",
      "📋 Final ingredient dataframe sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredient_id</th>\n",
       "      <th>ingredient_name</th>\n",
       "      <th>primary_allergen</th>\n",
       "      <th>allergen_group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>acai</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>agar-agar powder</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>all purpose flour</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>almond</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>almond butter</td>\n",
       "      <td>tree_nuts</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>almond milk</td>\n",
       "      <td>tree_nuts</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>almond nuts</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>aluminum foil</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>ambon banana</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>ambrosia fruit</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ingredient_id    ingredient_name primary_allergen  allergen_group_id\n",
       "0              1               acai             None                NaN\n",
       "1              2   agar-agar powder             None                NaN\n",
       "2              3  all purpose flour             None                NaN\n",
       "3              4             almond             None                NaN\n",
       "4              5      almond butter        tree_nuts                4.0\n",
       "5              6        almond milk        tree_nuts                4.0\n",
       "6              7        almond nuts             None                NaN\n",
       "7              8      aluminum foil             None                NaN\n",
       "8              9       ambon banana             None                NaN\n",
       "9             10     ambrosia fruit             None                NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validate and analyze the allergen mapping results\n",
    "print(\"🔍 VALIDATION AND ANALYSIS OF ALLERGEN MAPPING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check the structure of the updated dataframe\n",
    "print(f\"📊 Updated ingredient_df structure:\")\n",
    "print(f\"   Columns: {list(ingredient_df_with_allergens.columns)}\")\n",
    "print(f\"   Shape: {ingredient_df_with_allergens.shape}\")\n",
    "\n",
    "# Show detailed breakdown\n",
    "print(f\"\\n📈 Detailed allergen group mapping:\")\n",
    "allergen_mapping_summary = ingredient_df_with_allergens.groupby(['primary_allergen', 'allergen_group_id']).size().reset_index(name='count')\n",
    "for _, row in allergen_mapping_summary.iterrows():\n",
    "    if pd.notna(row['primary_allergen']):\n",
    "        print(f\"   {row['primary_allergen']} (Group ID: {row['allergen_group_id']}): {row['count']} ingredients\")\n",
    "\n",
    "# Show some specific examples\n",
    "print(f\"\\n🔍 Example allergen mappings:\")\n",
    "example_allergens = ['dairy', 'egg', 'soy', 'gluten', 'tree_nuts']\n",
    "for allergen in example_allergens:\n",
    "    examples = ingredient_df_with_allergens[ingredient_df_with_allergens['primary_allergen'] == allergen].head(3)\n",
    "    if len(examples) > 0:\n",
    "        print(f\"\\n   {allergen.upper()} examples:\")\n",
    "        for _, row in examples.iterrows():\n",
    "            print(f\"     - '{row['ingredient_name']}' → Group ID: {row['allergen_group_id']}\")\n",
    "\n",
    "# Save the updated dataframe\n",
    "output_filename = \"ingredient_master_with_allergens.xlsx\"\n",
    "ingredient_df_with_allergens.to_excel(output_filename, index=False)\n",
    "print(f\"\\n💾 Saved updated ingredient dataframe to '{output_filename}'\")\n",
    "\n",
    "# Display sample of final structure\n",
    "print(f\"\\n📋 Final ingredient dataframe sample:\")\n",
    "display(ingredient_df_with_allergens[['ingredient_id', 'ingredient_name', 'primary_allergen', 'allergen_group_id']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "fddf447a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚫 APPLYING EXCLUSION TERMS AND ADDING isAllergen COLUMN\n",
      "============================================================\n",
      "📋 Exclusion terms: ['breast milk', 'breastmilk', 'formula milk', 'formula', 'breast']\n",
      "\n",
      "✅ EXCLUSION AND FLAG RESULTS:\n",
      "   Total ingredients processed: 990\n",
      "   Excluded due to exclusion terms: 9\n",
      "   Final ingredients with allergens: 64\n",
      "   Final ingredients without allergens: 926\n",
      "   Allergen rate: 6.5%\n",
      "\n",
      "🚫 Excluded ingredients (due to exclusion terms):\n",
      "   - 'boneless skinless chicken breast' (was: None) → excluded by 'breast'\n",
      "   - 'breast milk' (was: None) → excluded by 'breast milk'\n",
      "   - 'chicken breast' (was: None) → excluded by 'breast'\n",
      "   - 'formula' (was: None) → excluded by 'formula'\n",
      "   - 'formula milk' (was: dairy) → excluded by 'formula milk'\n",
      "   - 'formula milk powder' (was: dairy) → excluded by 'formula milk'\n",
      "   - 'infant formula milk' (was: None) → excluded by 'formula milk'\n",
      "   - 'milk formula' (was: dairy) → excluded by 'formula'\n",
      "   - 'skinless boneless chicken breast' (was: None) → excluded by 'breast'\n",
      "\n",
      "📊 Updated allergen breakdown:\n",
      "   - dairy: 14 ingredients\n",
      "   - gluten: 11 ingredients\n",
      "   - fish: 10 ingredients\n",
      "   - soy: 8 ingredients\n",
      "   - tree_nuts: 7 ingredients\n",
      "   - egg: 7 ingredients\n",
      "   - shellfish: 5 ingredients\n",
      "   - peanuts: 2 ingredients\n",
      "\n",
      "📋 Sample of enhanced dataframe:\n",
      "With allergens:\n",
      "   ID: 5, Name: 'almond butter', Allergen: tree_nuts, isAllergen: True\n",
      "   ID: 6, Name: 'almond milk', Allergen: tree_nuts, isAllergen: True\n",
      "   ID: 12, Name: 'anchovy', Allergen: fish, isAllergen: True\n",
      "   ID: 60, Name: 'barley', Allergen: gluten, isAllergen: True\n",
      "   ID: 110, Name: 'bread', Allergen: gluten, isAllergen: True\n",
      "\n",
      "Without allergens:\n",
      "   ID: 1, Name: 'acai', isAllergen: False\n",
      "   ID: 2, Name: 'agar-agar powder', isAllergen: False\n",
      "   ID: 3, Name: 'all purpose flour', isAllergen: False\n",
      "   ID: 4, Name: 'almond', isAllergen: False\n",
      "   ID: 7, Name: 'almond nuts', isAllergen: False\n"
     ]
    }
   ],
   "source": [
    "# Enhanced allergen detection with exclusion terms and isAllergen column\n",
    "def add_exclusion_terms_and_allergen_flag(ingredient_df_with_allergens):\n",
    "    \"\"\"\n",
    "    Add exclusion terms logic and isAllergen column to ingredient dataframe.\n",
    "    \n",
    "    Exclusion terms like \"breast milk\", \"formula milk\" should NOT be flagged as allergens\n",
    "    even if they contain allergen keywords like \"milk\".\n",
    "    \n",
    "    Args:\n",
    "        ingredient_df_with_allergens: DataFrame with allergen mapping results\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Enhanced dataframe with exclusion logic and isAllergen column\n",
    "    \"\"\"\n",
    "    print(\"🚫 APPLYING EXCLUSION TERMS AND ADDING isAllergen COLUMN\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Define exclusion terms - ingredients that should NOT be considered allergens\n",
    "    exclusion_terms = [\n",
    "        \"breast milk\", \"breastmilk\", \"formula milk\", \"formula\", \"breast\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"📋 Exclusion terms: {exclusion_terms}\")\n",
    "    \n",
    "    # Create a copy to work with\n",
    "    enhanced_df = ingredient_df_with_allergens.copy()\n",
    "    \n",
    "    # Check for exclusions and nullify allergen data if needed\n",
    "    exclusion_count = 0\n",
    "    excluded_ingredients = []\n",
    "    \n",
    "    for idx, row in enhanced_df.iterrows():\n",
    "        ingredient_name = row['ingredient_name'].lower().strip()\n",
    "        \n",
    "        # Check if ingredient matches any exclusion term\n",
    "        is_excluded = False\n",
    "        for exclusion_term in exclusion_terms:\n",
    "            if exclusion_term.lower() in ingredient_name:\n",
    "                is_excluded = True\n",
    "                exclusion_count += 1\n",
    "                excluded_ingredients.append({\n",
    "                    'ingredient_name': row['ingredient_name'],\n",
    "                    'original_allergen': row['primary_allergen'],\n",
    "                    'original_allergen_id': row['allergen_group_id'],\n",
    "                    'exclusion_term': exclusion_term\n",
    "                })\n",
    "                break\n",
    "        \n",
    "        # If excluded, nullify allergen information\n",
    "        if is_excluded:\n",
    "            enhanced_df.at[idx, 'primary_allergen'] = None\n",
    "            enhanced_df.at[idx, 'allergen_group_id'] = None\n",
    "    \n",
    "    # Add isAllergen column based on allergen_group_id\n",
    "    enhanced_df['isAllergen'] = enhanced_df['allergen_group_id'].notna()\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_ingredients = len(enhanced_df)\n",
    "    ingredients_with_allergens = enhanced_df['isAllergen'].sum()\n",
    "    ingredients_without_allergens = total_ingredients - ingredients_with_allergens\n",
    "    \n",
    "    print(f\"\\n✅ EXCLUSION AND FLAG RESULTS:\")\n",
    "    print(f\"   Total ingredients processed: {total_ingredients}\")\n",
    "    print(f\"   Excluded due to exclusion terms: {exclusion_count}\")\n",
    "    print(f\"   Final ingredients with allergens: {ingredients_with_allergens}\")\n",
    "    print(f\"   Final ingredients without allergens: {ingredients_without_allergens}\")\n",
    "    print(f\"   Allergen rate: {(ingredients_with_allergens/total_ingredients)*100:.1f}%\")\n",
    "    \n",
    "    # Show excluded ingredients\n",
    "    if excluded_ingredients:\n",
    "        print(f\"\\n🚫 Excluded ingredients (due to exclusion terms):\")\n",
    "        for item in excluded_ingredients:\n",
    "            print(f\"   - '{item['ingredient_name']}' (was: {item['original_allergen']}) → excluded by '{item['exclusion_term']}'\")\n",
    "    \n",
    "    # Show updated allergen breakdown\n",
    "    print(f\"\\n📊 Updated allergen breakdown:\")\n",
    "    allergen_counts = enhanced_df[enhanced_df['isAllergen']]['primary_allergen'].value_counts()\n",
    "    for allergen, count in allergen_counts.items():\n",
    "        print(f\"   - {allergen}: {count} ingredients\")\n",
    "    \n",
    "    # Show sample of final structure\n",
    "    print(f\"\\n📋 Sample of enhanced dataframe:\")\n",
    "    sample_cols = ['ingredient_id', 'ingredient_name', 'primary_allergen', 'allergen_group_id', 'isAllergen']\n",
    "    print(\"With allergens:\")\n",
    "    sample_with = enhanced_df[enhanced_df['isAllergen']].head(5)\n",
    "    for _, row in sample_with.iterrows():\n",
    "        print(f\"   ID: {row['ingredient_id']}, Name: '{row['ingredient_name']}', Allergen: {row['primary_allergen']}, isAllergen: {row['isAllergen']}\")\n",
    "    \n",
    "    print(\"\\nWithout allergens:\")\n",
    "    sample_without = enhanced_df[~enhanced_df['isAllergen']].head(5)\n",
    "    for _, row in sample_without.iterrows():\n",
    "        print(f\"   ID: {row['ingredient_id']}, Name: '{row['ingredient_name']}', isAllergen: {row['isAllergen']}\")\n",
    "    \n",
    "    return enhanced_df\n",
    "\n",
    "# Apply the enhancement\n",
    "ingredient_df_final = add_exclusion_terms_and_allergen_flag(ingredient_df_with_allergens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dfb50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final validation and export of enhanced ingredient dataframe\n",
    "print(\"📊 FINAL INGREDIENT DATAFRAME VALIDATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check the final structure\n",
    "print(f\"Final dataframe columns: {list(ingredient_df_final.columns)}\")\n",
    "print(f\"Final dataframe shape: {ingredient_df_final.shape}\")\n",
    "\n",
    "# Data type validation\n",
    "print(f\"\\n📋 Column data types:\")\n",
    "for col in ingredient_df_final.columns:\n",
    "    print(f\"   {col}: {ingredient_df_final[col].dtype}\")\n",
    "\n",
    "# isAllergen column validation\n",
    "allergen_true_count = ingredient_df_final['isAllergen'].sum()\n",
    "allergen_false_count = (~ingredient_df_final['isAllergen']).sum()\n",
    "\n",
    "print(f\"\\n✅ isAllergen column validation:\")\n",
    "print(f\"   True (has allergen): {allergen_true_count}\")\n",
    "print(f\"   False (no allergen): {allergen_false_count}\")\n",
    "print(f\"   Total: {allergen_true_count + allergen_false_count}\")\n",
    "\n",
    "# Cross-validation: isAllergen should match allergen_group_id presence\n",
    "validation_passed = True\n",
    "mismatch_count = 0\n",
    "\n",
    "for _, row in ingredient_df_final.iterrows():\n",
    "    has_allergen_id = pd.notna(row['allergen_group_id'])\n",
    "    is_allergen_flag = row['isAllergen']\n",
    "    \n",
    "    if has_allergen_id != is_allergen_flag:\n",
    "        mismatch_count += 1\n",
    "        if mismatch_count <= 5:  # Show first 5 mismatches\n",
    "            print(f\"   ⚠️ Mismatch: {row['ingredient_name']} - allergen_group_id: {row['allergen_group_id']}, isAllergen: {is_allergen_flag}\")\n",
    "        validation_passed = False\n",
    "\n",
    "if validation_passed:\n",
    "    print(\"   ✅ All isAllergen flags match allergen_group_id presence\")\n",
    "else:\n",
    "    print(f\"   ❌ Found {mismatch_count} mismatches between isAllergen and allergen_group_id\")\n",
    "\n",
    "# Show final breakdown by allergen type\n",
    "print(f\"\\n📈 Final allergen distribution:\")\n",
    "allergen_breakdown = ingredient_df_final[ingredient_df_final['isAllergen']]['primary_allergen'].value_counts()\n",
    "for allergen, count in allergen_breakdown.items():\n",
    "    percentage = (count / allergen_true_count) * 100\n",
    "    print(f\"   {allergen}: {count} ingredients ({percentage:.1f}%)\")\n",
    "\n",
    "# Export final results\n",
    "final_output_filename = \"ingredient_master_final_with_allergens.xlsx\"\n",
    "ingredient_df_final.to_excel(final_output_filename, index=False)\n",
    "print(f\"\\n💾 Exported final ingredient dataframe to '{final_output_filename}'\")\n",
    "\n",
    "# Display final structure sample\n",
    "print(f\"\\n📋 Final dataframe structure sample:\")\n",
    "display(ingredient_df_final[['ingredient_id', 'ingredient_name', 'primary_allergen', 'allergen_group_id', 'isAllergen']].head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4575939",
   "metadata": {},
   "source": [
    "Finish Populating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a793c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the final dataset\n",
    "df.to_excel(\"cfirstversion_current_dataset.xlsx\", index=False)\n",
    "print(\"✅ DataFrame saved to 'cfirstversion_current_dataset.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dec744",
   "metadata": {},
   "source": [
    "Creating Category With Recipe Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162312db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categories and assign IDs\n",
    "categories = [\n",
    "    'vegan', 'vegetarian', 'pescetarian', 'dairy_free', \n",
    "    'egg_free', 'soy_free', 'nut_free', 'gluten_free',\n",
    "    'halal', 'non_halal', 'non_veg'\n",
    "]\n",
    "\n",
    "category_id_map = {category: idx for idx, category in enumerate(categories, 1)}\n",
    "\n",
    "# Create a reference DataFrame for categories\n",
    "category_df = pd.DataFrame({\n",
    "    'category_id': list(category_id_map.values()),\n",
    "    'category_name': list(category_id_map.keys())\n",
    "})\n",
    "\n",
    "print(\"Category DataFrame:\")\n",
    "print(category_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc8966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc22b8",
   "metadata": {},
   "source": [
    "## 🆔 Create Ingredient Master DataFrame with Unique IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7acd25",
   "metadata": {},
   "source": [
    "##### Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4efa62d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ingredient_ids_to_recipe_df(recipe_ingredient_df, ingredient_id_mapping, use_standardized=True):\n",
    "    \"\"\"\n",
    "    Map ingredient IDs to the recipe ingredient DataFrame using cleaned ingredient names\n",
    "    \n",
    "    Args:\n",
    "        recipe_ingredient_df: DataFrame with recipe-ingredient relationships\n",
    "        ingredient_id_mapping: Dictionary mapping cleaned ingredient names to IDs\n",
    "        use_standardized: If True, use standardized_ingredient; if False, use single_ingredient\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Updated recipe_ingredient_df with ingredient_id column\n",
    "    \"\"\"\n",
    "    print(\"🔗 MAPPING INGREDIENT IDS TO RECIPE DATAFRAME\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Choose which ingredient column to use\n",
    "    ingredient_column = 'standardized_ingredient' if use_standardized else 'single_ingredient'\n",
    "    \n",
    "    if ingredient_column not in recipe_ingredient_df.columns:\n",
    "        print(f\"❌ Column '{ingredient_column}' not found in recipe_ingredient_df\")\n",
    "        return recipe_ingredient_df\n",
    "    \n",
    "    # Create a copy to avoid modifying the original\n",
    "    updated_df = recipe_ingredient_df.copy()\n",
    "    \n",
    "    # Clean the ingredient names in the DataFrame and map to IDs\n",
    "    def get_ingredient_id(ingredient_name):\n",
    "        if pd.isna(ingredient_name):\n",
    "            return None\n",
    "        cleaned_name = clean_ingredient_name_symbols(ingredient_name)\n",
    "        return ingredient_id_mapping.get(cleaned_name, None)\n",
    "    \n",
    "    updated_df['ingredient_id'] = updated_df[ingredient_column].apply(get_ingredient_id)\n",
    "    \n",
    "    # Check mapping results\n",
    "    total_rows = len(updated_df)\n",
    "    mapped_rows = updated_df['ingredient_id'].notna().sum()\n",
    "    unmapped_rows = total_rows - mapped_rows\n",
    "    \n",
    "    print(f\"✅ Ingredient ID mapping complete:\")\n",
    "    print(f\"   Total rows: {total_rows}\")\n",
    "    print(f\"   Successfully mapped: {mapped_rows} ({(mapped_rows/total_rows)*100:.1f}%)\")\n",
    "    print(f\"   Unmapped: {unmapped_rows} ({(unmapped_rows/total_rows)*100:.1f}%)\")\n",
    "    \n",
    "    if unmapped_rows > 0:\n",
    "        print(f\"\\n🔍 Sample unmapped ingredients:\")\n",
    "        unmapped_sample = updated_df[updated_df['ingredient_id'].isna()][ingredient_column].dropna().unique()[:5]\n",
    "        for ingredient in unmapped_sample:\n",
    "            cleaned = clean_ingredient_name_symbols(ingredient)\n",
    "            print(f\"   Original: '{ingredient}' → Cleaned: '{cleaned}'\")\n",
    "    \n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d687e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Step 2: Mapping ingredient IDs to recipe DataFrame...\n",
      "🔗 MAPPING INGREDIENT IDS TO RECIPE DATAFRAME\n",
      "--------------------------------------------------\n",
      "✅ Ingredient ID mapping complete:\n",
      "   Total rows: 8176\n",
      "   Successfully mapped: 8163 (99.8%)\n",
      "   Unmapped: 13 (0.2%)\n",
      "\n",
      "🔍 Sample unmapped ingredients:\n",
      "\n",
      "📋 Sample of updated recipe_ingredient_df with IDs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>single_ingredient</th>\n",
       "      <th>standardized_ingredient</th>\n",
       "      <th>ingredient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>cassava</td>\n",
       "      <td>cassava</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fish</td>\n",
       "      <td>fish</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>chicken</td>\n",
       "      <td>chicken</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>coconut oil</td>\n",
       "      <td>coconut oil</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>chicken broth</td>\n",
       "      <td>chicken broth</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>lime juice</td>\n",
       "      <td>lime juice</td>\n",
       "      <td>497.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>spinach</td>\n",
       "      <td>spinach</td>\n",
       "      <td>818.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>beef</td>\n",
       "      <td>beef</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>potato starch</td>\n",
       "      <td>potato starch</td>\n",
       "      <td>670.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>milk</td>\n",
       "      <td>milk</td>\n",
       "      <td>538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe_id single_ingredient standardized_ingredient  ingredient_id\n",
       "0          1           cassava                 cassava          155.0\n",
       "1          1              fish                    fish          327.0\n",
       "2          1           chicken                 chicken          182.0\n",
       "3          1       coconut oil             coconut oil          231.0\n",
       "4          1     chicken broth           chicken broth          185.0\n",
       "5          1        lime juice              lime juice          497.0\n",
       "6          1           spinach                 spinach          818.0\n",
       "7          2              beef                    beef           72.0\n",
       "8          2     potato starch           potato starch          670.0\n",
       "9          2              milk                    milk          538.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Final DataFrame Statistics:\n",
      "   Recipe DataFrame shape: (8176, 8)\n",
      "   Unique recipes: 1322\n",
      "   Unique ingredients: 995\n",
      "   Recipe-ingredient relationships: 8176\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Map ingredient IDs back to recipe DataFrame\n",
    "if 'ingredient_id_mapping' in locals() and 'recipe_ingredient_df' in locals():\n",
    "    print(\"\\n📋 Step 2: Mapping ingredient IDs to recipe DataFrame...\")\n",
    "    \n",
    "    # Update the recipe_ingredient_df with ingredient IDs\n",
    "    recipe_ingredient_df_with_ids = map_ingredient_ids_to_recipe_df(\n",
    "        recipe_ingredient_df,\n",
    "        ingredient_id_mapping,\n",
    "        use_standardized=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n📋 Sample of updated recipe_ingredient_df with IDs:\")\n",
    "    sample_cols = ['recipe_id', 'single_ingredient', 'standardized_ingredient', 'ingredient_id']\n",
    "    available_cols = [col for col in sample_cols if col in recipe_ingredient_df_with_ids.columns]\n",
    "    display(recipe_ingredient_df_with_ids[available_cols].head(10))\n",
    "    \n",
    "    print(f\"\\n📊 Final DataFrame Statistics:\")\n",
    "    print(f\"   Recipe DataFrame shape: {recipe_ingredient_df_with_ids.shape}\")\n",
    "    print(f\"   Unique recipes: {recipe_ingredient_df_with_ids['recipe_id'].nunique()}\")\n",
    "    print(f\"   Unique ingredients: {len(ingredient_df)}\")\n",
    "    print(f\"   Recipe-ingredient relationships: {len(recipe_ingredient_df_with_ids)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Required variables not found for ID mapping\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7132bf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Step 3: Final Data Validation and Export\n",
      "--------------------------------------------------\n",
      "🔍 FINAL VALIDATION CHECKS:\n",
      "✅ Ingredient Master DataFrame:\n",
      "   Total unique ingredients: 995\n",
      "   Clean ingredients: 995\n",
      "   Empty/null ingredients: 0\n",
      "\n",
      "✅ Recipe-Ingredient Relationships:\n",
      "   Total relationships: 8176\n",
      "   Successfully mapped: 8163 (99.8%)\n",
      "   Unmapped: 13 (0.2%)\n",
      "\n",
      "✅ Data Consistency:\n",
      "   Unique ingredient IDs in recipes: 995\n",
      "   Total ingredient IDs in master: 995\n",
      "   Coverage: 100.0%\n",
      "\n",
      "💾 EXPORTING CLEANED DATASETS:\n",
      "✅ Exported ingredient master: cleaned_ingredient_master.xlsx\n",
      "✅ Exported recipe-ingredient data: cleaned_recipe_ingredient_with_ids.xlsx\n",
      "\n",
      "🎉 DATA PROCESSING COMPLETE!\n",
      "📁 Files ready for downstream modeling and analysis\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Final validation and export\n",
    "print(\"📋 Step 3: Final Data Validation and Export\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if 'ingredient_df' in locals() and 'recipe_ingredient_df_with_ids' in locals():\n",
    "    \n",
    "    # Validation checks\n",
    "    print(\"🔍 FINAL VALIDATION CHECKS:\")\n",
    "    \n",
    "    # Check 1: Ingredient DataFrame cleanliness\n",
    "    total_ingredients = len(ingredient_df)\n",
    "    clean_ingredients = ingredient_df['ingredient_name'].notna().sum()\n",
    "    empty_ingredients = ingredient_df['ingredient_name'].isna().sum()\n",
    "    \n",
    "    print(f\"✅ Ingredient Master DataFrame:\")\n",
    "    print(f\"   Total unique ingredients: {total_ingredients}\")\n",
    "    print(f\"   Clean ingredients: {clean_ingredients}\")\n",
    "    print(f\"   Empty/null ingredients: {empty_ingredients}\")\n",
    "    \n",
    "    # Check 2: Recipe-Ingredient mapping completeness\n",
    "    total_relationships = len(recipe_ingredient_df_with_ids)\n",
    "    mapped_relationships = recipe_ingredient_df_with_ids['ingredient_id'].notna().sum()\n",
    "    unmapped_relationships = total_relationships - mapped_relationships\n",
    "    \n",
    "    print(f\"\\n✅ Recipe-Ingredient Relationships:\")\n",
    "    print(f\"   Total relationships: {total_relationships}\")\n",
    "    print(f\"   Successfully mapped: {mapped_relationships} ({(mapped_relationships/total_relationships)*100:.1f}%)\")\n",
    "    print(f\"   Unmapped: {unmapped_relationships} ({(unmapped_relationships/total_relationships)*100:.1f}%)\")\n",
    "    \n",
    "    # Check 3: Data consistency\n",
    "    unique_ingredient_ids_in_recipes = recipe_ingredient_df_with_ids['ingredient_id'].dropna().nunique()\n",
    "    total_ingredient_ids_in_master = ingredient_df['ingredient_id'].nunique()\n",
    "    \n",
    "    print(f\"\\n✅ Data Consistency:\")\n",
    "    print(f\"   Unique ingredient IDs in recipes: {unique_ingredient_ids_in_recipes}\")\n",
    "    print(f\"   Total ingredient IDs in master: {total_ingredient_ids_in_master}\")\n",
    "    print(f\"   Coverage: {(unique_ingredient_ids_in_recipes/total_ingredient_ids_in_master)*100:.1f}%\")\n",
    "    \n",
    "    # Export cleaned datasets\n",
    "    print(f\"\\n💾 EXPORTING CLEANED DATASETS:\")\n",
    "    \n",
    "    try:\n",
    "        # Export ingredient master DataFrame\n",
    "        ingredient_filename = \"cleaned_ingredient_master.xlsx\"\n",
    "        ingredient_df.to_excel(ingredient_filename, index=False)\n",
    "        print(f\"✅ Exported ingredient master: {ingredient_filename}\")\n",
    "        \n",
    "        # Export recipe-ingredient DataFrame with IDs\n",
    "        recipe_ingredient_filename = \"cleaned_recipe_ingredient_with_ids.xlsx\"\n",
    "        recipe_ingredient_df_with_ids.to_excel(recipe_ingredient_filename, index=False)\n",
    "        print(f\"✅ Exported recipe-ingredient data: {recipe_ingredient_filename}\")\n",
    "        \n",
    "        print(f\"\\n🎉 DATA PROCESSING COMPLETE!\")\n",
    "        print(f\"📁 Files ready for downstream modeling and analysis\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Export error: {str(e)}\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ Required DataFrames not found for validation\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f7aece35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 DEBUGGING STANDARDIZED INGREDIENT FORMAT\n",
      "--------------------------------------------------\n",
      "📋 Sample standardized ingredients (raw format):\n",
      "   1. 'cassava'\n",
      "   2. 'fish'\n",
      "   3. 'chicken'\n",
      "   4. 'coconut oil'\n",
      "   5. 'chicken broth'\n",
      "   6. 'lime juice'\n",
      "   7. 'spinach'\n",
      "   8. 'beef'\n",
      "   9. 'potato starch'\n",
      "   10. 'milk'\n",
      "\n",
      "🧹 Testing cleaning function:\n",
      "   1. Original: 'cassava'\n",
      "      Cleaned:  'cassava'\n",
      "\n",
      "   2. Original: 'fish'\n",
      "      Cleaned:  'fish'\n",
      "\n",
      "   3. Original: 'chicken'\n",
      "      Cleaned:  'chicken'\n",
      "\n",
      "   4. Original: 'coconut oil'\n",
      "      Cleaned:  'coconut oil'\n",
      "\n",
      "   5. Original: 'chicken broth'\n",
      "      Cleaned:  'chicken broth'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check the format of standardized ingredients\n",
    "print(\"🔍 DEBUGGING STANDARDIZED INGREDIENT FORMAT\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if 'recipe_ingredient_df' in locals():\n",
    "    # Sample some standardized ingredients to see their actual format\n",
    "    sample_ingredients = recipe_ingredient_df['standardized_ingredient'].dropna().head(20).tolist()\n",
    "    \n",
    "    print(\"📋 Sample standardized ingredients (raw format):\")\n",
    "    for i, ingredient in enumerate(sample_ingredients[:10], 1):\n",
    "        print(f\"   {i}. {repr(ingredient)}\")  # repr shows quotes and special characters\n",
    "    \n",
    "    # Test the cleaning function on these samples\n",
    "    print(f\"\\n🧹 Testing cleaning function:\")\n",
    "    for i, ingredient in enumerate(sample_ingredients[:5], 1):\n",
    "        cleaned = clean_ingredient_name_symbols(ingredient)\n",
    "        print(f\"   {i}. Original: {repr(ingredient)}\")\n",
    "        print(f\"      Cleaned:  {repr(cleaned)}\")\n",
    "        print()\n",
    "\n",
    "else:\n",
    "    print(\"❌ recipe_ingredient_df not found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
